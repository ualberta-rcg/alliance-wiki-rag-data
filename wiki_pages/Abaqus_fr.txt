<languages />
[[Category:Software]]
__FORCETOC__
[https://www.3ds.com/products-services/simulia/products/abaqus/ Abaqus FEA] est un progiciel commercial pour l'analyse d'éléments finis et l'ingénierie assistée par ordinateur.

= Votre licence =
Des modules Abaqus sont disponibles sur nos grappes, mais vous devez posséder votre propre licence. Pour configurer votre compte sur les grappes que vous voulez utiliser, connectez-vous et créez sur chacune un fichier <code>$HOME/.licenses/abaqus.lic</code> qui contient les deux lignes suivantes, pour les versions 202X et 6.14.1 respectivement. Remplacez ensuite <code>port@server</code> par le numéro du port flexlm et l'adresse IP (ou le nom complet du domaine) de votre serveur de licence Abaqus.

{{File
|name=abaqus.lic
|contents=
prepend_path("ABAQUSLM_LICENSE_FILE","port@server")
prepend_path("LM_LICENSE_FILE","port@server")
}}

Si votre licence n'est pas configurée pour une grappe en particulier, les administrateurs de systèmes des deux parties devront effectuer certaines modifications. Ceci est nécessaire pour que les ports flexlm et TCP de votre serveur Abaqus puissent être rejoints par tous les nœuds de calcul quand vos tâches dans la queue seront exécutées. Pour que nous puissions vous assister dans cette tâche, écrivez au [[Technical support/fr|soutien technique]] en indiquant
* le numéro du port flexlm
* le numéro du port statique
* l'adresse IP de votre serveur de licence Abaqus.
En retour vous recevrez une liste d'adresses IP et votre administrateur de système pourra ouvrir les pare-feu de votre serveur local pour que la grappe puisse se connecter via les deux ports. Une entente spéciale doit habituellement être négociée et signée avec SIMULIA pour qu'une telle licence puisse être utilisée à distance avec notre matériel.

= Soumettre une tâche =
Vous trouverez ci-dessous des prototypes de scripts Slurm pour soumettre des simulations parallèles sur un ou plusieurs nœuds de calcul en utilisant des fils et MPI. Dans la plupart des cas, il suffira d'utiliser un des <b>scripts du répertoire /project</b> dans une des sections pour un nœud simple. Dans la dernière ligne des scripts, l'argument <code>memory=</code> est optionnel et sert aux tâches qui demandent beaucoup de mémoire ou qui posent problème; la valeur de déplacement de 3072Mo pourrait nécessiter un ajustement. Pour obtenir la liste des arguments en ligne de commande, chargez un module Abaqus et lancez <code>abaqus -help | less</code>.

Pour une tâche sur un nœud simple d'une durée de moins de 24 heures, le <i>script du répertoire /project</i> sous le premier onglet devrait suffire. Pour une tâche de plus longue durée, utilisez un script de redémarrage.

Il est préférable que les tâches qui créent des fichiers de redémarrage volumineux écrivent sur le disque local via l'utilisation de la variable d'environnement SLURM_TMPDIR utilisée dans les <b>scripts de répertoire temporaire</b> sous les deux onglets les plus à droite des sections d'analyse standard et explicite à nœud unique. Les scripts de redémarrage présentés ici poursuivront les tâches qui ont été interrompues prématurément pour une quelconque raison. De telles interruptions peuvent se produire si une tâche atteint son temps d'exécution maximal demandé avant de se terminer et est arrêtée par la file d'attente ou si le nœud de calcul sur lequel la tâche était exécutée a planté en raison d'une défaillance matérielle inattendue. D'autres types de redémarrage sont possibles en modifiant davantage le fichier d'entrée (non montré) pour continuer une tâche avec des étapes supplémentaires ou modifier l'analyse (consultez la documentation pour plus de détails pour la version).

Les tâches qui exigent beaucoup de mémoire ou beaucoup de ressources de calcul (plus que la capacité d'un nœud simple) devraient utiliser les scripts MPI dans les sections pour nœuds multiples afin de distribuer le calcul sur un ensemble de nœuds arbitraires déterminé automatiquement par l'ordonnanceur. Avant de lancer des tâches de longue durée, il est recommandé d'exécuter de courts tests présentant peu de scalabilité pour déterminer la durée réelle d'exécution (et les exigences en mémoire) en fonction du nombre optimal de cœurs (2, 4, 8, etc.). 

== Analyse standard ==
Les solveurs prennent en charge la parallélisation avec fils et avec MPI. Des scripts pour chaque mode sont présentés sous les onglets pour l'utilisation d'un nœud simple et celle de nœuds multiples. Des scripts pour redémarrer une tâche qui utilise des nœuds multiples ne sont pas présentés pour l'instant.

<span id="Single_node_computing"></span>
=== Scripts pour un nœud simple === 

<tabs>
<tab name="script du répertoire /project">
{{File
  |name="scriptsp1.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # Specify account
#SBATCH --time=00-06:00        # Specify days-hrs:mins
#SBATCH --cpus-per-task=4      # Specify number of cores
#SBATCH --mem=8G               # Specify total memory > 5G
#SBATCH --nodes=1              # Do not change !
##SBATCH --constraint=cascade  # Uncomment to specify node (cpu/gpu jobs)
##SBATCH --gres=gpu:t4:1       # Uncomment to specify gpu
# or
##SBATCH --constraint=rome     # Uncomment to specify node (gpu only jobs)
##SBATCH --gres=gpu:a100:1     # Uncomment to specify gpu

module load StdEnv/2020        # Latest installed version
module load abaqus/2021        # Latest installed version

#module load StdEnv/2016       # Uncomment to use
#module load abaqus/2020       # Uncomment to use

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"

rm -f testsp1* testsp2*
abaqus job=testsp1 input=mystd-sim.inp \
   scratch=$SLURM_TMPDIR cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB" \
#  gpus=$SLURM_GPUS_ON_NODE  # uncomment this line to use gpu
}}

Pour écrire les données de redémarrage en incréments de N=12, le fichier en entrée doit contenir
 *RESTART, WRITE, OVERLAY, FREQUENCY=12
Pour écrire les données de redémarrage pour un total de 12 incréments, entrez plutôt 
 *RESTART, WRITE, OVERLAY, NUMBER INTERVAL=12, TIME MARKS=NO
Pour vérifier l'information complète sur le redémarrage 
 egrep -i "step|start" testsp*.com testsp*.msg testsp*.sta
Certaines simulations peuvent être améliorées en ajoutant au bas du script la commande Abaqus
 order_parallel=OFF

</tab>
<tab name="script de redémarrage pour le répertoire /project">
{{File
  |name="scriptsp2.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # Specify account
#SBATCH --time=00-06:00        # Specify days-hrs:mins
#SBATCH --cpus-per-task=4      # Specify number of cores
#SBATCH --mem=8G               # Specify total memory > 5G
#SBATCH --nodes=1              # Do not change !
##SBATCH --constraint=cascade  # Uncomment to specify node (44cores)
##SBATCH --gres=gpu:t4:1       # Uncomment to specify gpu
# or
##SBATCH --constraint=rome     # Uncomment to specify node (128cores)
##SBATCH --gres=gpu:a100:1     # Uncomment to specify gpu

module load StdEnv/2020        # Latest installed version
module load abaqus/2021        # Latest installed version

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"

rm -f testsp2* testsp1.lck
abaqus job=testsp2 oldjob=testsp1 input=mystd-sim-restart.inp \
   scratch=$SLURM_TMPDIR cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB" \
#  gpus=$SLURM_GPUS_ON_NODE  # uncomment this line to use gpu
}}

Le fichier en entrée pour le redémarrage doit contenir
 *HEADING
 *RESTART, READ

</tab>
<tab name="script pour répertoire temporaire">
{{File
  |name="scriptst1.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # Specify account
#SBATCH --time=00-06:00        # Specify days-hrs:mins
#SBATCH --cpus-per-task=4      # Specify number of cores
#SBATCH --mem=8G               # Specify total memory > 5G
#SBATCH --nodes=1              # Do not change !
##SBATCH --constraint=cascade  # Uncomment to specify node (cpu/gpu jobs)
##SBATCH --gres=gpu:t4:1       # Uncomment to specify gpu
# or
##SBATCH --constraint=rome     # Uncomment to specify node (gpu only jobs)
##SBATCH --gres=gpu:a100:1     # Uncomment to specify gpu

module load StdEnv/2020        # Latest installed version
module load abaqus/2021        # Latest installed version

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"
echo "SLURM_SUBMIT_DIR =" $SLURM_SUBMIT_DIR
echo "SLURM_TMPDIR = " $SLURM_TMPDIR

rm -f testst1* testst2*
mkdir $SLURM_TMPDIR/scratch
cd $SLURM_TMPDIR
while sleep 6h; do
   echo "Saving data due to time limit ..."
   cp -fv * $SLURM_SUBMIT_DIR 2>/dev/null
done &
WPID=$!
abaqus job=testst1 input=$SLURM_SUBMIT_DIR/mystd-sim.inp \
   scratch=$SLURM_TMPDIR/scratch cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB" \
#  gpus=$SLURM_GPUS_ON_NODE  # uncomment this line to use gpu
{ kill $WPID && wait $WPID; } 2>/dev/null
cp -fv * $SLURM_SUBMIT_DIR
}}

Pour écrire les données de redémarrage en incréments de N=12, le fichier en entrée doit contenir
 *RESTART, WRITE, OVERLAY, FREQUENCY=12
Pour écrire les données de redémarrage pour un total de 12 incréments, entrez plutôt 
 *RESTART, WRITE, OVERLAY, NUMBER INTERVAL=12, TIME MARKS=NO
Pour vérifier l'information complète sur le redémarrage
 egrep -i "step|start" testst*.com testst*.msg testst*.sta

</tab>
<tab name="script de redémarrage pour le répertoire temporaire">
{{File
  |name="scriptst2.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # Specify account
#SBATCH --time=00-06:00        # Specify days-hrs:mins
#SBATCH --cpus-per-task=4      # Specify number of cores
#SBATCH --mem=8G               # Specify total memory > 5G
#SBATCH --nodes=1              # Do not change !
##SBATCH --constraint=cascade  # Uncomment to specify node (44 cores)
##SBATCH --gres=gpu:t4:1       # Uncomment to specify gpu
# or
##SBATCH --constraint=rome     # Uncomment to specify node (128 cores)
##SBATCH --gres=gpu:a100:1     # Uncomment to specify gpu

module load StdEnv/2020        # Latest installed version
module load abaqus/2021        # Latest installed version

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"
echo "SLURM_SUBMIT_DIR =" $SLURM_SUBMIT_DIR
echo "SLURM_TMPDIR = " $SLURM_TMPDIR

rm -f testst2* testst1.lck
cp testst1* $SLURM_TMPDIR
mkdir $SLURM_TMPDIR/scratch
cd $SLURM_TMPDIR
while sleep 6h; do
   echo "Saving data due to time limit ..."
   cp -fv testst2* $SLURM_SUBMIT_DIR 2>/dev/null
done &
WPID=$!
abaqus job=testst2 oldjob=testst1 input=$SLURM_SUBMIT_DIR/mystd-sim-restart.inp \
   scratch=$SLURM_TMPDIR/scratch cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB" \
#  gpus=$SLURM_GPUS_ON_NODE  # uncomment this line to use gpu
{ kill $WPID && wait $WPID; } 2>/dev/null
cp -fv testst2* $SLURM_SUBMIT_DIR
}}

Le fichier en entrée pour le redémarrage doit contenir
 *HEADING
 *RESTART, READ

</tab>
</tabs>

<span id="Multiple_node_computing"></span>
=== Script pour nœuds multiples ===

Si vous disposez d'une licence qui vous permet d'exécuter des tâches nécessitant beaucoup de mémoire et de calcul, le script suivant pourra effectuer le calcul avec MPI en utilisant un ensemble de nœuds arbitraires idéalement déterminé automatiquement par l'ordonnanceur. Un script modèle pour redémarrer des tâches sur nœuds multiples n'est pas fourni car son utilisation présente des limitations supplémentaires.

{{File
  |name="scriptsp1-mpi.txt"
  |lang="sh"
  |contents=
!/bin/bash
#SBATCH --account=def-group    # Specify account
#SBATCH --time=00-06:00        # Specify days-hrs:mins
##SBATCH --nodes=2             # Uncomment to specify (optional)
#SBATCH --ntasks=8             # Specify number of cores
#SBATCH --mem-per-cpu=4G       # Specify memory per core
##SBATCH --tasks-per-node=4    # Uncomment to specify (optional)
#SBATCH --cpus-per-task=1      # Do not change !

module load StdEnv/2020        # Latest installed version
module load abaqus/2021        # Latest installed version

unset SLURM_GTIDS
#export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"

rm -f testsp1-mpi*

unset hostlist
nodes="$(slurm_hl2hl.py --format MPIHOSTLIST {{!}} xargs)"
for i in `echo "$nodes" {{!}} xargs -n1 {{!}} uniq`; do hostlist=${hostlist}$(echo "['${i}',$(echo "$nodes" {{!}} xargs -n1 {{!}} grep $i {{!}} wc -l)],"); done
hostlist="$(echo "$hostlist" {{!}} sed 's/,$//g')"
mphostlist="mp_host_list=[$(echo "$hostlist")]"
export $mphostlist
echo "$mphostlist" > abaqus_v6.env

abaqus job=testsp1-mpi input=mystd-sim.inp \
  scratch=$SLURM_TMPDIR cpus=$SLURM_NTASKS interactive mp_mode=mpi \
  #mp_host_split=1  # number of dmp processes per node >= 1 (uncomment to specify)
}}

==Analyse explicite==
Les solveurs prennent en charge la parallélisation avec fils et avec MPI. Des scripts pour chaque mode sont présentés sous les onglets pour l'utilisation d'un nœud simple et celle de nœuds multiples. Des modèles de scripts pour redémarrer une tâche qui utilise des nœuds multiples nécessitent plus de tests et ne sont pas présentés pour l'instant.

<span id="Single_node_computing"></span>
=== Scripts pour un nœud simple === 

<tabs>
<tab name="script pour le répertoire /project">
{{File
  |name="scriptep1.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # indiquer le nom du compte
#SBATCH --time=00-06:00        # indiquer la limite de temps (jours-heures:minutes)
#SBATCH --mem=8000M            # indiquer la mémoire totale > 5M
#SBATCH --cpus-per-task=4      # indiquer le nombre de cœurs > 1
#SBATCH --nodes=1              # ne pas modifier

module load StdEnv/2020
module load abaqus/2021

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"

rm -f testep1* testep2*
abaqus job=testep1 input=myexp-sim.inp \
   scratch=$SLURM_TMPDIR cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB"
}}

Pour écrire les données de redémarrage pour un total de 12 incréments, le fichier en entrée doit contenir
 *RESTART, WRITE, OVERLAY, NUMBER INTERVAL=12, TIME MARKS=NO
Pour vérifier l'information complète sur le redémarrage
 egrep -i "step|restart" testep*.com testep*.msg testep*.sta

</tab>
<tab name="script de redémarrage pour le répertoire /project">
{{File
  |name="scriptep2.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # indiquer le nom du compte
#SBATCH --time=00-06:00        # indiquer la limite de temps (jours-heures:minutes)
#SBATCH --mem=8000M            # indiquer la mémoire totale > 5M
#SBATCH --cpus-per-task=4      # indiquer le nombre de cœurs > 1
#SBATCH --nodes=1              # ne pas modifier

module load StdEnv/2020
module load abaqus/2021

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"

rm -f testep2* testep1.lck
for f in testep1*; do [[ -f ${f} ]] && cp -a "$f" "testep2${f#testep1}"; done
abaqus job=testep2 input=myexp-sim.inp recover \
   scratch=$SLURM_TMPDIR cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB"
}}

Le fichier en entrée ne requiert aucune modification pour le redémarrage de l'analyse.

</tab>
<tab name="script pour le répertoire temporaire">
{{File
  |name="scriptet1.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # specify account
#SBATCH --time=00-06:00        # days-hrs:mins
#SBATCH --mem=8000M            # node memory > 5G
#SBATCH --cpus-per-task=4      # number cores > 1
#SBATCH --nodes=1              # do not change

module load StdEnv/2020
module load abaqus/2021

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"
echo "SLURM_SUBMIT_DIR =" $SLURM_SUBMIT_DIR
echo "SLURM_TMPDIR = " $SLURM_TMPDIR

rm -f testet1* testet2*
cd $SLURM_TMPDIR
while sleep 6h; do
   cp -f * $SLURM_SUBMIT_DIR 2>/dev/null
done &
WPID=$!
abaqus job=testet1 input=$SLURM_SUBMIT_DIR/myexp-sim.inp \
   scratch=$SLURM_TMPDIR cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB"
{ kill $WPID && wait $WPID; } 2>/dev/null
cp -f * $SLURM_SUBMIT_DIR
}}

Pour écrire les données de redémarrage pour un total de 12 incréments, le fichier en entrée doit contenir
 *RESTART, WRITE, OVERLAY, NUMBER INTERVAL=12, TIME MARKS=NO
Pour vérifier l'information complète sur le redémarrage
 egrep -i "step|restart" testet*.com testet*.msg testet*.sta

</tab>
<tab name="script de redémarrage pour le répertoire temporaire">
{{File
  |name="scriptet2.txt"
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-group    # specify account
#SBATCH --time=00-06:00        # days-hrs:mins
#SBATCH --mem=8000M            # node memory > 5G
#SBATCH --cpus-per-task=4      # number cores > 1
#SBATCH --nodes=1              # do not change

module load StdEnv/2020
module load abaqus/2021

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"
echo "SLURM_SUBMIT_DIR =" $SLURM_SUBMIT_DIR
echo "SLURM_TMPDIR = " $SLURM_TMPDIR

rm -f testet2* testet1.lck
for f in testet1*; do cp -a "$f" $SLURM_TMPDIR/"testet2${f#testet1}"; done
cd $SLURM_TMPDIR
while sleep 3h; do
   cp -f * $SLURM_SUBMIT_DIR 2>/dev/null
done &
WPID=$!
abaqus job=testet2 input=$SLURM_SUBMIT_DIR/myexp-sim.inp recover \
   scratch=$SLURM_TMPDIR cpus=$SLURM_CPUS_ON_NODE interactive \
   mp_mode=threads memory="$((${SLURM_MEM_PER_NODE}-3072))MB"
{ kill $WPID && wait $WPID; } 2>/dev/null
cp -f  * $SLURM_SUBMIT_DIR
}}

Le fichier en entrée ne requiert aucune modification pour le redémarrage de l'analyse.

</tab>
</tabs>

<span id="Multiple_node_computing"></span>
=== Script pour nœuds multiples === 

{{File
  |name="scriptep1-mpi.txt"
  |lang="sh"
  |contents=
!/bin/bash
#SBATCH --account=def-group    # Specify account
#SBATCH --time=00-06:00        # Specify days-hrs:mins
#SBATCH --ntasks=8             # Specify number of cores
#SBATCH --mem-per-cpu=16000M   # Specify memory per core
# SBATCH --nodes=2             # Specify number of nodes (optional)
#SBATCH --cpus-per-task=1      # Do not change !

module load StdEnv/2020        # Latest installed version
module load abaqus/2021        # Latest installed version

unset SLURM_GTIDS
export MPI_IC_ORDER='tcp'
# uncomment next line when using abaqus/2021
export I_MPI_HYDRA_TOPOLIB=ipl
echo "LM_LICENSE_FILE=$LM_LICENSE_FILE"
echo "ABAQUSLM_LICENSE_FILE=$ABAQUSLM_LICENSE_FILE"

rm -f testep1-mpi*

unset hostlist
nodes="$(slurm_hl2hl.py --format MPIHOSTLIST {{!}} xargs)"
for i in `echo "$nodes" {{!}} xargs -n1 {{!}} uniq`; do hostlist=${hostlist}$(echo "['${i}',$(echo "$nodes" {{!}} xargs -n1 {{!}} grep $i {{!}} wc -l)],"); done
hostlist="$(echo "$hostlist" {{!}} sed 's/,$//g')"
mphostlist="mp_host_list=[$(echo "$hostlist")]"
export $mphostlist
echo "$mphostlist" > abaqus_v6.env

abaqus job=testep1-mpi input=myexp-sim.inp \
  scratch=$SLURM_TMPDIR cpus=$SLURM_NTASKS interactive mp_mode=mpi \
  #mp_host_split=1  # number of dmp processes per node >= 1 (uncomment to specify)
}}

<span id="Memory_estimates"></span>
== Estimer le besoin en termes de mémoire ==

<span id="Single_process"></span>
=== Processus simple ===

Une estimation de la mémoire totale pour un nœud  (--mem=) requise par Slurm pour qu'une simulation soit effectuée uniquement en mémoire vive (sans être virtualisée sur le disque scratch) se trouve dans le fichier de sortie Abaqus <code>test.dat</code>. Dans l'exemple suivant, la simulation exige une assez grande quantité de mémoire.

<source lang="bash">
                   M E M O R Y   E S T I M A T E
  
 PROCESS      FLOATING PT       MINIMUM MEMORY        MEMORY TO
              OPERATIONS           REQUIRED          MINIMIZE I/O
             PER ITERATION           (MB)               (MB)
  
     1          1.89E+14             3612              96345
</source>

Alternativement, l'estimation de la mémoire totale pour un processus avec fils sur un nœud unique peut être obtenue en exécutant la simulation de manière interactive sur un nœud de calcul, puis en surveillant la consommation de mémoire à l'aide des commandes <code>ps</code> ou <code>top</code>. Ce qui suit décrit comment procéder dans le dernier cas&nbsp;:<br>
1) Connectez-vous à une grappe aevec SSH et obtenez une allocation sur un nœud de calcul (comme gra100) et démarrez votre simulationavec&nbsp;:

{{Commands
|salloc --time=0:30:00 --cpus-per-task=8 --mem=64G --account=def-piname
|module load StdEnv/2020
|module load abaqus/2021
|unset SLURM_GTIDS
|abaqus job=test input=Sample.inp scratch=$SLURM_TMPDIR cpus=8 mp_mode=threads interactive
}}

2) via SSH, connectez-vous de nouveau à la grappe réservée par salloc puis au nœud de calcul et lancez top.

{{Commands|ssh gra100
|top -u $USER}}

3) observez les colonnes VIRT and RES jusqu'à ce que des valeurs de mémoire maximales stables soient atteintes.

Pour satisfaire complètement la valeur recommandée pour <code>MEMORY TO OPERATIONS REQUIRED MINIMIZE I/O</code> (MRMIO), au moins la même quantité de mémoire physique non échangée (RES) doit être disponible pour Abaqus. Étant donné que la RES sera en général inférieure à la mémoire virtuelle (VIRT) d'une quantité relativement constante pour une simulation donnée, il est nécessaire de surallouer légèrement la mémoire du nœud demandée <code>-mem=</code>. Dans l'exemple de script ci-dessus, cette surallocation a été codée en dur à une valeur prudente de 3072Mo sur la base des tests initiaux du solveur Abaqus standard. Pour éviter les longs temps d'attente associés aux valeurs élevées de MRMIO, il peut être utile d'étudier l'impact sur les performances de simulation associées à la réduction de la mémoire RES mise à disposition d'Abaqus de manière significative en dessous de la MRMIO. Cela peut être fait en diminuant la valeur de <code>-mem=</code> qui à son tour définira une valeur artificiellement basse de <code>memory=</code> dans la commande Abaqus (trouvée dans la dernière ligne du script). En faisant cela, il faut s'asssurer que RES ne descende pas en dessous de <code>MINIMUM MEMORY REQUIRED</code> (MMR) sinon Abaqus fermera à cause d'une mémoire insuffisante (OOM). Par exemple, si votre MRMIO est de 96Go, essayez d'exécuter une série de tâches de test courtes avec <code>#SBATCH --mem=8G, 16G, 32G, 64G</code> jusqu'à ce qu'un impact minimal acceptable sur les performances soit trouvé, en notant que des valeurs plus petites entraîneront un espace /scratch de plus en plus grand pour les fichiers temporaires.

<span id="Multi_process"></span>
=== Processus multiples ===

Pour déterminer la mémoire requise pour les scripts qui utilisent plusieurs nœuds, les estimations de mémoire (par processus de calcul) requises pour minimiser les entrées/sorties sont données dans le fichier de sortie dat pour les tâches terminées. Si <code>mp_host_split</code> n'est pas spécifié (ou est défini comme étant 1), le nombre total de processus de calcul sera égal au nombre de nœuds. La valeur de <code>mem-per-cpu</code> peut alors être déterminée approximativement en multipliant la plus grande estimation de mémoire par le nombre de nœuds, puis en divisant par le nombre de <code>ntasks</code>. Si toutefois la valeur de <code>mp_host_split</code> est spécifiée (supérieure à 1), la valeur de <code>mem-per-cpu</code> peut être déterminée approximativement à partir de la plus grande estimation de mémoire multipliée par le nombre de nœuds, multiplié par la valeur de <code>mp_host_split</code> divisée par le nombre de tâches. Notez que la valeur de <code>mp_host_split</code> doit être inférieure ou égale au nombre de cœurs par nœud attribué par au moment de l'exécution, sinon Abaqus s'arrêtera. Ce scénario peut être contrôlé en supprimant les commentaires pour spécifier une valeur pour les tâches par nœud. L'énoncé définitif suivant est donné dans chaque fichier dat et mentionné ici pour référence.

 LE MAXIMUM DE MÉMOIRE POUVANT ÊTRE ALLOUÉ PAR ABAQUS DÉPEND EN GÉNÉRAL DE LA VALEUR DU
PARAMÈTRE <CODE>MÉMOIRE</CODE> ET DE LA QUANTITÉ DE MÉMOIRE PHYSIQUE DISPONIBLE SUR LA MACHINE. VEUILLEZ CONSULTER
LE MANUEL D'UTILISATION D'ABAQUS ANALYSIS POUR PLUS DE DÉTAILS. L'UTILISATION RÉELLE DE LA MÉMOIRE ET DE L'ESPACE
DISQUE POUR LES DONNÉES DE /SCRATCH DÉPENDRA DE CETTE LIMITE SUPÉRIEURE AINSI QUE DE LA MÉMOIRE REQUISE POUR
MINIMISER LES ENTRÉES/SORTIES. SI LA LIMITE SUPÉRIEURE DE MÉMOIRE EST SUPÉRIEURE À LA MÉMOIRE REQUISE POUR MINIMISER LES ENTRÉES/SORTIES, L'UTILISATION RÉELLE DE LA MÉMOIRE SERA PROCHE DE LA VALEUR ESTIMÉE DE <CODE>MEMORY TO MINIMIZE I/O</CODE> ET L'UTILISATION DU DISQUE DE TRAVAIL SERA PROCHE DE ZÉRO. AUTREMENT, LA MÉMOIRE RÉELLE UTILISÉE SERA PROCHE DE LA LIMITE DE MÉMOIRE
MENTIONNÉE PRÉCÉDEMMENT, ET L'UTILISATION DU DISQUE /SCRATCH SERA À PEU PRÈS PROPORTIONNELLE À LA DIFFÉRENCE
ENTRE <CODE>MEMORY TO MINIMIZE I/O</CODE> ESTIMÉE ET LA LIMITE SUPÉRIEURE DE LA MÉMOIRE. TOUTEFOIS, IL EST IMPOSSIBLE D'ÉVALUER AVEC PRÉCISION L'ESPACE /SCRATCH DU DISQUE.

= Mode graphique =
Abaqus peut être utilisé interactivement en mode graphique sur une grappe ou sur gra-vdi avec VCN.

== Sur une grappe ==
1. [[VNC/fr#Nœuds_de_calcul|Connectez-vous à un nœud de calcul (durée maximale 3 heures) avec TigerVNC]].<br>
2. Ouvrez une nouvelle fenêtre de terminal et entrez
 module load StdEnv/2020 abaqus/2021
3. Lancez l'application avec<br>
 abaqus cae -mesa

<span id="On_demand"></span>
<div class="mw-translate-fuzzy">
== Sur gra-vdi ==
1. [[VNC/fr#Nœuds_VDI|Connectez-vous à un nœud VDI (durée maximale 24 heures) avec TigerVNC]].<br>
2. Ouvrez une nouvelle fenêtre de terminal et entrez un des énoncés suivants&nbsp;:
 module load StdEnv/2016 abaqus/6.14.1 ou
 module load StdEnv/2016 abaqus/2020 ou 
 module load StdEnv/2020 abaqus/2021
3. Lancez l'application avec<br>
 abaqus cae
</div>

To run abaqus interactively in a gui desktop do the following :

1. Connect to the following url from your laptop browser<br>
 <code>ondemand.sharcnet.ca</code>
2. Open a new terminal window and enter one of the following:
 module load StdEnv/2020 abaqus/2021
3. Start the application in graphical mode:<br>
 abaqus cae

Note that a module for <code>abaqus/2025</code> is in the process of being installed and when its ready will appear as an option in the above 3 steps showing how to optionally load it instead.

== On gra-vdi ==

IMPORTANT:  Gra-vdi will be permanently shutdown very soon, so use of it should be discontinued.  Instead you may use the new Ondemand system as described in the section above.

1. Connect to gra-vdi with [[VNC#VDI_nodes|TigerVNC]]<br><br>
2. Open a new terminal window and enter one of the following:
 module load CcEnv StdEnv/2016 abaqus/6.14.1 or
 module load CcEnv StdEnv/2016 abaqus/2020 or
 module load CcEnv StdEnv/2020 abaqus/2021
3. Start the application with<br>
 abaqus cae

Pour qu'Abaqus puisse démarrer en mode graphique, il faut au moins une licence CAE libre (non utilisée). La licence SHARCNET comporte 2 licences libres et 2 licences réservées. Si les 4 sont utilisées selon

 [gra-vdi3:~] abaqus licensing lmstat -c $ABAQUSLM_LICENSE_FILE -a | grep "Users of cae"
 Users of cae:  (Total of 4 licenses issued;  Total of 4 licenses in use)

Les messages d'erreur suivants seront affichés quand vous tenterez de lancer Abaqus cae&nbsp;:

 [gra-vdi3:~] abaqus cae
 ABAQUSLM_LICENSE_FILE=27050@license3.sharcnet.ca
 /opt/sharcnet/abaqus/2020/Commands/abaqus cae
 No socket connection to license server manager.
 Feature:       cae
 License path:  27050@license3.sharcnet.ca:
 FLEXnet Licensing error:-7,96
 For further information, refer to the FLEXnet Licensing documentation,
 or contact your local Abaqus representative.
 Number of requested licenses: 1
 Number of total licenses:     4
 Number of licenses in use:    2
 Number of available licenses: 2
 Abaqus Error: Abaqus/CAE Kernel exited with an error.

= Site-specific use =
== SHARCNET license == 
The SHARCNET license has been renewed until 17-jan-2026.  It provides a small but free license consisting of 2 cae and 35 execute tokens where usage limits are imposed 10 tokens/user and 15 tokens/group.  For groups that have purchased dedicated tokens, the free token usage limits are added to their reservation.  The free tokens are available on a first come first serve basis and mainly intended for testing and light usage before deciding whether or not to purchase dedicated tokens.  Costs for dedicated tokens (in 2021) were approximately CAD$110 per compute token and CAD$400 per GUI token: submit a ticket to request an official quote.  The license can be used by any Alliance researcher, but only on SHARCNET hardware.  Groups that purchase dedicated tokens to run on the SHARCNET license server may likewise only use them on SHARCNET hardware including gra-vdi (for running Abaqus in full graphical mode) and Graham or Dusky clusters (for submitting compute batch jobs to the queue).  Before you can use the license, you must contact [[technical support]] and request access.  In your email 1) mention that it is for use on SHARCNET systems and 2) include a copy/paste of the following <code>License Agreement</code> statement with your full name and username entered in the indicated locations.  Please note that every user must do this it cannot be done one time only for a group; this includes PIs who have purchased their own dedicated tokens.

===Entente===
<pre>----------------------------------------------------------------------------------
Subject: Abaqus SHARCNET Academic License User Agreement

This email is to confirm that i "_____________" with username "___________" will
only use “SIMULIA Academic Software” with tokens from the SHARCNET license server
for the following purposes:

1) on SHARCNET hardware where the software is already installed
2) in affiliation with a Canadian degree-granting academic institution
3) for education, institutional or instruction purposes and not for any commercial
   or contract-related purposes where results are not publishable
4) for experimental, theoretical and/or digital research work, undertaken primarily
   to acquire new knowledge of the underlying foundations of phenomena and observable
   facts, up to the point of proof-of-concept in a laboratory    
-----------------------------------------------------------------------------------</pre>

=== Configurer le fichier de licence ===
Configurez votre fichier de licence comme suit (pour utilisation uniquement sur les systèmes SHARCNET Graham, gra-vdi et Dusky).
<source lang="bash">
[gra-login1:~] cat ~/.licenses/abaqus.lic
prepend_path("LM_LICENSE_FILE","27050@license3.sharcnet.ca")
prepend_path("ABAQUSLM_LICENSE_FILE","27050@license3.sharcnet.ca")
</source>

Si vos tâches se terminent anormalement et que le fichier de sortie de l'ordonnanceur contient le message d'erreur ''*** ABAQUS/eliT_CheckLicense rank 0 terminated by signal 11 (Segmentation fault)'', vérifiez si votre fichier  <code>abaqus.lic</code> contient  ''ABAQUSLM_LICENSE_FILE'' pour Abaqus/2020. 
Si le fichier de sortie contient ''License server machine is down or not responding etc.'',  vérifiez si le fichier <code>abaqus.lic</code> contient ''LM_LICENSE_FILE'' pour Abaqus/6.14.1, comme montré. Puisque le fichier <code>abaqus.lic</code> montré contient les deux énoncés, vous ne devriez pas avoir ce problème.

=== Interroger le serveur de licences===
Connectez-vous à Graham, chargez Abaqus et exécutez une des commandes suivantesnbsp;:
<source lang="bash">
ssh graham.alliancecan.ca
module load StdEnv/2020
module load abaqus
</source>

I) Vérifiez s'il y a des tâches lancées et des tâches dans la queue pour le serveur de licence SHARCNET.
<source lang="bash">
abaqus licensing lmstat -c $LM_LICENSE_FILE -a | egrep "Users|start|queued"
</source>
II)  Vérifiez s'il y a des tâches lancées et des tâches dans la queue pour le serveur de licence SHARCNET et s'il indique des réservations de produits par groupe d'acquisition.
<source lang="bash">
abaqus licensing lmstat -c $LM_LICENSE_FILE -a | egrep "Users|start|queued|RESERVATION"
</source>
III)  Vérifiez si le serveur de licences SHARCNET montre une disponibilité pour le produit cae standard et explicite.
<source lang="bash">
abaqus licensing lmstat -c $LM_LICENSE_FILE -a | grep "Users of" | egrep "cae|standard|explicit"
</source>

<!--T:94-->
When the output of query I) above indicates that a job for a particular username is queued this means the job has entered the "R"unning state from the perspective of <code>squeue -j jobid</code> or <code>sacct -j jobid</code> and is therefore idle on a compute node waiting for a license.  This will have the same impact on your account priority as if the job were performing computations and consuming CPU time.  Eventually when sufficient licenses come available the queued job will start.

==== Example ==== <!--T:95-->

<!--T:96-->
The following shows the situation where a user submitted two 6-core jobs (each requiring 12 tokens) in quick succession.  The scheduler then started each job on a different node in the order they were submitted.  Since the user had 10 Abaqus compute tokens, the first job (27527287) was able to acquire exactly enough (10) tokens for the solver to begin running.  The second job (27527297) not having access to any more tokens entered an idle "queued" state (as can be seen from the lmstat output) until the first job completed, wasting the available resources and depreciating the user's fair share level in the process ...

 [roberpj@gra-login1:~] sq
            JOBID     USER              ACCOUNT           NAME  ST  TIME_LEFT NODES CPUS TRES_PER_N MIN_MEM NODELIST (REASON) 
         27530366  roberpj         cc-debug_cpu  scriptsp2.txt   R    9:56:13     1    6        N/A      8G gra107 (None) 
         27530407  roberpj         cc-debug_cpu  scriptsp2.txt   R    9:59:37     1    6        N/A      8G gra292 (None) 

 [roberpj@gra-login1:~] abaqus licensing lmstat -c $LM_LICENSE_FILE -a | egrep "Users|start|queued"
 Users of abaqus:  (Total of 78 licenses issued;  Total of 53 licenses in use)
    roberpj gra107 /dev/tty (v62.6) (license3.sharcnet.ca/27050 1042), start Mon 11/25 17:15, 10 licenses
    roberpj gra292 /dev/tty (v62.6) (license3.sharcnet.ca/27050 125) queued for 10 licenses

<!--T:97-->
To avoid license shortage problems when submitting multiple jobs when working with expensive Abaqus tokens either use a [https://docs.alliancecan.ca/wiki/Running_jobs#Cancellation_of_jobs_with_dependency_conditions_which_cannot_be_met job dependency], [https://docs.alliancecan.ca/wiki/Job_arrays job array] or at the very least set up a slurm [https://docs.alliancecan.ca/wiki/Running_jobs#Email_notification email notification] to know when your job completes before manually submitting another one.

=== Indiquer les ressources pour la tâche ===
Pour garantir une utilisation optimale de vos jetons Abaqus et de nos ressources, il est important de bien spécifier la mémoire et le ncpus requis dans votre script Slurm. Les valeurs peuvent être obtenues en soumettant quelques courtes tâches de test à la file d'attente, puis en vérifiant leur utilisation. Pour les tâches <b>terminées</b>, utilisez <code>seff JobNumber</code> pour afficher la <i>mémoire utilisée</i> totale et l'<i>efficacité de la mémoire</i>. Si l'<i>efficacité de la mémoire</i> est inférieure à environ 90%, diminuez la valeur du paramètre <code>#SBATCH --mem=</code> dans votre script Slurm. Notez que la commande <code>seff JobNumber</code> affiche également le total du <i>CPU (temps) utilisé</i> et l'<i>efficacité du processeur</i>. Si l'efficacité du processeur est inférieure à environ 90%, effectuez des tests de mise à l'échelle pour déterminer le nombre optimal de processeurs pour des performances optimales, puis mettez à jour la valeur de <code>#SBATCH --cpus-per-task=</code> dans votre script Slurm. Pour les tâches en cours d'exécution, utilisez la commande <code>srun --jobid=29821580 --pty top -d 5 -u $USER</code> pour surveiller le %CPU, le %MEM et le RES pour chaque processus parent Abaqus sur le nœud de calcul. Les colonnes %CPU et %MEM affichent le pourcentage d'utilisation par rapport au total disponible sur le nœud tandis que la colonne RES affiche la taille de la mémoire résidente par processus (dans un format facilement lisible pour les valeurs supérieures à 1 Go). De plus amples informations sur la manière de [[Running jobs#Monitoring_jobs|surveiller les tâches]] sont disponibles sur notre wiki de documentation

<span id="Core_token_mapping"></span>
=== Correspondance cœur-jeton ===
<pre>
TOKENS 5  6  7  8  10  12  14  16  19  21  25  28  34  38
CORES  1  2  3  4   6   8  12  16  24  32  48  64  96 128
</pre>

où TOKENS = floor[5 X CORES^0.422]

Chaque GPU nécessite un jeton additionnel.

== Licence Western ==
La licence de site Western ne peut être utilisée que par les chercheuses et chercheurs de Western sur le matériel situé sur le campus de Western. Présentement, la grappe Dusky est la seule qui satisfait ces conditions. Graham et gra-vdi sont exclus car ils sont situés sur le campus de Waterloo. Contactez l'administrateur du serveur de licences Western Abaqus <jmilner@robarts.ca> pour vous renseigner sur l'utilisation de la licence Western. Vous devrez fournir votre nom d'utilisateur et éventuellement prendre des dispositions pour acheter des jetons. Si l'accès vous est accordé, vous pouvez procéder à la configuration de votre fichier <code>abaqus.lic</code> pour qu'il pointe vers le serveur de licences Western comme suit&nbsp;:

===Configurer le fichier de licences===
Configurez votre fichier de licence comme suit (pour utilisation uniquement sur Dusky).

<source lang="bash">
[dus241:~] cat .licenses/abaqus.lic
prepend_path("LM_LICENSE_FILE","27000@license4.sharcnet.ca")
prepend_path("ABAQUSLM_LICENSE_FILE","27000@license4.sharcnet.ca")
</source>
Par la suite, soumettez votre tâche tel que décrit à la section <i>Soumettre une tâche sur une grappe</i> ci-dessus. Si un problème survient, écrivez au [[Technical support/fr|soutien technique]] en indiquant que vous utilisez la licence du site Western sur Dusky. Ajoutez le numéro de la tâche qui pose problème et copiez le ou les messages d'erreur s'il y a lieu.

= Documentation en ligne =
Vous pouvez consulter la documentation pour la plus récente version sur gra-vdi comme suit&nbsp;:

Préparation de votre compte
# [[VNC/fr#Nœuds_VDI|Connectez-vous à <b>gra-vdi.com</b> avec TigerVNC]].
# Sur gra-vdi, ouvrez une fenêtre de terminal et entrez <code>firefox</code> (appuyez sur Entrée).
# Dans la barre d'adresse, entrez <code>about:config</code> (appuyez sur Entrée) -> cliquez sur le bouton <i>I accept the risk</i>.
# Dans la barre de recherche, entrez <code>unique</code> et double-cliquez sur <code>privacy.file_unique_origin</code> pour changer <i>true'</i> en <i>false</i>. 

Afficher la documentation
# [[VNC/fr#Nœuds_VDI|Connectez-vous à <b>gra-vdi.com</b> avec TigerVNC]].
# Sur gra-vdi, ouvrez une fenêtre de terminal et entrez <code>firefox</code> (appuyez sur Entrée).
# Dans la barre de recherche, copiez-collez un des énoncés suivants&nbsp;: <br><code>file:///opt/sharcnet/abaqus/2020/doc/English/DSSIMULIA_Established.htm</code>, ou<br><code>file:///opt/sharcnet/abaqus/2021/doc/English/DSSIMULIA_Established.htm</code>
# Cliquez sur un sujet, par exemple <i>Abaqus -> Analysis -> Analysis Techniques -> Analysis Continuation Techniques</i>.