[
  {
    "question": "What is the status of P100 GPUs on Graham?",
    "answer": "P100 GPUs have been decommissioned and are no longer available on Graham."
  },
  {
    "question": "How does the performance of V100 GPUs compare to P100 GPUs for different workloads?",
    "answer": "V100 GPUs offer about double the performance for standard computation and approximately 8X performance for deep learning computations utilizing their tensor core units, compared to P100 GPUs."
  },
  {
    "question": "What are the characteristics of T4 Turing GPUs, particularly regarding double precision and deep learning?",
    "answer": "T4 Turing GPUs are targeted specifically at deep learning workloads, supporting good performance for single precision, featuring tensor cores, and supporting reduced precision integer calculations. However, they do not support efficient double precision computations."
  },
  {
    "question": "Are Pascal GPU nodes still available on Graham?",
    "answer": "No, Pascal GPU nodes are no longer available on Graham."
  },
  {
    "question": "How many Volta GPU nodes does Graham have and what type of interconnect do they use?",
    "answer": "Graham has a total of 2 Volta nodes, and they use high bandwidth NVLINK interconnect."
  },
  {
    "question": "What is the maximum job duration allowed on Volta GPU nodes?",
    "answer": "The maximum job duration for jobs on Volta GPU nodes is seven days."
  },
  {
    "question": "What is the recommended CPU-to-GPU ratio for 28-core Volta nodes?",
    "answer": "For 28-core Volta nodes, the recommended CPU-to-GPU ratio should be 3.5 or less. For example, if using 4 GPUs, request at most 14 CPU cores; for 1 GPU, request at most 3 CPU cores."
  },
  {
    "question": "Can test jobs on Volta nodes disregard the recommended CPU-to-GPU ratio?",
    "answer": "Yes, users are allowed to run a few short test jobs (shorter than 1 hour) that break the recommended CPU-to-GPU ratio to evaluate code performance."
  },
  {
    "question": "What is the recommended CPU-to-GPU ratio for the newest 40-core Volta nodes?",
    "answer": "For the two newest Volta nodes with 40 cores, you can use 5 CPU cores per GPU."
  },
  {
    "question": "How do you request a specific NVLINK Volta node with 40 cores for a job?",
    "answer": "To request one of the NVLINK Volta nodes with 40 cores, you should add the `--constraint=cascade,v100` parameter to your job submission script."
  },
  {
    "question": "How should the fast local disk on Volta nodes be utilized for I/O intensive jobs?",
    "answer": "For I/O intensive jobs, use the fast local disk by copying input files to the temporary directory specified by the `$SLURM_TMPDIR` environment variable at the start of the job, and copying output files out at the end. All files in `$SLURM_TMPDIR` are removed once the job finishes."
  },
  {
    "question": "Can Python virtual environments be created in the temporary space on Volta nodes?",
    "answer": "Yes, Python virtual environments can be created in the temporary space specified by `$SLURM_TMPDIR` for greater efficiency."
  },
  {
    "question": "How do you specify the request for Turing GPU nodes in a job script?",
    "answer": "When requesting Turing GPU nodes, you should specify `--gres=gpu:t4:2` (for two T4 cards per node) or adjust the number as needed."
  },
  {
    "question": "How do you specify the request for Ampere GPU nodes in a job script?",
    "answer": "When requesting Ampere GPU nodes, you should specify `--gres=gpu:a100:2` or `--gres=gpu:a5000:2` (for two Ampere cards per node) or adjust the number as needed."
  },
  {
    "question": "When will the Graham cluster's capacity be reduced, and to what level?",
    "answer": "Starting January 13, 2025, the Graham cluster will operate at approximately 25% capacity until the new Nibi system comes online."
  }
]