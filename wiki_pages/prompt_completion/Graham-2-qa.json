[
  {
    "question": "Which GPU type on Graham has been decommissioned?",
    "answer": "P100 GPUs have been decommissioned."
  },
  {
    "question": "How does V100 GPU performance compare to P100 for standard and deep learning computations?",
    "answer": "V100 offers about double the performance for standard computation and about 8X performance for deep learning computations (utilizing tensor cores) compared to P100."
  },
  {
    "question": "What are the key characteristics of T4 Turing GPUs on Graham?",
    "answer": "T4 Turing GPUs are targeted for deep learning workloads, do not support efficient double precision computations, but have good performance for single precision, include tensor cores, and support reduced precision integer calculations."
  },
  {
    "question": "Are Pascal GPU nodes still available on Graham?",
    "answer": "No, Pascal GPU nodes are no longer available."
  },
  {
    "question": "How many Volta GPU nodes are available on Graham?",
    "answer": "Graham has a total of 2 Volta nodes."
  },
  {
    "question": "What is the maximum job duration for Volta GPU nodes on Graham?",
    "answer": "The maximum job duration for Volta nodes is seven days."
  },
  {
    "question": "What is the recommended CPU to GPU ratio for 28-core Volta nodes?",
    "answer": "You should keep the ratio of CPUs to GPUs at 3.5 or less on 28-core Volta nodes."
  },
  {
    "question": "How many CPU cores should be requested for a job using 1 GPU on a 28-core Volta node?",
    "answer": "For a job with 1 GPU on a 28-core Volta node, you should request at most 3 CPU cores."
  },
  {
    "question": "How many CPU cores can be used per GPU on the newer 40-core Volta nodes?",
    "answer": "On the two newest Volta nodes with 40 cores, you can use 5 CPU cores per GPU."
  },
  {
    "question": "How can users specifically request the newer Volta nodes with NVLINK interconnect?",
    "answer": "To use one of these NVLINK nodes, you should request it directly by adding the `--constraint=cascade,v100` parameter to the job submission script."
  },
  {
    "question": "How should the fast local disk on Volta nodes be utilized for I/O-intensive jobs?",
    "answer": "For I/O-intensive jobs, use the temporary directory specified by the environment variable `$SLURM_TMPDIR` on the fast local disk, copying input files at the start and output files at the end of the job script."
  },
  {
    "question": "How do you request two T4 Turing GPU cards for a job on Graham?",
    "answer": "When requesting Turing nodes, you should specify `--gres=gpu:t4:2` for two T4 cards per node."
  },
  {
    "question": "How do you request two A100 Ampere GPU cards for a job on Graham?",
    "answer": "When requesting Ampere nodes, you should specify `--gres=gpu:a100:2` for two A100 cards per node."
  },
  {
    "question": "How do you request two A5000 Ampere GPU cards for a job on Graham?",
    "answer": "When requesting Ampere nodes, you should specify `--gres=gpu:a5000:2` for two A5000 cards per node."
  },
  {
    "question": "When will Graham's cluster capacity be reduced and by how much?",
    "answer": "Starting January 13, 2025, the Graham cluster will operate at approximately 25% capacity."
  }
]