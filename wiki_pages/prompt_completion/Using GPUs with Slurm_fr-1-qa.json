[
  {
    "question": "How do you request one or more GPUs for a task?",
    "answer": "You can request GPUs by using the option `--gpus-per-node=[type:]number`."
  },
  {
    "question": "What is the syntax for requesting a specific number of GPUs per node without specifying a type?",
    "answer": "You can use `--gpus-per-node=number`, for example, `--gpus-per-node=2` to request two GPUs per node."
  },
  {
    "question": "How do you request one V100 GPU per node?",
    "answer": "You can request one V100 GPU per node using `--gpus-per-node=v100:1`."
  },
  {
    "question": "Which GPU request directive is recommended for future Slurm versions?",
    "answer": "The `--gpus-per-node` directive is recommended as `--gres` may not be supported in upcoming Slurm versions."
  },
  {
    "question": "What are some other Slurm directives that can be used to request GPUs?",
    "answer": "Other directives include `--gpus`, `--gpus-per-socket`, `--gpus-per-task`, `--mem-per-gpu`, and `--ntasks-per-gpu`."
  },
  {
    "question": "Where can users find general information about task scheduling?",
    "answer": "Users can consult [[Running jobs/fr|Ex\u00e9cuter des t\u00e2ches]] for general information on task scheduling."
  },
  {
    "question": "Which GPU models are available on the Fir cluster?",
    "answer": "The Fir cluster has H100-80gb GPU models."
  },
  {
    "question": "What is the Compute Capability of the A100-40gb GPU on Narval?",
    "answer": "The A100-40gb GPU on Narval has a Compute Capability of 80."
  },
  {
    "question": "Which GPU models are available on the Nibi cluster?",
    "answer": "The Nibi cluster offers H100-80gb and MI300A-128gb GPU models."
  },
  {
    "question": "What is a notable feature of the MI300A-128gb GPU?",
    "answer": "The MI300A-128gb GPU features unified memory between the CPU and GPU."
  },
  {
    "question": "What is the purpose of 'Compute Capability'?",
    "answer": "'Compute Capability' is an NVIDIA term indicating hardware-specific features of a GPU, useful for compiling custom GPU programs, and not related to performance."
  },
  {
    "question": "Are GPU resources scheduled on the Arbutus cluster?",
    "answer": "No, GPU resources on the Arbutus cluster, which are cloud resources, are not scheduled."
  },
  {
    "question": "What is Multi-Instance GPU (MIG) technology?",
    "answer": "MIG technology allows partitioning a GPU into multiple instances."
  },
  {
    "question": "If you encounter issues when requesting GPUs, who should you contact?",
    "answer": "If you do not obtain the desired result, you should contact the technical support team."
  }
]