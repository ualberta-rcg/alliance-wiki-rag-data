[
  {
    "question": "How should the CIFAR10 dataset be handled if it's not already stored locally when running a TensorFlow script?",
    "answer": "The script will try to download the CIFAR10 dataset from the internet. If it's not in `~/.keras/datasets`, you should either run the download line on a login node before submitting the job, or manually download the `cifar-10-python.tar.gz` file from `https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz`, rename it to `cifar-10-batches-py.tar.gz`, and place it in `~/.keras/datasets`."
  },
  {
    "question": "What is the primary difference in TensorFlow strategies when moving from single-node to multi-node distributed GPU usage?",
    "answer": "The main difference is the use of `MultiWorkerMirroredStrategy()` for multiple nodes, as opposed to `MirroredStrategy()` for a single node."
  },
  {
    "question": "How does TensorFlow obtain cluster information for multi-node tasks using the `MultiWorkerMirroredStrategy`?",
    "answer": "It uses `tf.distribute.cluster_resolver.SlurmClusterResolver()` to retrieve task information from Slurm, avoiding manual assignment of primary and secondary nodes."
  },
  {
    "question": "Which communication backend is explicitly configured for inter-GPU communication in the multi-node `MultiWorkerMirroredStrategy`?",
    "answer": "The NCCL library from NVIDIA is used for inter-GPU communication, indicated by `CommunicationImplementation.NCCL` in the `CommunicationOptions`."
  },
  {
    "question": "What are the SLURM resource requests specified in the `tensorflow-multiworker.sh` script for a multi-node job?",
    "answer": "The script requests 2 nodes (`--nodes 2`), 2 GPUs per node (`--gres=gpu:2`), 2 tasks per node (`--ntasks-per-node=2`), 8GB of memory (`--mem=8G`), and a time limit of 30 minutes (`--time=0-00:30`)."
  },
  {
    "question": "What is the role of the `config_env.sh` script in a multi-node TensorFlow setup?",
    "answer": "The `config_env.sh` script is responsible for loading the Python module, creating a virtual environment in `$SLURM_TMPDIR/ENV`, activating it, upgrading pip, and installing TensorFlow without an index."
  },
  {
    "question": "How is the `launch_training.sh` script executed in the multi-node TensorFlow example?",
    "answer": "The `launch_training.sh` script is executed via `srun launch_training.sh` after the environment setup, and it then activates the virtual environment and runs the `tensorflow-multiworker.py` Python script."
  },
  {
    "question": "What environment variable can be set to enable the NCCL backend for inter-GPU communication?",
    "answer": "The environment variable `NCCL_BLOCKING_WAIT` should be set to `1` (e.g., `export NCCL_BLOCKING_WAIT=1`)."
  },
  {
    "question": "How is the `MultiWorkerMirroredStrategy` instantiated in the `tensorflow-multiworker.py` script?",
    "answer": "It is instantiated as `tf.distribute.MultiWorkerMirroredStrategy(cluster_resolver=cluster_config, communication_options=comm_options)`, where `cluster_config` is a `SlurmClusterResolver` and `comm_options` specifies `CommunicationImplementation.NCCL`."
  },
  {
    "question": "What is the purpose of setting `XLA_FLAGS` in the `tensorflow-multiworker.sh` script?",
    "answer": "The `XLA_FLAGS` environment variable is set to `--xla_gpu_cuda_data_dir=$CUDA_HOME`, likely to specify the CUDA installation directory for XLA GPU operations."
  }
]