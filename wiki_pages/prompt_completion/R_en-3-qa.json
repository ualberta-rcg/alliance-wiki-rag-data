[
  {
    "question": "What R programming practices are recommended to improve performance, especially when dealing with loops?",
    "answer": "You should try to use vectorized forms of R functions and more functional elements like the `apply` functions and the `ifelse` function, as loops (especially nested ones) are a significant performance bottleneck."
  },
  {
    "question": "Why is vectorization often preferred over parallelizing loops in R for performance gains?",
    "answer": "Vectorization frequently offers a far better performance gain by eliminating a loop altogether instead of simply parallelizing the (slow) execution of that loop across several CPU cores."
  },
  {
    "question": "Where can one find information on R packages for high-performance and parallel computing?",
    "answer": "The CRAN Task View on High-Performance and Parallel Computing with R describes a collection of interrelated R packages for parallel computing."
  },
  {
    "question": "Is there a recommended resource for an overview of High-Performance R?",
    "answer": "Yes, the October 2023 Compute Ontario colloquium 'High-Performance R' (with available slides) offers an excellent overview and advice."
  },
  {
    "question": "How does the term 'node' differ in general documentation compared to R documentation like the `snow` package?",
    "answer": "In most general documentation, 'node' refers to an individual machine or host, while in a lot of R documentation (e.g., `snow`), 'node' refers to a worker process."
  },
  {
    "question": "What is `foreach` in the context of R parallel computing?",
    "answer": "`foreach` can be considered a unified interface for various backends such as `doMC`, `doMPI`, `doParallel`, and `doRedis`."
  },
  {
    "question": "What is the function of the `doParallel` package?",
    "answer": "`doParallel` acts as an interface between `foreach` and the `parallel` package."
  },
  {
    "question": "Are there any known efficiency issues when using `foreach`?",
    "answer": "Yes, there are known efficiency issues when using `foreach` to run a very large number of very small tasks."
  },
  {
    "question": "What happens if the backend for `foreach` is not registered with the number of cores?",
    "answer": "If the backend is not registered, `foreach` will assume that the number of cores is 1 and will proceed to go through the iterations serially."
  },
  {
    "question": "What are the general steps to use `foreach` for parallel execution?",
    "answer": "The general method is to load both `foreach` and the backend package, register the backend, and call `foreach()` by keeping it on the same line as the `%do%` (serial) or `%dopar%` operator."
  },
  {
    "question": "How is the number of cores typically set for `doParallel` in a SLURM environment, according to the example?",
    "answer": "The number of cores (`ncores`) is typically set using the `SLURM_CPUS_PER_TASK` environment variable, accessed via `Sys.getenv(\"SLURM_CPUS_PER_TASK\")`."
  },
  {
    "question": "Which R function is used to register the parallel backend with a specified number of cores in the `doParallel` example?",
    "answer": "`registerDoParallel(cores=ncores)` is used to register the parallel backend."
  },
  {
    "question": "What is a crucial syntax requirement for `foreach()` and `%dopar%` when used together?",
    "answer": "The `foreach()` call and the `%dopar%` operator must be on the same line."
  },
  {
    "question": "What SLURM parameters are included in the `job_foreach.sh` script for a basic `doParallel` job?",
    "answer": "The script includes `#SBATCH --account=def-someacct`, `#SBATCH --nodes=1`, `#SBATCH --cpus-per-task=4`, `#SBATCH --mem-per-cpu=2000M`, and `#SBATCH --time=0-00:15`."
  },
  {
    "question": "How is an R script (`test_foreach.R`) executed non-interactively within a SLURM batch job (`job_foreach.sh`)?",
    "answer": "It is executed using the command `R CMD BATCH --no-save --no-restore test_foreach.R`."
  },
  {
    "question": "How do you submit the `job_foreach.sh` script to the job scheduler?",
    "answer": "You submit the job using the command `sbatch job_foreach.sh`."
  },
  {
    "question": "When using `doParallel` with `makeCluster`, how should the backend be registered for multiple processes across nodes?",
    "answer": "You must register the backend by feeding it the node names multiplied by the desired number of processes, such as `node1 node1 node2 node2` for two nodes with two processes each."
  },
  {
    "question": "What type of cluster in R's `makeCluster` runs commands via SSH connections into the nodes?",
    "answer": "The `PSOCK` cluster type will run commands through SSH connections into the nodes."
  },
  {
    "question": "How are node names obtained and prepared for `makeCluster` in the `test_makecluster.R` script example?",
    "answer": "Node names are created as an array from the `NODESLIST` environment variable by splitting `Sys.getenv(\"NODESLIST\", split=\" \")`."
  },
  {
    "question": "What R function is used to create a cluster with specific node names and a PSOCK type?",
    "answer": "`cl = makeCluster(nodeslist, type = \"PSOCK\")` is used to create the cluster."
  },
  {
    "question": "What R function should be called to release resources after a `makeCluster` job is complete?",
    "answer": "`stopCluster(cl)` should be called to release resources."
  },
  {
    "question": "How is the `NODESLIST` environment variable populated in the `job_makecluster.sh` script?",
    "answer": "It is populated by `export NODESLIST=$(echo $(srun hostname | cut -f 1 -d '.'))` which gets hostnames and cuts off the domain name."
  },
  {
    "question": "What SLURM parameter can be added to a `makeCluster` job script to ensure processes are distributed across different nodes?",
    "answer": "Adding the line `#SBATCH --ntasks-per-node=2` can help prove that the job works even if processes are placed on different nodes."
  },
  {
    "question": "On which cluster are the `Rmpi` instructions explicitly stated not to work?",
    "answer": "The `Rmpi` instructions do not work on the Cedar cluster."
  },
  {
    "question": "What is `Rmpi` and what does it facilitate?",
    "answer": "`Rmpi` is an interface (wrapper) to MPI routines which allows R to run in parallel."
  },
  {
    "question": "What modules should be loaded before attempting to install `Rmpi`?",
    "answer": "You should load `gcc`, an `r` module, and an `openmpi` module, for example: `module load gcc/11.3.0`, `module load r/4.2.1`, `module load openmpi/4.1.4`."
  },
  {
    "question": "How would you download the `Rmpi` package tarball for manual installation from CRAN?",
    "answer": "You would use `wget https://cran.r-project.org/src/contrib/Rmpi_0.6-9.2.tar.gz`, adjusting the version number as desired."
  },
  {
    "question": "What is the command to install `Rmpi` from a downloaded tarball, specifying MPI configuration arguments?",
    "answer": "The command is `R CMD INSTALL --configure-args=\"--with-Rmpi-include=$EBROOTOPENMPI/include --with-Rmpi-libpath=$EBROOTOPENMPI/lib --with-Rmpi-type='OPENMPI' \" Rmpi_0.6-9.2.tar.gz`."
  },
  {
    "question": "How is the `test.R` script executed within the `job.sh` submission script when using `Rmpi`?",
    "answer": "It is executed using `mpirun -np 1 R CMD BATCH test.R test.txt`."
  },
  {
    "question": "What SLURM parameter in the `job.sh` script defines the number of MPI processes for an `Rmpi` job?",
    "answer": "The `#SBATCH --ntasks=5` parameter defines the number of MPI processes."
  }
]