[
  {
    "question": "Qu'est-ce que CUDA ?",
    "answer": "CUDA est une plateforme de calcul parall\u00e8le et un mod\u00e8le de programmation d\u00e9velopp\u00e9 par NVIDIA pour des calculs g\u00e9n\u00e9raux utilisant le GPU. On peut le voir comme un ensemble de biblioth\u00e8ques et de compilateurs C, C++ et Fortran qui permettent de cr\u00e9er des programmes pour les GPU."
  },
  {
    "question": "Quel compilateur est utilis\u00e9 pour le code CUDA C/C++ ?",
    "answer": "Le compilateur CUDA C/C++ utilis\u00e9 est `nvcc`."
  },
  {
    "question": "Que faut-il faire avant de compiler du code CUDA ?",
    "answer": "Il faut charger le module CUDA en ex\u00e9cutant les commandes `$ module purge` suivi de `$ module load cuda`."
  },
  {
    "question": "Quel suffixe de fichier est important pour les fichiers source CUDA ?",
    "answer": "Le suffixe `cu` est important pour les fichiers source CUDA, par exemple `add.cu`."
  },
  {
    "question": "Comment compiler un programme CUDA nomm\u00e9 `add.cu` en un ex\u00e9cutable nomm\u00e9 `add` ?",
    "answer": "Utilisez la commande `nvcc add.cu -o add`."
  },
  {
    "question": "Comment soumettre une t\u00e2che CUDA avec Slurm ?",
    "answer": "Apr\u00e8s avoir cr\u00e9\u00e9 un script Slurm (par exemple `gpu_job.sh`), soumettez la t\u00e2che \u00e0 l'ordonnanceur avec la commande `$ sbatch gpu_job.sh`."
  },
  {
    "question": "Quel est le but de la directive Slurm `#SBATCH --gres=gpu:1` dans un script ?",
    "answer": "Cette directive sp\u00e9cifie le nombre de GPU (par n\u0153ud) \u00e0 allouer pour la t\u00e2che."
  },
  {
    "question": "Quel serait le r\u00e9sultat attendu de l'ex\u00e9cution du programme `add` via Slurm dans l'exemple donn\u00e9 ?",
    "answer": "Le fichier de sortie `slurm-3127733.out` afficherait `2+7=9`."
  },
  {
    "question": "Quel serait le r\u00e9sultat si le programme CUDA s'ex\u00e9cutait sans GPU ?",
    "answer": "Sans GPU, le r\u00e9sultat serait `2+7=0`."
  },
  {
    "question": "Comment lier des biblioth\u00e8ques CUDA, comme cuBLAS, lors de la compilation ?",
    "answer": "Compilez avec les indicateurs suivants : `nvcc -lcublas -Xlinker=-rpath,$CUDA_PATH/lib64`."
  },
  {
    "question": "Qu'est-ce que l'attribut 'compute capability' ?",
    "answer": "L'attribut 'compute capability', parfois appel\u00e9 'SM version', est un num\u00e9ro de version utilis\u00e9 par NVIDIA pour identifier les fonctionnalit\u00e9s et instructions sp\u00e9cifiques disponibles pour un GPU donn\u00e9."
  },
  {
    "question": "Quels messages d'erreur peuvent \u00eatre li\u00e9s \u00e0 un probl\u00e8me de 'compute capability' ?",
    "answer": "Des messages comme `nvcc fatal : Unsupported gpu architecture 'compute_XX'` ou `no kernel image is available for execution on the device (209)` sont souvent li\u00e9s \u00e0 cet attribut."
  },
  {
    "question": "Comment r\u00e9soudre les probl\u00e8mes li\u00e9s \u00e0 l'architecture GPU lors de la compilation avec `nvcc` ?",
    "answer": "Ajoutez l'indicateur `-gencode arch=compute_XX,code=[sm_XX,compute_XX]` \u00e0 l'appel `nvcc`, o\u00f9 `XX` est la valeur de 'compute capability' du GPU cible."
  },
  {
    "question": "Comment sp\u00e9cifier l'architecture GPU avec `cmake` pour r\u00e9soudre les probl\u00e8mes de 'compute capability' ?",
    "answer": "Utilisez l'indicateur `cmake .. -DCMAKE_CUDA_ARCHITECTURES=XX`, o\u00f9 `XX` est la valeur de 'compute capability'."
  },
  {
    "question": "Quelle est la valeur de 'compute capability' pour un n\u0153ud A100 de Narval ?",
    "answer": "La valeur de 'compute capability' pour un n\u0153ud A100 de Narval est 80."
  },
  {
    "question": "Quel indicateur `nvcc` doit \u00eatre utilis\u00e9 pour un GPU A100 (compute capability 80) ?",
    "answer": "L'indicateur \u00e0 utiliser est `-gencode arch=compute_80,code=[sm_80,compute_80]`."
  },
  {
    "question": "Quel indicateur `cmake` doit \u00eatre utilis\u00e9 pour un GPU A100 (compute capability 80) ?",
    "answer": "L'indicateur pour `cmake` est `cmake .. -DCMAKE_CUDA_ARCHITECTURES=80`."
  }
]