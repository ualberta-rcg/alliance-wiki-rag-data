[
  {
    "question": "How can you submit a collection of identical jobs ensuring only one runs at a time using job arrays?",
    "answer": "Using the `--array=1-100%10` syntax, one can submit a collection of identical jobs with the condition that only one job of them will run at any given time."
  },
  {
    "question": "How is the number of restarts determined when using job arrays?",
    "answer": "The number of restarts is fixed by the `--array` argument."
  },
  {
    "question": "What should a job array script ensure regarding checkpoint files for restarting simulations?",
    "answer": "The script should be written to ensure that the last checkpoint is always used for the next job. If a checkpoint file (e.g., `state.cpt`) exists, the script should restart the simulation with `mdrun --restart state.cpt`; otherwise, it should start a new simulation with `mdrun`."
  },
  {
    "question": "How does job resubmission from the job script work for long-running computations?",
    "answer": "One submits a job that runs the first chunk of the calculation and saves a checkpoint. Once the chunk is done but before the allocated run-time of the job has elapsed, the script checks if the end of the calculation has been reached. If not finished, the script submits a copy of itself to continue working."
  },
  {
    "question": "What command is used within a job script to resubmit itself for continued work?",
    "answer": "The command `sbatch ${BASH_SOURCE[0]}` is used within the job script to resubmit itself."
  },
  {
    "question": "What type of test should be used when determining whether to resubmit a follow-up job from within a script?",
    "answer": "The test to determine whether to submit a follow-up job, abbreviated as `work_should_continue`, should be a positive test to prevent indefinite job chains if unforeseen errors arise."
  },
  {
    "question": "What are other terms for the practice of automating a large number of related calculations?",
    "answer": "This practice is sometimes called farming, serial farming, or task farming."
  },
  {
    "question": "What is an additional benefit of using tools for automating job submission besides workflow automation?",
    "answer": "These tools can also improve computational efficiency by bundling up many short computations into fewer tasks of longer duration."
  },
  {
    "question": "What tools are available on the clusters for automating job submission beyond array jobs?",
    "answer": "META-Farm, GNU Parallel, and GLOST are available on the clusters for automating job submission."
  },
  {
    "question": "What is the recommended approach for specifying a partition for Slurm jobs?",
    "answer": "It is recommended to allow the scheduler to assign a partition to your job based on the resources it requests, rather than specifying one."
  },
  {
    "question": "How should users handle software that automatically submits jobs and requires a partition specification, which conflicts with the recommended approach?",
    "answer": "Users should configure such software to use `--partition=default`, which the script treats the same as not specifying a partition."
  },
  {
    "question": "What is the maximum permitted job duration on clusters like Beluga, Fir, Narval, Nibi, and Rorqual?",
    "answer": "On these clusters, no jobs are permitted longer than 168 hours (7 days)."
  },
  {
    "question": "What is the job limit per user on clusters such as Beluga, Fir, Narval, Nibi, and Rorqual?",
    "answer": "There is a limit of 1000 jobs, queued and running, per user on these clusters."
  },
  {
    "question": "What is the recommended minimum duration for production jobs on clusters like Beluga, Fir, Narval, Nibi, and Rorqual?",
    "answer": "Production jobs should have a duration of at least an hour on these clusters."
  },
  {
    "question": "Where can users find information about Trillium-specific job scheduling restrictions?",
    "answer": "Users can find information in the 'Trillium specific restrictions' section of the Trillium Quickstart page."
  },
  {
    "question": "What is a common cause of trouble when preparing job scripts?",
    "answer": "Preparing a job script with a word processor instead of a text editor is a common cause of trouble."
  },
  {
    "question": "What is the best practice for preparing job scripts?",
    "answer": "The best practice is to prepare your job script on the cluster using an editor such as nano, vim, or emacs."
  },
  {
    "question": "What should Windows users do if they prepare job scripts offline?",
    "answer": "Windows users should use a text editor such as Notepad or Notepad++ and then use `dos2unix` to change Windows end-of-line characters to Linux end-of-line characters after uploading the script."
  },
  {
    "question": "What should Mac users do to prepare job scripts?",
    "answer": "Mac users should open a terminal window and use an editor such as nano, vim, or emacs."
  },
  {
    "question": "What is a job submitted with `--dependency=afterok:<jobid>` called?",
    "answer": "A job submitted with `--dependency=afterok:<jobid>` is a dependent job."
  },
  {
    "question": "What happens to a dependent job if its parent job fails?",
    "answer": "If the parent job fails (that is, ends with a non-zero exit code), the dependent job can never be scheduled and will be automatically cancelled."
  },
  {
    "question": "What error message might indicate a module cannot be loaded due to an unsatisfied prerequisite?",
    "answer": "An error message like \"Lmod has detected the following error: These module(s) exist but cannot be loaded as requested: \"<module-name>/<version>\" Try: \"module spider <module-name>/<version>\" to see how to load the module(s)\" indicates this."
  },
  {
    "question": "Why might a module fail to load as requested?",
    "answer": "A module might fail to load if it has an unsatisfied prerequisite."
  },
  {
    "question": "How can an unsatisfied prerequisite for a module be resolved in a job script?",
    "answer": "Adding the necessary prerequisite modules (e.g., `module load nixpkgs/16.09 intel/2016.4 openmpi/2.1.1`) to your job script before loading the desired module will solve the problem."
  },
  {
    "question": "Do Slurm jobs inherit environment variables from the submission shell by default?",
    "answer": "Yes, by default a job will inherit the environment variables of the shell where the job was submitted."
  },
  {
    "question": "What is a best practice to ensure a consistent environment for job submissions regarding modules?",
    "answer": "It is best to include the line `module purge` in your job script before loading all the required modules to ensure a consistent state for each job submission and avoid changes made in your shell affecting your jobs."
  },
  {
    "question": "How can a user prevent a job from inheriting environment settings from the submitting shell?",
    "answer": "Use the `--export=none` directive when submitting jobs to suppress environment inheritance."
  },
  {
    "question": "Why might a submitted job appear to hang with no output for an extended period?",
    "answer": "A common reason for a submitted job appearing to hang with no output is the aggressive buffering performed by the Slurm scheduler, which aggregates many output lines before flushing them to the log file."
  },
  {
    "question": "When is output typically written to the log file for a buffered Slurm job?",
    "answer": "Often the output file will only be written after the job completes; if the job is cancelled or runs out of time, part of the output may be lost."
  },
  {
    "question": "What is recommended for monitoring the real-time progress of a submitted job?",
    "answer": "Consider running an interactive job to monitor the progress of your submitted job as it runs in real time."
  },
  {
    "question": "Where can users find comprehensive documentation and tutorials for Slurm?",
    "answer": "Comprehensive documentation and tutorials for Slurm are maintained by SchedMD."
  },
  {
    "question": "Is there a resource for users transitioning from other schedulers to Slurm?",
    "answer": "Yes, there is a 'Rosetta stone' mapping commands and directives from PBS/Torque, SGE, LSF, and LoadLeveler to Slurm."
  }
]