[
  {
    "question": "What is Apache MXNet?",
    "answer": "Apache MXNet is a deep learning framework designed for both efficiency and flexibility."
  },
  {
    "question": "What programming paradigms does MXNet support?",
    "answer": "MXNet allows you to mix symbolic and imperative programming to maximize efficiency and productivity."
  },
  {
    "question": "How does MXNet handle parallelization?",
    "answer": "MXNet contains a dynamic dependency scheduler that automatically parallelizes both symbolic and imperative operations on the fly."
  },
  {
    "question": "What is the function of the graph optimization layer in MXNet?",
    "answer": "A graph optimization layer makes symbolic execution fast and memory efficient."
  },
  {
    "question": "What are some key characteristics of MXNet regarding portability and scalability?",
    "answer": "MXNet is portable and lightweight, and it is scalable to many GPUs and machines."
  },
  {
    "question": "How can you list available MXNet wheels?",
    "answer": "You can list available wheels using the `avail_wheels` command, for example, `avail_wheels mxnet`."
  },
  {
    "question": "What MXNet versions are available for Python cp39, cp38, and cp310 according to the `avail_wheels` command output?",
    "answer": "MXNet version 1.9.1 is available for Python cp39, cp38, and cp310, all with avx2 architecture."
  },
  {
    "question": "What is the first step to install MXNet in a Python virtual environment?",
    "answer": "The first step is to create and activate a Python virtual environment."
  },
  {
    "question": "What commands are used to create and activate a Python 3.10 virtual environment?",
    "answer": "The commands are `module load python/3.10`, `virtualenv --no-download ~/env`, and `source ~/env/bin/activate`."
  },
  {
    "question": "How do you install MXNet and its Python dependencies within an activated virtual environment?",
    "answer": "Run `pip install --no-index mxnet`."
  },
  {
    "question": "How can an MXNet installation be validated using a Python command?",
    "answer": "Validate it by running `python -c \"import mxnet as mx;print((mx.nd.ones((2, 3))*2).asnumpy());\"`."
  },
  {
    "question": "What is the expected output when validating an MXNet installation with the provided Python command?",
    "answer": "The expected output is `[[2. 2. 2.] [2. 2. 2.]]`."
  },
  {
    "question": "What does the `mxnet-conv-ex.py` script demonstrate?",
    "answer": "The `mxnet-conv-ex.py` script demonstrates a single Convolution layer using MXNet."
  },
  {
    "question": "How is the device (CPU or GPU) determined in the `mxnet-conv-ex.py` example?",
    "answer": "The device is set to `mx.gpu()` if `mx.context.num_gpus() > 0`, otherwise it defaults to `mx.cpu()`."
  },
  {
    "question": "Which libraries are imported in the `mxnet-conv-ex.py` script?",
    "answer": "`mxnet` and `numpy` are imported."
  },
  {
    "question": "What is the purpose of `y.simple_bind(device, x=shape)` in the MXNet convolution example?",
    "answer": "It binds the symbolic graph `y` to the specified `device` with the input `x` having the defined `shape`."
  },
  {
    "question": "What are the common steps in both CPU and GPU MXNet job submission scripts?",
    "answer": "The common steps include loading `python/3.10`, generating and activating a virtual environment in `$SLURM_TMPDIR`, installing `mxnet==1.9.1`, and running `python mxnet-conv-ex.py`."
  },
  {
    "question": "What SLURM resource allocation is specified for a GPU job in the `mxnet-conv.sh` script?",
    "answer": "For a GPU job, `#SBATCH --gres=gpu:1` is specified."
  },
  {
    "question": "How do you submit the MXNet convolution job to the scheduler?",
    "answer": "Submit the job using the command `sbatch mxnet-conv.sh`."
  },
  {
    "question": "What backend is used for CPU-based MXNet convolution as specified in the CPU submission script?",
    "answer": "MKLDNN will be used for CPU-based MXNet convolution."
  },
  {
    "question": "What backend is used for GPU-based MXNet convolution as specified in the GPU submission script?",
    "answer": "cuDNN will be used for GPU-based MXNet convolution."
  },
  {
    "question": "What Python version is loaded as a module in the MXNet job submission scripts?",
    "answer": "Python 3.10 is loaded."
  },
  {
    "question": "How is MXNet installed within the virtual environment in the submission script?",
    "answer": "MXNet is installed using `pip install --no-index mxnet==1.9.1`."
  },
  {
    "question": "What are the suggested `walltime` and `mem` allocations for the MXNet convolution job in the submission scripts?",
    "answer": "The suggested `walltime` is `01:00:00` and `mem` is `20G`."
  },
  {
    "question": "What technologies does MXNet use for parallel implementations of deep learning operators on CPUs?",
    "answer": "MXNet uses OpenMP and MKLDNN for CPU-based parallel implementations."
  },
  {
    "question": "What technologies does MXNet use for parallel implementations of deep learning operators on GPUs?",
    "answer": "MXNet uses CUDA and CUDNN for GPU-based parallel implementations."
  },
  {
    "question": "What is the strong recommendation for training small-scale models with MXNet in terms of CPU versus GPU usage?",
    "answer": "When training small-scale models, it is strongly recommended to use multiple CPUs instead of a GPU."
  },
  {
    "question": "Why is it discouraged to request a GPU for small-scale models in a shared HPC environment?",
    "answer": "It is discouraged because the speed-up relative to CPU may not be significant, leading to underutilization, blocking resources, wasting allocation, and affecting colleagues' job priorities."
  },
  {
    "question": "Under what condition should you avoid requesting a GPU for your MXNet code?",
    "answer": "You should not ask for a GPU if your code is not capable of making reasonable use of its compute capacity."
  },
  {
    "question": "How can the `mxnet-example.sh` script be modified to run a job using only the CPU?",
    "answer": "To run using CPU only, remove the line `#SBATCH --gres=gpu:1` from the `mxnet-example.sh` script."
  },
  {
    "question": "What Python modules are imported in the `mxnet-example.py` script?",
    "answer": "`numpy`, `time`, `mxnet` (context, autograd, gpu, cpu), `mxnet.gluon` (nn, Trainer, loss, data.vision.transforms, data.vision.datasets, data), and `argparse` are imported."
  },
  {
    "question": "How is the execution context (CPU or GPU) determined in the `mxnet-example.py` script?",
    "answer": "The context `ctx` is set to `gpu()` if `context.num_gpus() > 0`, otherwise it is set to `cpu()`."
  },
  {
    "question": "What type of neural network is defined in the `mxnet-example.py` script?",
    "answer": "A Sequential Convolutional Neural Network (CNN) is defined."
  },
  {
    "question": "What layers are included in the `nn.Sequential` model in `mxnet-example.py`?",
    "answer": "The model includes `Conv2D`, `MaxPool2D`, `Flatten`, and `Dense` layers."
  },
  {
    "question": "How is the network initialized in the `mxnet-example.py` script?",
    "answer": "The network is initialized using `net.initialize(ctx=ctx)`."
  },
  {
    "question": "What is the purpose of the `argparse` module in `mxnet-example.py`?",
    "answer": "The `argparse` module is used to define command-line arguments like learning rate (`--lr`), batch size (`--batch_size`), and number of workers (`--num_workers`)."
  },
  {
    "question": "Which SLURM parameter in `mxnet-example.sh` can be adjusted to observe performance effects?",
    "answer": "The `#SBATCH --cpus-per-task` parameter can be changed (e.g., to 2, 4, 6,...) to see the effect on performance."
  }
]