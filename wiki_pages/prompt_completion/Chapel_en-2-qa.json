[
  {
    "question": "What module enables NVIDIA GPU support for multi-locale Chapel on InfiniBand clusters?",
    "answer": "To enable GPU support, you should use the `chapel-ucx-cuda` module."
  },
  {
    "question": "What specific modules need to be loaded to run multi-locale Chapel code with GPU support on an InfiniBand cluster?",
    "answer": "You need to load `gcc/12.3`, `cuda/12.2`, and `chapel-ucx-cuda/2.4.0` using the command `module load gcc/12.3 cuda/12.2 chapel-ucx-cuda/2.4.0`."
  },
  {
    "question": "How do you request resources for an interactive job with GPU support for Chapel programs?",
    "answer": "You can use `salloc` with parameters like `--time=0:30:0 --mem-per-cpu=3500 --gpus-per-node=1 --account=def-someprof`, for example: `salloc --time=0:30:0 --mem-per-cpu=3500 --gpus-per-node=1 --account=def-someprof`."
  },
  {
    "question": "What is the command to compile the `probeGPU.chpl` example code with fast optimization?",
    "answer": "The command to compile `probeGPU.chpl` is `chpl --fast probeGPU.chpl`."
  },
  {
    "question": "How do you execute the compiled `probeGPU.chpl` program for a single locale with GPU support?",
    "answer": "After compilation, you can run the executable using `./probeGPU -nl 1`."
  },
  {
    "question": "How does the example `probeGPU.chpl` code determine whether to execute an operation on a GPU or a CPU?",
    "answer": "The `probeGPU.chpl` code checks the size of available GPUs (`here.gpus.size`). If there are GPUs (`here.gpus.size > 0`), it uses the first GPU (`here.gpus[0]`); otherwise, it defaults to using the CPU (`here`)."
  },
  {
    "question": "What is the recommended approach for running multi-locale Chapel jobs with NVIDIA GPU support in a production environment?",
    "answer": "For production jobs, it is recommended to write a Slurm submission script and submit the job using `sbatch`."
  }
]