[
  {
    "question": "What is the primary purpose of the `deepspeed-stage3.sh` example script?",
    "answer": "The script is designed to train a model using ZeRO stage 3, distributing optimizer states, model parameters, and model gradients across a group of GPUs."
  },
  {
    "question": "How does DeepSpeed ZeRO stage 3 improve memory efficiency compared to pure data parallelism?",
    "answer": "ZeRO stage 3 distributes the optimizer states, model parameters, and model gradients across multiple GPUs, making it more efficient than loading a complete model copy on each GPU."
  },
  {
    "question": "Which specific optimizer is used in the `deepspeed-stage3.py` script to maintain performance comparable to pure data parallelism with ZeRO stage 3?",
    "answer": "The `FusedAdam` optimizer from DeepSpeed is used to achieve performance comparable to pure data parallelism."
  },
  {
    "question": "What is a prerequisite for using DeepSpeed optimizers in terms of loaded modules?",
    "answer": "A `cuda/<version>` module must be loaded, and its version must match the version used to compile the PyTorch package being used."
  },
  {
    "question": "What SLURM resources are requested by the `deepspeed-stage3.sh` script for the training job?",
    "answer": "The script requests 1 node, 2 GPUs (`--gres=gpu:2`), 2 tasks per node (`--tasks-per-node=2`), 32GB of memory (`--mem=32G`), and a time limit of 20 minutes (`--time=0-00:20`)."
  },
  {
    "question": "Which Python libraries are installed in the virtual environment within the `deepspeed-stage3.sh` script?",
    "answer": "The script installs `torchvision`, `pytorch-lightning`, and `deepspeed` in the virtual environment."
  },
  {
    "question": "What environment variable related to NCCL is set in the `deepspeed-stage3.sh` script?",
    "answer": "The `TORCH_NCCL_ASYNC_HANDLING` environment variable is exported with a value of `1`."
  },
  {
    "question": "How is the `pytorch_lightning.Trainer` configured to utilize DeepSpeed ZeRO stage 3 in the `deepspeed-stage3.py` script?",
    "answer": "The `pl.Trainer` is initialized with `accelerator=\"gpu\"`, `devices=2`, `num_nodes=1`, and `strategy=\"deepspeed_stage_3\"`."
  },
  {
    "question": "What is the default batch size passed to the `deepspeed-stage3.py` script when executed by `srun`?",
    "answer": "The `srun` command passes `--batch_size 256` to the Python script."
  },
  {
    "question": "According to the comments in `deepspeed-stage3.sh`, what does PyTorch Lightning expect regarding tasks per GPU in a SLURM batch job?",
    "answer": "PyTorch Lightning expects the user to have requested one task per GPU when running inside a SLURM batch job."
  },
  {
    "question": "Describe the architecture of the neural network model defined in `deepspeed-stage3.py`.",
    "answer": "The `Net` class defines a neural network model composed of a `ConvPart` (convolutional and pooling layers) and an `MLPPart` (dense feedforward layers), which are then combined into a `nn.Sequential` block."
  }
]