[
  {
    "question": "Which GPU model is used as the reference for Reference GPU Units (RGUs)?",
    "answer": "The NVidia A100-40gb GPU is used as the reference model."
  },
  {
    "question": "What RGU value is assigned to the NVidia A100-40gb reference GPU?",
    "answer": "It is assigned an RGU value of 4.0 for historical reasons."
  },
  {
    "question": "How are FP16 performance, FP32 performance, and memory size defined for the A100-40gb reference GPU?",
    "answer": "For the A100-40gb, FP16 performance, FP32 performance, and memory size are each defined as 1.0."
  },
  {
    "question": "What are the coefficients used for calculating RGU values based on FP32, FP16, and GPU memory scores?",
    "answer": "The coefficients are 1.6 for FP32 score, 1.6 for FP16 score, and 0.8 for GPU memory score."
  },
  {
    "question": "What is the combined RGU score for an H100-80gb GPU?",
    "answer": "The combined RGU score for an H100-80gb GPU is 12.2."
  },
  {
    "question": "What is the RGU score for a V100-32gb GPU?",
    "answer": "The RGU score for a V100-32gb GPU is 2.6."
  },
  {
    "question": "What is the RGU score for a P100-12gb GPU?",
    "answer": "The RGU score for a P100-12gb GPU is 1.0."
  },
  {
    "question": "When will it become possible to schedule fractions of a GPU using Multi-Instance GPU technology?",
    "answer": "It will become possible with the 2025 infrastructure renewal."
  },
  {
    "question": "What is a GPU instance (or MIG instance)?",
    "answer": "A GPU instance is a fraction of a GPU allocated to a single job, potentially allowing different jobs from different users to run on the same GPU simultaneously."
  },
  {
    "question": "What is the RGU value for an A100-3g.20gb GPU instance?",
    "answer": "The RGU value for an A100-3g.20gb GPU instance is 2.0."
  },
  {
    "question": "What is the RGU value for an H100-3g.40gb GPU instance?",
    "answer": "The RGU value for an H100-3g.40gb GPU instance is 6.1."
  },
  {
    "question": "How do A100-40gb and P100-12gb GPUs compare for applications primarily doing FP32 operations?",
    "answer": "For FP32 operations, an A100-40gb GPU is expected to be twice as fast as a P100-12gb GPU, but recorded usage will be 4 times the resources."
  },
  {
    "question": "How do A100-40gb and P100-12gb GPUs compare for applications primarily doing FP16 operations?",
    "answer": "For FP16 operations, using an A100-40gb will be evaluated as using 4 times the resources of a P100-12gb, but it is capable of computing approximately 30 times the calculations, allowing about 7.5 times the computations for the same amount of time."
  },
  {
    "question": "What information must be specified in a GPU proposal during the Resource Allocation Competition (RAC)?",
    "answer": "Any proposal asking for GPUs must specify the preferred GPU model for the project."
  },
  {
    "question": "How are Reference GPU Units (RGUs) calculated in the CCDB form for RAC awards?",
    "answer": "The amount of Reference GPU Units (RGUs) will automatically be calculated from the requested amount of gpu-years per year of the project."
  },
  {
    "question": "If an allocation requires movement to a different cluster, how does the RAC committee ensure RGU consistency?",
    "answer": "If an allocation must be moved to a different cluster, the committee will allocate gpu-years at that cluster so as to keep the amount of RGUs the same."
  },
  {
    "question": "Which GPU instance profiles have been deprecated and for what reason?",
    "answer": "The A100-4g.20gb and H100-4g.40gb profiles are deprecated mainly to simplify scheduling."
  },
  {
    "question": "What fraction of an A100 or H100 GPU is a '1g' profile GPU instance worth?",
    "answer": "A GPU instance of profile '1g' is worth 1/7 of an A100 or H100 GPU."
  }
]