[
  {
    "question": "What is an allocation in high-performance computing?",
    "answer": "An allocation is an amount of resources that a research group can target for use for a period of time, usually a year."
  },
  {
    "question": "How are resources typically allocated to research groups?",
    "answer": "Allocations are usually made in terms of core years, GPU years, or storage space."
  },
  {
    "question": "What is the difference between storage allocations and core year/GPU year allocations?",
    "answer": "Storage allocations are a maximum amount of storage that can be used exclusively, while core year and GPU year allocations represent an average amount of usage over the period on shared resources."
  },
  {
    "question": "Does a research group get extra resource usage if clusters are down for maintenance during their allocation period?",
    "answer": "No, if the allocation period was a year and clusters were down for a week of maintenance, a research group would not be entitled to an additional week of resource usage."
  },
  {
    "question": "How can research groups maximize their chances of hitting core year or GPU year allocation targets?",
    "answer": "A research group is more likely to hit its targets if resources are used evenly over the allocation period, rather than in bursts or delayed use."
  },
  {
    "question": "What is a 'job' in the context of compute allocations?",
    "answer": "A job is a combination of a computer program (an application) and a list of resources that the application is expected to use."
  },
  {
    "question": "What role does a scheduler play in managing compute allocations?",
    "answer": "The scheduler is a program that calculates the priority of each job submitted and provides the needed resources based on the job's priority and available resources."
  },
  {
    "question": "How does the scheduler determine job priority?",
    "answer": "The scheduler uses prioritization algorithms based on a research group\u2019s recent usage of the system compared to their allocated usage, with recent usage being weighted most heavily."
  },
  {
    "question": "What happens if a research group runs more jobs than their CPU or GPU allocation target?",
    "answer": "If competing demand is low, the scheduler may allow more jobs to run than the target level. The only consequence is that succeeding jobs may have lower priority for a time while the scheduler prioritizes other groups that were below their target."
  },
  {
    "question": "Are research groups prevented from submitting new jobs if they exceed their allocation target?",
    "answer": "No, research groups are not prevented from submitting or running new jobs even if they temporarily exceed their allocation target."
  },
  {
    "question": "Why were Reference GPU Units (RGUs) introduced?",
    "answer": "RGUs were introduced in the 2024 RAC year to rank all GPU models in production and alleviate problems caused by treating all GPUs as equivalent for allocation purposes, due to the dramatic increase in GPU performance."
  },
  {
    "question": "What criteria and weights are used to rank GPU models for RGU calculation?",
    "answer": "The evaluation criteria are FP32 score (40% weight), FP16 score (40% weight), and GPU memory score (20% weight)."
  },
  {
    "question": "Which GPU model serves as the reference for RGU values and what is its assigned RGU value?",
    "answer": "The NVidia A100-40gb GPU is the reference model and is assigned an RGU value of 4.0 for historical reasons."
  },
  {
    "question": "How is the performance of the A100-40gb reference GPU defined for RGU calculation?",
    "answer": "Its FP16 performance, FP32 performance, and memory size are each defined as 1.0."
  }
]