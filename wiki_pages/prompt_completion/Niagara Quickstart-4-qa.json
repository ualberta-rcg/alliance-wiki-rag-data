[
  {
    "question": "Where can I find detailed information about Niagara's file systems for I/O?",
    "answer": "Details about Niagara's file systems for I/O can be found on the 'Data management at Niagara' page."
  },
  {
    "question": "Are files visible across all Niagara nodes?",
    "answer": "Yes, your files can be seen on all Niagara login and compute nodes."
  },
  {
    "question": "What parallel file system do $HOME, $SCRATCH, and $PROJECT use on Niagara?",
    "answer": "$HOME, $SCRATCH, and $PROJECT all use the parallel file system called GPFS."
  },
  {
    "question": "What are the key characteristics of GPFS on Niagara?",
    "answer": "GPFS is a high-performance parallel file system that provides rapid reads and writes to large data sets in parallel from many nodes."
  },
  {
    "question": "What kind of data access patterns result in poor performance on GPFS?",
    "answer": "Accessing data sets which consist of many, small files leads to poor performance on GPFS."
  },
  {
    "question": "What is the recommended approach for handling many small files on Niagara to optimize I/O?",
    "answer": "You should avoid reading and writing lots of small amounts of data to disk. If you must write many small files, use ramdisk."
  },
  {
    "question": "Why should I avoid using many small files on the Niagara file system?",
    "answer": "Many small files on the system waste space and are slower to access, read, and write."
  },
  {
    "question": "What data format is recommended for faster I/O and less storage space on Niagara?",
    "answer": "Writing data out in a binary format is recommended as it is faster and takes less space."
  },
  {
    "question": "When is the Burst Buffer beneficial for jobs on Niagara?",
    "answer": "The Burst Buffer is better for I/O heavy jobs and to speed up checkpoints."
  },
  {
    "question": "What is an example of an MPI job submission script on Niagara?",
    "answer": "An MPI job script might include `#SBATCH --nodes=2`, `#SBATCH --ntasks=80`, `#SBATCH --time=1:00:00`, module loads for intel and openmpi, and an `mpirun` command for the application."
  },
  {
    "question": "How do you submit an MPI job script on Niagara?",
    "answer": "You submit an MPI job script from your scratch directory using the command `sbatch mpi_job.sh`."
  },
  {
    "question": "What does the first line `#!/bin/bash` signify in a job script?",
    "answer": "The first line `#!/bin/bash` indicates that the script is a bash script."
  },
  {
    "question": "What is the purpose of lines starting with `#SBATCH` in a SLURM job script?",
    "answer": "Lines starting with `#SBATCH` are directives that go to SLURM for job configuration."
  },
  {
    "question": "What resources does the example MPI job script request from SLURM?",
    "answer": "The example MPI script requests 2 nodes, a total of 80 tasks, and a walltime of 1 hour."
  },
  {
    "question": "Can I specify tasks per node instead of total tasks for an MPI job in SLURM, and how?",
    "answer": "Yes, instead of `--ntasks=80`, you can specify `--ntasks-per-node=40`, which achieves the same result for the example MPI job."
  },
  {
    "question": "Is the `mpirun` flag `--ppn` respected on Niagara?",
    "answer": "No, the `mpirun` flag `--ppn` (processors per node) is ignored."
  },
  {
    "question": "How can hyperthreading be enabled for an MPI job using the example script?",
    "answer": "To use hyperthreading, change `--ntasks=80` to `--ntasks=160` and add `--bind-to none` to the `mpirun` command (the latter is for OpenMPI only, not IntelMPI)."
  },
  {
    "question": "What does an example OpenMP job submission script look like on Niagara?",
    "answer": "An OpenMP job script might include `#SBATCH --nodes=1`, `#SBATCH --cpus-per-task=40`, `#SBATCH --time=1:00:00`, loading the intel module, setting `OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK`, and running `./openmp_example`."
  },
  {
    "question": "How do you submit an OpenMP job script on Niagara?",
    "answer": "You submit an OpenMP job script from your scratch directory using the command `sbatch openmp_job.sh`."
  },
  {
    "question": "What resources does the example OpenMP job script request from SLURM?",
    "answer": "The example OpenMP script requests one node with 40 cores for one task, to run for 1 hour."
  },
  {
    "question": "How can hyperthreading be enabled for an OpenMP job using the example script?",
    "answer": "To use hyperthreading for an OpenMP job, change `--cpus-per-task=40` to `--cpus-per-task=80` in the job script."
  }
]