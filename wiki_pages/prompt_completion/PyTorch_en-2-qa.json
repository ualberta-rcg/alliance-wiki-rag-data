[
  {
    "question": "Which cluster was equipped with Ampere GPUs as of October 2022?",
    "answer": "As of October 2022, Narval was the only cluster equipped with Ampere GPUs."
  },
  {
    "question": "What are the potential performance and accuracy differences when using PyTorch versions less than 1.12.0 compared to 1.12.0 or higher on Ampere GPUs?",
    "answer": "You may observe a significant slowdown and get different results when running GPU-enabled code with `torch < 1.12.0` versus `torch >= 1.12.0`."
  },
  {
    "question": "How can TF32 be enabled or disabled for matrix multiplications in PyTorch versions 1.12.0 and higher?",
    "answer": "To enable or disable TF32 for matrix multiplications on `torch >= 1.12.0`, set the flag `torch.backends.cuda.matmul.allow_tf32` to `True` or `False`."
  },
  {
    "question": "How can TF32 be enabled or disabled for convolutions in PyTorch versions 1.12.0 and higher?",
    "answer": "To enable or disable TF32 for convolutions on `torch >= 1.12.0`, set the flag `torch.backends.cudnn.allow_tf32` to `True` or `False`."
  },
  {
    "question": "What are the two ways PyTorch natively supports parallelizing work across multiple CPUs?",
    "answer": "PyTorch natively supports parallelizing work across multiple CPUs through intra-op parallelism and inter-op parallelism."
  },
  {
    "question": "What is intra-op parallelism in PyTorch?",
    "answer": "Intra-op parallelism refers to PyTorch's parallel implementations of Deep Learning operators (like matrix multiplication and convolution) using OpenMP or libraries like MKL and OneDNN, which automatically leverage multi-threading over available CPU cores."
  },
  {
    "question": "What is inter-op parallelism in PyTorch?",
    "answer": "Inter-op parallelism refers to PyTorch's ability to execute different parts of your code concurrently, typically requiring explicit program design, such as using `torch.jit` for asynchronous tasks in a TorchScript program."
  },
  {
    "question": "When is it recommended to use multiple CPUs instead of a GPU for PyTorch models?",
    "answer": "For small scale models, it is strongly recommended to use multiple CPUs instead of a GPU."
  },
  {
    "question": "Why is it discouraged to use a GPU for very small models on HPC clusters?",
    "answer": "For very small models on HPC clusters, using a GPU can unnecessarily block a resource that another user may need for large-scale computations and consume your group's allocation inefficiently."
  },
  {
    "question": "What is a common misconception regarding GPU usage for model training on HPC clusters?",
    "answer": "A common misconception is that you should always use a GPU for model training if one is available, but this is not always the case on HPC clusters, especially for very small models."
  },
  {
    "question": "When should you not request a GPU on HPC clusters for PyTorch code?",
    "answer": "You should not request a GPU if your PyTorch code is not capable of making reasonable use of its compute capacity."
  },
  {
    "question": "What are the two primary sources of performance advantage for GPUs in Deep Learning tasks?",
    "answer": "GPUs gain performance advantage from their ability to parallelize numerical operations over many thousands of compute cores and their much higher memory bandwidth compared to CPUs."
  },
  {
    "question": "What GPU-specific libraries does PyTorch use for parallel implementations of Deep Learning operators?",
    "answer": "PyTorch uses GPU-specific libraries like CUDNN or MIOpen for parallel implementations of Deep Learning operators such as matrix multiplication and convolution."
  },
  {
    "question": "What characteristics make a learning task suitable for running on a GPU?",
    "answer": "A learning task is suitable for running on a GPU if it is composed of elements that scale out with massive parallelism in terms of the number of operations, the amount of data required, or both, such as large models or large inputs."
  },
  {
    "question": "What two parameters play an important role in optimizing single GPU performance with PyTorch?",
    "answer": "The two parameters that play an important role in optimizing single GPU performance are `batch_size` and `num_workers`."
  },
  {
    "question": "How does `batch_size` affect single GPU performance in PyTorch?",
    "answer": "`batch_size` influences performance by increasing the size of inputs at each iteration, which helps utilize more of the GPU's compute capacity."
  },
  {
    "question": "How does `num_workers` affect single GPU performance in PyTorch?",
    "answer": "`num_workers` influences performance by streamlining the movement of inputs from the CPU's memory to the GPU's memory, thereby reducing the time the GPU spends idle waiting for data."
  },
  {
    "question": "What is the recommendation for `batch_size` to optimize single GPU compute performance?",
    "answer": "Increase your `batch_size` to as much as you can fit in the GPU's memory to optimize compute performance."
  },
  {
    "question": "What is the recommendation for `num_workers` with a `DataLoader` to optimize feeding data to a single GPU?",
    "answer": "Use a `DataLoader` with as many workers as you have `cpus-per-task` to streamline feeding data to the GPU."
  }
]