[
  {
    "question": "How many cores are configured in a NUMA node within a CPU node on Rorqual?",
    "answer": "A NUMA node on Rorqual's CPU nodes has 24 cores (3x8) and shares a trio of system memory channels."
  },
  {
    "question": "What is the total number of cores available per CPU node?",
    "answer": "Each CPU node has a total of 192 cores (2x4x3x8)."
  },
  {
    "question": "What is the recommended approach to fully utilize the CPU node topology?",
    "answer": "To fully utilize the CPU node topology, it is recommended to reserve complete nodes (e.g., using `--ntasks-per-node=24 --cpus-per-task=8`) and explicitly control the placement of processes and threads."
  },
  {
    "question": "How is the architecture of GPU nodes described compared to CPU nodes?",
    "answer": "The architecture in GPU nodes is less hierarchical than that of CPU nodes."
  },
  {
    "question": "What are the key architectural features within a GPU node's CPU sockets?",
    "answer": "Each of the two CPU sockets in a GPU node features eight system memory channels, 60 MiB of L3 cache, 32 equidistant cores (each with its own L2 and L1 cache), and two NVidia H100 accelerators."
  },
  {
    "question": "How are the four NVidia H100 accelerators within a GPU node connected?",
    "answer": "The four NVidia H100 accelerators within a GPU node are interconnected by SXM5."
  },
  {
    "question": "What are the common short names used for a full H100-80gb GPU instance?",
    "answer": "The common short names for a full H100-80gb GPU instance are `h100` or `h100_80gb`."
  },
  {
    "question": "What is the full descriptive name for the H100-80gb GPU model?",
    "answer": "The full descriptive name for the H100-80gb GPU model is `nvidia_h100_80gb_hbm3`."
  },
  {
    "question": "What Slurm options can be used to request a single H100-80gb GPU?",
    "answer": "To request a single H100-80gb GPU, you can use either `--gpus=h100:1` or `--gpus=h100_80gb:1`."
  },
  {
    "question": "How can multiple H100-80gb GPUs be requested per node using Slurm?",
    "answer": "To request multiple H100-80gb GPUs per node, you can use Slurm options such as `--gpus-per-node=h100:2`, `--gpus-per-node=h100:3`, or `--gpus-per-node=h100:4`."
  },
  {
    "question": "How can a general number of H100-80gb GPUs be requested without specifying per node?",
    "answer": "To request a general number of H100-80gb GPUs (scattered anywhere), use the Slurm option `--gpus=h100:n`, replacing `n` with the desired quantity."
  },
  {
    "question": "What percentage of Rorqual's GPU nodes are configured with Multi-Instance GPU (MIG) technology?",
    "answer": "Approximately half of Rorqual's GPU nodes are configured with Multi-Instance GPU (MIG) technology."
  },
  {
    "question": "What are the three available sizes of MIG instances on Rorqual?",
    "answer": "The three available sizes of MIG instances are H100-1g.10gb, H100-2g.20gb, and H100-3g.40gb."
  },
  {
    "question": "What are the specifications of the H100-1g.10gb MIG instance?",
    "answer": "The H100-1g.10gb MIG instance provides 1/8 of the computing power with 10 GB of GPU memory."
  },
  {
    "question": "What are the specifications of the H100-2g.20gb MIG instance?",
    "answer": "The H100-2g.20gb MIG instance provides 2/8 of the computing power with 20 GB of GPU memory."
  },
  {
    "question": "What are the specifications of the H100-3g.40gb MIG instance?",
    "answer": "The H100-3g.40gb MIG instance provides 3/8 of the computing power with 40 GB of GPU memory."
  },
  {
    "question": "How do you request a single H100-1g.10gb MIG instance for a task?",
    "answer": "To request a single H100-1g.10gb MIG instance, use the Slurm option `--gpus=h100_1g.10gb:1`."
  },
  {
    "question": "What Slurm option is used to request one H100-2g.20gb MIG instance?",
    "answer": "To request one H100-2g.20gb MIG instance, use the Slurm option `--gpus=h100_2g.20gb:1`."
  },
  {
    "question": "What is the Slurm option for requesting a single H100-3g.40gb MIG instance?",
    "answer": "The Slurm option for requesting a single H100-3g.40gb MIG instance is `--gpus=h100_3g.40gb:1`."
  }
]