[
  {
    "question": "What are the two high-level features provided by PyTorch?",
    "answer": "PyTorch offers tensor computation (like NumPy) with strong GPU acceleration and deep neural networks built on a tape-based autograd system."
  },
  {
    "question": "Where can I find a tutorial for porting PyTorch programs to the clusters?",
    "answer": "You should follow 'our tutorial on the subject' ([[Tutoriel Apprentissage machine/en|our tutorial on the subject]])."
  },
  {
    "question": "Is PyTorch the same as Torch?",
    "answer": "No, for all practical purposes, PyTorch and Torch can be treated as separate projects, despite a distant connection."
  },
  {
    "question": "What is LibTorch used for?",
    "answer": "LibTorch allows one to implement extensions to PyTorch using C++ and to implement pure C++ machine learning applications."
  },
  {
    "question": "How can models written in Python using PyTorch be used in pure C++?",
    "answer": "Models written in Python using PyTorch can be converted and used in pure C++ through TorchScript."
  },
  {
    "question": "How can I check the latest available version of PyTorch that has been built?",
    "answer": "You can use the `avail_wheels torch` command to see the latest built version of PyTorch."
  },
  {
    "question": "What is the preferred method for installing PyTorch?",
    "answer": "The preferred method is to install PyTorch using a Python wheel, which involves loading a Python module, creating a virtual environment, and then using `pip install`."
  },
  {
    "question": "How do you install the PyTorch `torch` package for GPU and CPU within a virtual environment?",
    "answer": "Inside a virtual environment, run the command `pip install --no-index torch`."
  },
  {
    "question": "What PyTorch version is required for H100 GPUs?",
    "answer": "For H100 GPUs, PyTorch version 2.3 and higher is required."
  },
  {
    "question": "What is the recommendation if encountering issues with PyTorch 1.10, such as `c10::Error` or distributed training problems?",
    "answer": "It is recommended to install PyTorch 1.9.1 using `pip install --no-index torch==1.9.1` due to known issues with version 1.10 on clusters (except Narval)."
  },
  {
    "question": "How can I install additional PyTorch packages like `torchvision`, `torchtext`, and `torchaudio`?",
    "answer": "You can install them within your virtual environment using `pip install --no-index torch torchvision torchtext torchaudio`."
  },
  {
    "question": "What is the `pytorch-test.sh` script example used for?",
    "answer": "It is an example of a job submission script for running a PyTorch application on the cluster, including loading Python, setting up a virtual environment, and installing PyTorch."
  },
  {
    "question": "How do you submit a PyTorch job using the provided `pytorch-test.sh` script?",
    "answer": "You can submit a PyTorch job using the `sbatch pytorch-test.sh` command."
  },
  {
    "question": "What does the `pytorch-test.py` script demonstrate?",
    "answer": "The `pytorch-test.py` script demonstrates basic tensor creation, random tensor generation, and tensor addition, with a conditional check to utilize CUDA if available."
  },
  {
    "question": "Which PyTorch version introduced support for Nvidia's TensorFloat-32 (TF32) Mode?",
    "answer": "PyTorch version 1.7.0 introduced support for Nvidia's TensorFloat-32 (TF32) Mode."
  },
  {
    "question": "On which Nvidia GPU architectures is TF32 Mode available?",
    "answer": "TF32 Mode is available only on Ampere and later Nvidia GPU architectures."
  },
  {
    "question": "What are the performance and accuracy implications of using TF32 Mode?",
    "answer": "TF32 Mode can yield up to 20x speed-ups compared to equivalent single precision (FP32) operations, but these performance gains may come at the cost of potentially decreased accuracy."
  },
  {
    "question": "What are the default TF32 settings for matrix multiplications and convolutions starting with PyTorch version 1.12.0?",
    "answer": "Starting with PyTorch version 1.12.0, TF32 is disabled by default for matrix multiplications but remains enabled by default for convolutions."
  },
  {
    "question": "Which cluster is equipped with Ampere GPUs as of October 2022?",
    "answer": "As of October 2022, Narval is the only cluster equipped with Ampere GPUs."
  },
  {
    "question": "How can TF32 be explicitly enabled or disabled for matrix multiplications and convolutions in PyTorch versions 1.12.0 and above?",
    "answer": "For `torch >= 1.12.0`, TF32 can be enabled/disabled by setting `torch.backends.cuda.matmul.allow_tf32` to `True` or `False` for matrix multiplications, and `torch.backends.cudnn.allow_tf32` to `True` or `False` for convolutions."
  }
]