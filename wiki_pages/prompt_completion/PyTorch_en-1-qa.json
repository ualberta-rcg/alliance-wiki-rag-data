[
  {
    "question": "What are the two high-level features provided by PyTorch?",
    "answer": "PyTorch provides Tensor computation (like NumPy) with strong GPU acceleration and Deep neural networks built on a tape-based autograd system."
  },
  {
    "question": "Where can I find a tutorial for porting a PyTorch program to your clusters?",
    "answer": "You should follow 'our tutorial on the subject' found under [[Tutoriel Apprentissage machine/en|our tutorial on the subject]]."
  },
  {
    "question": "Is PyTorch the same as Torch?",
    "answer": "For all practical purposes, you can treat PyTorch and Torch as separate projects, despite a distant connection."
  },
  {
    "question": "What is LibTorch used for?",
    "answer": "LibTorch allows one to implement extensions to PyTorch using C++ and to implement pure C++ machine learning applications."
  },
  {
    "question": "How can Python models written in PyTorch be used in C++?",
    "answer": "Models written in Python using PyTorch can be converted and used in pure C++ through TorchScript."
  },
  {
    "question": "How can I see the latest available version of PyTorch that has been built?",
    "answer": "Run the command `avail_wheels torch`."
  },
  {
    "question": "What is the preferred method for installing PyTorch using a Python wheel?",
    "answer": "The preferred method is to load a Python module, create and start a virtual environment, and then install PyTorch using `pip install`."
  },
  {
    "question": "What command is used to install PyTorch for GPU and CPU within a virtual environment?",
    "answer": "Use `pip install --no-index torch` within the virtual environment."
  },
  {
    "question": "Which PyTorch version is required for H100 GPUs?",
    "answer": "Torch 2.3 and higher is required with H100 GPUs."
  },
  {
    "question": "What additional PyTorch-related packages can be installed besides `torch`?",
    "answer": "In addition to `torch`, you can install `torchvision`, `torchtext`, and `torchaudio`."
  },
  {
    "question": "How do you install `torch`, `torchvision`, `torchtext`, and `torchaudio` in a virtual environment?",
    "answer": "Run `pip install --no-index torch torchvision torchtext torchaudio` within the virtual environment."
  },
  {
    "question": "How do you submit a PyTorch job using the provided example script?",
    "answer": "You can submit a PyTorch job with `sbatch pytorch-test.sh`."
  },
  {
    "question": "What is PyTorch's TensorFloat-32 (TF32) Mode?",
    "answer": "TF32 is a mode introduced in PyTorch 1.7.0 for Ampere and later Nvidia GPU architectures, designed to speed up tensor operations."
  },
  {
    "question": "What performance benefit does TF32 mode offer?",
    "answer": "TF32 mode has been shown to yield up to 20x speed-ups compared to equivalent single precision (FP32) operations."
  },
  {
    "question": "When was TF32 mode enabled by default in PyTorch?",
    "answer": "TF32 mode was enabled by default in PyTorch versions 1.7.x up to 1.11.x."
  },
  {
    "question": "How has the default behavior of TF32 changed in PyTorch version 1.12.0 and later?",
    "answer": "Starting with PyTorch version 1.12.0, TF32 is disabled by default for matrix multiplications but still enabled by default for convolutions."
  },
  {
    "question": "What are the potential drawbacks of using TF32 mode?",
    "answer": "Gains in performance from TF32 may come at the cost of potentially decreased accuracy in results, especially with ill-conditioned matrices or long sequences of tensor operations."
  },
  {
    "question": "What might users notice when running GPU-enabled code with `torch < 1.12.0` versus `torch >= 1.12.0` on A100, H100, or newer Nvidia GPUs?",
    "answer": "Users may notice a significant slowdown and/or get different results when switching between `torch < 1.12.0` and `torch >= 1.12.0`."
  },
  {
    "question": "How can TF32 be enabled or disabled for matrix multiplications in `torch >= 1.12.0`?",
    "answer": "Set `torch.backends.cuda.matmul.allow_tf32 = True` (to enable) or `False` (to disable)."
  },
  {
    "question": "How can TF32 be enabled or disabled for convolutions in `torch >= 1.12.0`?",
    "answer": "Set `torch.backends.cudnn.allow_tf32 = True` (to enable) or `False` (to disable)."
  },
  {
    "question": "Where can I find more official documentation on TF32 in PyTorch?",
    "answer": "Refer to PyTorch's official documentation at `https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere`."
  }
]