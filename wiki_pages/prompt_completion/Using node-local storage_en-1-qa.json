[
  {
    "question": "What is `SLURM_TMPDIR`?",
    "answer": "`SLURM_TMPDIR` is an environment variable set by Slurm that contains the full path name of a temporary directory created on each node assigned to a job."
  },
  {
    "question": "When does Slurm create temporary directories for a job?",
    "answer": "Slurm creates a temporary directory on each node assigned to the job when the job starts."
  },
  {
    "question": "Why is I/O to `SLURM_TMPDIR` usually faster than to network storage?",
    "answer": "I/O to `SLURM_TMPDIR` is almost always faster than to network storage because the directory resides on local disk."
  },
  {
    "question": "For what type of I/O transactions is local disk storage particularly effective?",
    "answer": "Local disk is better for frequent small I/O transactions than network storage."
  },
  {
    "question": "How can using `$SLURM_TMPDIR` improve the runtime of a job?",
    "answer": "Any job doing a lot of input and output may expect to run more quickly if it uses `$SLURM_TMPDIR` instead of network storage due to faster I/O."
  },
  {
    "question": "What is a main challenge when using `$SLURM_TMPDIR` compared to network storage?",
    "answer": "The temporary nature of `$SLURM_TMPDIR` means input must be copied into it before use, and output must be copied back to network storage before the job ends to preserve it."
  },
  {
    "question": "How do you typically copy input data into `$SLURM_TMPDIR`?",
    "answer": "In the simplest case, you can use `cp` or `rsync` to copy data from network storage to `$SLURM_TMPDIR`."
  },
  {
    "question": "Provide an example command to copy input files into `$SLURM_TMPDIR`.",
    "answer": "An example command is `cp /project/def-someone/you/input.files.* $SLURM_TMPDIR/`."
  },
  {
    "question": "When might simple `cp` or `rsync` not be sufficient for input to `$SLURM_TMPDIR`?",
    "answer": "Simple `cp` or `rsync` may not work if the input is too large, or if it must be read by processes on different nodes."
  },
  {
    "question": "Why is creating Python virtual environments inside `$SLURM_TMPDIR` recommended for jobs?",
    "answer": "Using a Python virtual environment generates a large number of small I/O transactions, and creating it inside `$SLURM_TMPDIR` helps manage these efficiently."
  },
  {
    "question": "What must be done with output data in `$SLURM_TMPDIR` before a job completes?",
    "answer": "Output data must be copied from `$SLURM_TMPDIR` back to some permanent storage before the job ends."
  },
  {
    "question": "What are three ways to prevent data loss from `$SLURM_TMPDIR` if a job times out?",
    "answer": "To prevent data loss from a job timing out, you can request enough runtime, write checkpoints to network storage, or implement a signal trapping function."
  },
  {
    "question": "What is signal trapping in the context of Slurm jobs and output preservation?",
    "answer": "Signal trapping is a method where Slurm sends a signal to your job before runtime expires, triggering a shell function to copy output from `$SLURM_TMPDIR` to network storage."
  },
  {
    "question": "When is signal trapping particularly useful for preserving job output?",
    "answer": "Signal trapping is useful if your runtime estimate is uncertain or if you are chaining multiple Slurm jobs for a long calculation."
  },
  {
    "question": "How do you implement a signal trapping function in a shell script for output copying?",
    "answer": "You need to write a shell function to do the copying and use the `trap` shell command to associate that function with the signal."
  },
  {
    "question": "What are the limitations of the signal trapping method for preserving `$SLURM_TMPDIR` contents?",
    "answer": "This method will not preserve the contents of `$SLURM_TMPDIR` in the case of a node failure or certain malfunctions of the network file system."
  },
  {
    "question": "How do you copy one or more files to `$SLURM_TMPDIR` on every node for a multinode job?",
    "answer": "You can use the command: `srun --ntasks=$SLURM_NNODES --ntasks-per-node=1 cp file [files...] $SLURM_TMPDIR`."
  },
  {
    "question": "How do you extract a ZIP archive to `$SLURM_TMPDIR` on every node in a multinode job?",
    "answer": "You can use the command: `srun --ntasks=$SLURM_NNODES --ntasks-per-node=1 unzip archive.zip -d $SLURM_TMPDIR`."
  },
  {
    "question": "How do you extract a tarball archive to `$SLURM_TMPDIR` on every node in a multinode job?",
    "answer": "You can use the command: `srun --ntasks=$SLURM_NNODES --ntasks-per-node=1 tar -xvf archive.tar.gz -C $SLURM_TMPDIR`."
  },
  {
    "question": "How is `$SLURM_TMPDIR` implemented at the Trillium cluster, and what determines its available space?",
    "answer": "At Trillium, `$SLURM_TMPDIR` is implemented as RAMdisk, so the amount of space available is limited by the node's memory, less the RAM used by your application."
  },
  {
    "question": "How does the available space in `$SLURM_TMPDIR` vary on general-purpose clusters?",
    "answer": "At general-purpose clusters, the amount of space available in `$SLURM_TMPDIR` depends on the specific cluster and the node to which your job is assigned."
  },
  {
    "question": "What is the available space in `$SLURM_TMPDIR` on the Fir cluster?",
    "answer": "The available space in `$SLURM_TMPDIR` on the Fir cluster is 7TB."
  },
  {
    "question": "What is the available space in `$SLURM_TMPDIR` on the Narval cluster?",
    "answer": "The available space in `$SLURM_TMPDIR` on the Narval cluster is 800GB."
  },
  {
    "question": "What is the available space in `$SLURM_TMPDIR` on the Nibi cluster?",
    "answer": "The available space in `$SLURM_TMPDIR` on the Nibi cluster is 3TB."
  },
  {
    "question": "What is the available space in `$SLURM_TMPDIR` on the Rorqual cluster?",
    "answer": "The available space in `$SLURM_TMPDIR` on the Rorqual cluster is 375GB."
  },
  {
    "question": "When can you assume the full listed space in `$SLURM_TMPDIR` is available on each node for your job?",
    "answer": "You can reasonably assume the full listed space is available in `$SLURM_TMPDIR` on each node if your job reserves whole nodes."
  },
  {
    "question": "How can reserving less than a whole node affect the available space in `$SLURM_TMPDIR` for a job?",
    "answer": "If a job requests less than a whole node, other jobs may also write to the same filesystem (in a different directory), which can reduce the space available to your job."
  }
]