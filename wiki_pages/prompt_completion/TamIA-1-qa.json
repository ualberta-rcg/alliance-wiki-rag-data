[
  {
    "question": "What is the availability date for tamIA?",
    "answer": "tamIA is available as of March 31, 2025."
  },
  {
    "question": "What is the connection node address for tamIA?",
    "answer": "The connection node for tamIA is tamia.alliancecan.ca."
  },
  {
    "question": "Where can I find TamIA's Globus collection?",
    "answer": "TamIA's Globus v5 Server collection can be found at https://app.globus.org/file-manager?origin_id=72c3bca0-9281-4742-b066-333ba0fdef72."
  },
  {
    "question": "What is the address for the copy node for tools like rsync, scp, and sftp?",
    "answer": "The copy node for rsync, scp, sftp, and similar tools is tamia.alliancecan.ca."
  },
  {
    "question": "What is the URL for the tamIA portal?",
    "answer": "The tamIA portal is accessible at https://portail.tamia.ecpia.ca/."
  },
  {
    "question": "What is tamIA?",
    "answer": "tamIA is a computing cluster dedicated to the artificial intelligence needs of the Canadian scientific community."
  },
  {
    "question": "Where is tamIA located and who co-manages it?",
    "answer": "tamIA is located at Universit\u00e9 Laval and is co-managed with Mila and Calcul Qu\u00e9bec."
  },
  {
    "question": "What does the name 'tamIA' refer to?",
    "answer": "The name 'tamIA' refers to the tamia (chipmunk), a rodent mammal found in North America."
  },
  {
    "question": "Is tamIA part of a larger computing environment?",
    "answer": "Yes, tamIA is part of the pan-Canadian AI computing environment (ECPIA)."
  },
  {
    "question": "Do tamIA compute nodes have internet access?",
    "answer": "No, tamIA compute nodes do not have internet access. Exceptions can be made by contacting technical support with a justification."
  },
  {
    "question": "Is the `crontab` tool available on tamIA?",
    "answer": "No, the `crontab` tool is not offered on tamIA."
  },
  {
    "question": "Is VSCode allowed on tamIA?",
    "answer": "VSCode is forbidden on login nodes due to its heavy load but is authorized on compute nodes."
  },
  {
    "question": "What is the minimum duration for a regular task on tamIA?",
    "answer": "Each regular task should be at least one hour long. For test tasks, the minimum duration is five minutes."
  },
  {
    "question": "What is the maximum number of tasks (running and waiting) a user can have at once?",
    "answer": "Users cannot have more than 1000 tasks (in execution and pending) simultaneously."
  },
  {
    "question": "What is the maximum duration for a task on tamIA?",
    "answer": "The maximum duration for a task is one day (24 hours)."
  },
  {
    "question": "How many GPUs must each task utilize on tamIA?",
    "answer": "Each task must use 4 GPUs, which corresponds to one complete node."
  },
  {
    "question": "How do researchers gain access to the tamIA cluster?",
    "answer": "To access the computing cluster, each researcher must complete an access request in the CCDB."
  },
  {
    "question": "How long does it take to get effective access after completing the request?",
    "answer": "Effective access to the cluster can take up to one hour after completing the access request."
  },
  {
    "question": "Who are eligible Principal Investigators (PIs) for tamIA?",
    "answer": "Eligible Principal Investigators are members of an AIP-type RAP (prefix `aip-`)."
  },
  {
    "question": "What is the process to sponsor other researchers for access to tamIA?",
    "answer": "To sponsor other researchers: on the CCDB homepage, consult the 'Projet avec allocation de ressources' table, find and click the `aip-` project's RAPI, then click 'G\u00e9rer l'appartenance aux projets' at the bottom of the RAP management page, and finally, enter the CCRI of the member to add in the 'Ajouter des membres' section."
  },
  {
    "question": "From where is the tamIA computing cluster accessible?",
    "answer": "The tamIA computing cluster is accessible only from Canada."
  },
  {
    "question": "What are the characteristics of the HOME file system on tamIA?",
    "answer": "The HOME file system is a small Lustre space that cannot be enlarged, has small fixed quotas per user, and currently has no automatic backup (planned for summer 2025). Users should use their PROJECT space for large storage needs."
  },
  {
    "question": "What are the characteristics of the SCRATCH file system on tamIA?",
    "answer": "The SCRATCH file system is a large Lustre space for temporary files during calculations, has no automatic backup, large fixed quotas per user, and features automatic purging of old files."
  },
  {
    "question": "What are the characteristics of the PROJECT file system on tamIA?",
    "answer": "The PROJECT file system is a Lustre space designed for data sharing among group members and storing large amounts of data, offers large adjustable quotas per project, and has automatic daily backups."
  },
  {
    "question": "Which address should be used for data transfers via Globus?",
    "answer": "For data transfers via Globus, the 'Point de chute Globus' (Globus Drop Point) should be used."
  },
  {
    "question": "What type of high-performance network connects the tamIA cluster nodes?",
    "answer": "The tamIA cluster nodes are connected by an Nvidia InfiniBand NDR network."
  },
  {
    "question": "How are GPUs connected to the InfiniBand network?",
    "answer": "Each H100 GPU is connected to a NDR200 port via an Nvidia ConnectX-7 card. Each server therefore has 4 NDR200 ports connected to the InfiniBand fabric."
  },
  {
    "question": "What is the topology of the InfiniBand network?",
    "answer": "The InfiniBand network is non-blocking for compute servers and consists of 2 stages of switches arranged in a \"fat-tree\" topology."
  },
  {
    "question": "How is storage and management nodes connected to the network core?",
    "answer": "The storage and management nodes are connected via 4 x 400Gb/s connections to the network core."
  },
  {
    "question": "What are the specifications of the 42 compute nodes with GPUs?",
    "answer": "The 42 compute nodes have 48 cores, 512GB available memory, 2 x Intel Xeon Gold 6442Y 2.6 GHz (24C) CPUs, 1 x 7.68TB SSD storage, and 4 x NVIDIA HGX H100 SXM 80GB HBM3 700W GPUs connected via NVLink."
  },
  {
    "question": "What are the specifications of the 4 nodes without GPUs?",
    "answer": "The 4 nodes without GPUs have 64 cores, 512GB available memory, 2 x Intel Xeon Gold 6438M 2.2G (32C/64T) CPUs, 1 x 7.68TB SSD storage, and no GPUs."
  },
  {
    "question": "What is the default software environment on tamIA?",
    "answer": "The standard software environment `StdEnv/2023` is the default on tamIA."
  },
  {
    "question": "How can users monitor their tasks on tamIA?",
    "answer": "Users can monitor their GPU and CPU computing tasks in real-time or past tasks via the tamIA portal (https://portail.tamia.ecpia.ca/)."
  },
  {
    "question": "What information can users visualize for a task on the portal?",
    "answer": "For a task, users can visualize the utilization of compute cores, used memory, and GPU utilization."
  },
  {
    "question": "What should a user do if they are not fully utilizing requested resources?",
    "answer": "Users should adjust their submission file accordingly if they are not fully utilizing the allocated resources, for example, by modifying the CPU core request."
  }
]