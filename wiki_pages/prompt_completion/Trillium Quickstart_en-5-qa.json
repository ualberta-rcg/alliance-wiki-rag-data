[
  {
    "question": "How do you submit a job script on Trillium's CPU login node?",
    "answer": "You submit a job script from a CPU login node while in your `$SCRATCH` directory using the command `sbatch <jobscript.sh>`."
  },
  {
    "question": "What is the purpose of lines starting with `#SBATCH` in a job script?",
    "answer": "Lines starting with `#SBATCH` are directives for SLURM that specify the resources and parameters for the job request."
  },
  {
    "question": "What does the first line `#!/bin/bash` indicate in the example job scripts?",
    "answer": "The first line `#!/bin/bash` indicates that the script is a Bash script."
  },
  {
    "question": "How many nodes and tasks per node are requested for the example MPI job script?",
    "answer": "The example MPI job script requests 2 nodes, with 192 tasks per node."
  },
  {
    "question": "What is the requested walltime and job name for the example MPI job script?",
    "answer": "The requested walltime is 1 hour (`01:00:00`), and the job name is `mpi_job`."
  },
  {
    "question": "Which software modules are loaded in the example MPI job script?",
    "answer": "The `StdEnv/2023`, `gcc/12.3`, and `openmpi/4.1.5` modules are loaded."
  },
  {
    "question": "How is MPI-IO optimized for the VAST file system in the MPI job example?",
    "answer": "A library for tuning MPI-IO for the VAST file system is preloaded by sourcing `/scinet/vast/etc/vastpreload-openmpi.bash`."
  },
  {
    "question": "What application is executed in the example MPI job script?",
    "answer": "The `mpi_example` application is run using `mpirun`, with SLURM informing `mpirun` how many processes to run."
  },
  {
    "question": "How many nodes, tasks, and CPUs per task are requested for the example OpenMP job script?",
    "answer": "The example OpenMP job script requests 1 node, 1 task, and 192 CPUs per task."
  },
  {
    "question": "How is the `OMP_NUM_THREADS` environment variable set in the OpenMP job script?",
    "answer": "`OMP_NUM_THREADS` is set to the value of `$SLURM_CPUS_PER_TASK`, based on SLURM\u2019s CPU allocation."
  },
  {
    "question": "What OpenMP-related environment variables are set in the example hybrid MPI/OpenMP job script?",
    "answer": "`OMP_NUM_THREADS` is set to `$SLURM_CPUS_PER_TASK`, `OMP_PLACES` to `cores`, and `OMP_PROC_BIND` to `true`."
  },
  {
    "question": "How does the `mpirun` command in the hybrid MPI/OpenMP job example spread processes and threads?",
    "answer": "The `mpirun` command uses the `--bind-to core --map-by ppr:$RANKS_PER_L3CACHE:l3cache:pe=$OMP_NUM_THREADS` options to spread processes and threads evenly over the cores."
  },
  {
    "question": "What steps does a job script typically perform after SLURM allocates nodes and runs the script?",
    "answer": "After SLURM allocates nodes, the script typically changes to the submission directory, loads modules, sets environment variables, and then runs the application."
  }
]