[
  {
    "question": "What are the available H100 Multi-Instance GPU (MIG) sizes?",
    "answer": "The available H100 MIG sizes are H100-1g.10gb, H100-2g.20gb, and H100-3g.40gb."
  },
  {
    "question": "What is the computational power and GPU memory of an H100-1g.10gb instance?",
    "answer": "An H100-1g.10gb instance provides 1/8 of the computational power with 10 GB of GPU memory."
  },
  {
    "question": "How much computational power and GPU memory does an H100-2g.20gb instance offer?",
    "answer": "An H100-2g.20gb instance offers 2/8 of the computational power with 20 GB of GPU memory."
  },
  {
    "question": "Describe the characteristics of an H100-3g.40gb GPU instance.",
    "answer": "An H100-3g.40gb instance provides 3/8 of the computational power with 40 GB of GPU memory."
  },
  {
    "question": "How do you request a single H100-1g.10gb GPU instance for a compute task?",
    "answer": "To request a single H100-1g.10gb instance, use the Slurm option `--gpus=h100_1g.10gb:1`."
  },
  {
    "question": "What Slurm option is used to request one H100-2g.20gb GPU instance?",
    "answer": "The Slurm option for requesting one H100-2g.20gb instance is `--gpus=h100_2g.20gb:1`."
  },
  {
    "question": "What is the Slurm command to request a single H100-3g.40gb instance?",
    "answer": "To request a single H100-3g.40gb instance, use the Slurm option `--gpus=h100_3g.40gb:1`."
  },
  {
    "question": "Where can I find information about the recommended CPU cores and system memory per GPU instance?",
    "answer": "The recommended maximum quantities of CPU cores and system memory per GPU instance are listed in the 'table des caract\u00e9ristiques des bundles'."
  }
]