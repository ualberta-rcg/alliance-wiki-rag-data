[
  {
    "question": "How do I request a single A100-40gb GPU for my task?",
    "answer": "To request a single A100-40gb GPU, you should use the Slurm option `--gpus=a100:1`."
  },
  {
    "question": "What Slurm options are available for requesting multiple A100-40gb GPUs per node?",
    "answer": "You can use Slurm options such as `--gpus-per-node=a100:2`, `--gpus-per-node=a100:3`, or `--gpus-per-node=a100:4` to request multiple A100-40gb GPUs per node."
  },
  {
    "question": "How can I request a specific number of A100-40gb GPUs that can be spread across different nodes?",
    "answer": "To request multiple A100-40gb GPUs that can be spread anywhere, use the Slurm option `--gpus=a100:n`, replacing `n` with the desired number of GPUs."
  },
  {
    "question": "What technology is used on some Narval GPU nodes to provide smaller, partitioned GPU resources?",
    "answer": "Several Narval GPU nodes are configured with Multi-Instance GPU (MIG) technology."
  },
  {
    "question": "What are the different sizes of Multi-Instance GPU (MIG) instances available on Narval?",
    "answer": "Four sizes of MIG instances are available: 1g.5gb, 2g.10gb, 3g.20gb, and 4g.20gb."
  },
  {
    "question": "What are the specifications of the '1g.5gb' GPU instance?",
    "answer": "The '1g.5gb' GPU instance provides 1/8 of the computing power with 5 GB of GPU memory."
  },
  {
    "question": "What are the specifications of the '2g.10gb' GPU instance?",
    "answer": "The '2g.10gb' GPU instance provides 2/8 of the computing power with 10 GB of GPU memory."
  },
  {
    "question": "What are the specifications of the '3g.20gb' GPU instance?",
    "answer": "The '3g.20gb' GPU instance provides 3/8 of the computing power with 20 GB of GPU memory."
  },
  {
    "question": "What are the specifications of the '4g.20gb' GPU instance, and is it always available?",
    "answer": "The '4g.20gb' GPU instance offers 4/8 of the computing power with 20 GB of GPU memory. This version is available in smaller quantities."
  },
  {
    "question": "How do I request a single '1g.5gb' GPU instance for my compute task?",
    "answer": "To request a single '1g.5gb' GPU instance, use the Slurm option `--gpus=a100_1g.5gb:1`."
  },
  {
    "question": "How do I request a single '2g.10gb' GPU instance?",
    "answer": "You can request a single '2g.10gb' GPU instance using the Slurm option `--gpus=a100_2g.10gb:1`."
  },
  {
    "question": "What Slurm option should I use to request one '3g.20gb' GPU instance?",
    "answer": "To request one '3g.20gb' GPU instance, use the Slurm option `--gpus=a100_3g.20gb:1`."
  },
  {
    "question": "How can I request a single '4g.20gb' GPU instance for a task?",
    "answer": "To request a single '4g.20gb' GPU instance, use the Slurm option `--gpus=a100_4g.20gb:1`."
  },
  {
    "question": "Where can I find information on the recommended maximum CPU cores and system memory for GPU instances?",
    "answer": "The maximum recommended quantities of CPU cores and system memory per GPU instance are listed in the 'table des caract\u00e9ristiques des bundles' (bundles characteristics table)."
  },
  {
    "question": "How can users monitor their computational tasks on Narval?",
    "answer": "Users can monitor their CPU and GPU computational tasks in real-time or view past tasks through the Narval portal at `https://portail.narval.calculquebec.ca/`."
  },
  {
    "question": "What specific metrics can be visualized for a task on the Narval portal?",
    "answer": "On the Narval portal, you can visualize the utilization of compute cores, memory used, and GPU utilization for a task."
  },
  {
    "question": "Why is it important to adjust resource requests for tasks if resources are underutilized?",
    "answer": "It is important to adjust resource requests when compute resources are underutilized to maximize resource usage and reduce waiting times in the queue."
  }
]