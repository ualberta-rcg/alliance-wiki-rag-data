[
  {
    "question": "What is RAPIDS?",
    "answer": "RAPIDS is an open-source software suite from NVIDIA primarily used for running data science and analytics pipelines in Python with GPUs."
  },
  {
    "question": "What technologies does RAPIDS rely on?",
    "answer": "RAPIDS relies on CUDA for low-level computational optimization and provides user-friendly Python APIs similar to Pandas or Scikit-learn."
  },
  {
    "question": "What are the main components of RAPIDS?",
    "answer": "The main components of RAPIDS are cuDF, cuML, cuGraph, Cyber Log Accelerators (CLX), cuxFilter, cuSpatial, cuSignal, cuCIM, and RAPIDS Memory Manager (RMM)."
  },
  {
    "question": "What is cuDF used for?",
    "answer": "cuDF is a Python GPU DataFrames library for loading, merging, aggregating, selecting, and manipulating data, based on the Apache Arrow column format."
  },
  {
    "question": "What is cuML?",
    "answer": "cuML is a suite of libraries for implementing machine learning algorithms and primitive functions, enabling compatible API sharing with other RAPIDS projects."
  },
  {
    "question": "What is cuGraph?",
    "answer": "cuGraph is a GPU-accelerated graph analysis library that offers functionality similar to NetworkX and is well-integrated with the RAPIDS data science platform."
  },
  {
    "question": "What are Cyber Log Accelerators (CLX)?",
    "answer": "CLX is a collection of RAPIDS examples in security, data science, and engineering, allowing for rapid application of RAPIDS and GPU acceleration to cybersecurity use cases."
  },
  {
    "question": "What is cuxFilter?",
    "answer": "cuxFilter is a connector library designed to easily link visualization libraries with GPU DataFrames and enable interactive use of graphs from different libraries in the same dashboard."
  },
  {
    "question": "What is cuSpatial?",
    "answer": "cuSpatial is a C++/Python library with GPU acceleration for geographic information systems, including point-in-polygon search, spatial joins, coordinate systems, shape primitives, distances, and trajectory analysis."
  },
  {
    "question": "What is cuSignal?",
    "answer": "cuSignal provides GPU acceleration for signal processing using CuPy, Numba, and the RAPIDS ecosystem, sometimes as a direct port of Scipy Signal or with Numba CUDA kernels for selected functions."
  },
  {
    "question": "What is cuCIM?",
    "answer": "cuCIM is an extensible toolkit for GPU acceleration of I/O, computer vision, and primitive processing, primarily in the field of medical imaging."
  },
  {
    "question": "What is RAPIDS Memory Manager (RMM)?",
    "answer": "RMM is a memory allocation management tool for cuDF (C++ and Python) and other RAPIDS libraries, handling CUDA memory allocations and device memory replacements, and performing fast asynchronous allocations and deallocations by reserving a defined amount of memory."
  },
  {
    "question": "What is the first step to create an Apptainer image for RAPIDS?",
    "answer": "To create an Apptainer image for RAPIDS, you must first find and select a Docker image provided by NVIDIA."
  },
  {
    "question": "What was Apptainer previously known as?",
    "answer": "Apptainer was previously known as Singularity."
  },
  {
    "question": "What are the two types of Docker images for RAPIDS available from version v23.08 onwards?",
    "answer": "From RAPIDS v23.08, the two types of Docker images for RAPIDS are 'base' and 'notebooks'."
  },
  {
    "question": "What is included in the RAPIDS Base Docker image?",
    "answer": "The RAPIDS Base Docker image contains a RAPIDS environment ready for submitting a task to the scheduler."
  },
  {
    "question": "What is included in the RAPIDS Notebooks Docker image and what is its purpose?",
    "answer": "The RAPIDS Notebooks Docker image adds a Jupyter notebook server and example notebooks to the Base image, suitable for interactive work with notebooks and examples."
  },
  {
    "question": "How can you find the `pull` command for a specific Docker image?",
    "answer": "The `pull` command for a specific Docker image can be found under the 'Tags' tab on each of the sites."
  },
  {
    "question": "How do you build an Apptainer image from a Docker image?",
    "answer": "You can build an Apptainer image (e.g., 'rapids.sif') from a Docker image using a command like `apptainer build rapids.sif docker://nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.0-py3.12`."
  },
  {
    "question": "How long does building an Apptainer image usually take?",
    "answer": "The process of building an Apptainer image usually takes 30 to 60 minutes."
  },
  {
    "question": "What should you ensure when building a large Apptainer image?",
    "answer": "Since the image size is large, you should ensure that you have enough memory and disk space on the server."
  },
  {
    "question": "What can you do with a RAPIDS Apptainer image on a cluster?",
    "answer": "Once you have a RAPIDS Apptainer image on a cluster, you can request an interactive session on a GPU node or submit a batch job to the scheduler."
  },
  {
    "question": "When can an Apptainer image be used interactively on a GPU node?",
    "answer": "An Apptainer image can be used interactively on a GPU node if it was built with a 'notebooks' type Docker image, as it includes a Jupyter Notebook server."
  },
  {
    "question": "What command is used to request an interactive session on a GPU compute node like Graham?",
    "answer": "To request an interactive session on a GPU compute node, for example a T4 GPU on Graham, you use `salloc --ntasks=1 --cpus-per-task=2 --mem=10G --gres=gpu:t4:1 --time=1:0:0 --account=def-someuser`."
  },
  {
    "question": "How do you launch the RAPIDS interpreter on a GPU node after resource allocation?",
    "answer": "After resource allocation, load the apptainer module (`module load apptainer`) and then launch the interpreter with `apptainer shell --nv -B /home -B /project -B /scratch rapids.sif`."
  },
  {
    "question": "What is the purpose of the `--nv` option in the `apptainer shell` command?",
    "answer": "The `--nv` option performs a 'bind mount' of the host's GPU device onto the container, allowing GPU access from within the Apptainer container."
  },
  {
    "question": "What is the purpose of the `-B` option in the `apptainer shell` command?",
    "answer": "The `-B` option performs a 'bind mount' of filesystems that you want to access within the container."
  },
  {
    "question": "How do you verify GPU access inside the Apptainer interpreter?",
    "answer": "When the interpreter prompt changes to `Apptainer>`, you can check GPU statistics using `nvidia-smi` to ensure access."
  },
  {
    "question": "How do you launch a Jupyter Notebook server within the RAPIDS environment inside Apptainer?",
    "answer": "When the prompt changes to `Apptainer>`, you can launch the Jupyter Notebook server using `jupyter-lab --ip $(hostname -f) --no-browser`."
  },
  {
    "question": "Is it necessary to activate RAPIDS after Conda starts for versions 23.08 and later?",
    "answer": "No, starting from version 23.08, RAPIDS does not need to be activated after Conda starts, as all packages are included in the base Conda environment, which is activated by default."
  },
  {
    "question": "Why is an SSH tunnel required to connect to Jupyter Notebook on a Graham compute node?",
    "answer": "An SSH tunnel is required because a compute node on Graham is not directly connected to the internet, and it's needed to redirect the port between your computer and the GPU node."
  },
  {
    "question": "What is considered good practice when working with containers on a compute node for RAPIDS jobs?",
    "answer": "It is good practice to use node-local storage when working with a container on a compute node."
  },
  {
    "question": "What command in a Slurm script executes a Python script within an Apptainer container?",
    "answer": "The command `apptainer exec --nv rapids.sif python ./my_rapids_code.py` executes a Python script within an Apptainer container."
  },
  {
    "question": "How are results from a batch job saved to persistent storage?",
    "answer": "Results from a batch job should be copied from `$SLURM_TMPDIR` (local disk) to your `/project` directory (e.g., `~/projects/def-someuser/username/`) before the job terminates."
  },
  {
    "question": "Where can users find complete documentation for RAPIDS?",
    "answer": "Complete documentation for RAPIDS, contact information, and problem reporting can be found in the RAPIDS Docs ([https://docs.rapids.ai/ RAPIDS Docs])."
  },
  {
    "question": "Where can users find example RAPIDS notebooks?",
    "answer": "Example RAPIDS notebooks are available on GitHub at [https://github.com/rapidsai/notebooks RAPIDS Notebooks]."
  },
  {
    "question": "Where can users find RAPIDS use cases and blog posts?",
    "answer": "RAPIDS use cases and blog posts can be found on Medium at [https://medium.com/rapids-ai RAPIDS on Medium]."
  }
]