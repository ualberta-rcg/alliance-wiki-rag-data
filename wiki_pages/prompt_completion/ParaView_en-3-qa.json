[
  {
    "question": "What is the minimum number of cores required for visualization on Trillium when scheduling a client-server job?",
    "answer": "On Trillium, you must schedule on whole nodes, meaning the minimum example will require 192 cores."
  },
  {
    "question": "What `salloc` command should be used to start a parallel CPU interactive job for visualization on Trillium?",
    "answer": "The command for Trillium is: `salloc --time=1:00:0 --ntasks=192 --account=def-someprof`."
  },
  {
    "question": "Which module must be loaded on Trillium before attempting to load `paraview/6.0.0`?",
    "answer": "On Trillium, you must load `StdEnv/2023` before attempting to load `paraview/6.0.0`."
  },
  {
    "question": "How do you start the ParaView server after loading the ParaView module within a job on a cluster?",
    "answer": "You start the ParaView server using the command: `srun pvserver --force-offscreen-rendering --opengl-window-backend OSMesa`."
  },
  {
    "question": "What information should you note from the ParaView server output after it starts on the cluster?",
    "answer": "You should make a note of the compute node (e.g., `fc30669`) and the port (usually `11111`) from the `Connection URL`."
  },
  {
    "question": "What command is used on a local computer to create an SSH tunnel for ParaView client-server connection to clusters like Fir, Rorqual, Trillium, or Narval?",
    "answer": "The command is: `ssh <username>@fir.alliancecan.ca -L 11111:fc30669:11111`, replacing placeholders with your username, cluster, and compute node."
  },
  {
    "question": "What is the specific SSH command for port forwarding when connecting a ParaView client to a server on Nibi?",
    "answer": "For Nibi, the command is: `ssh -T -J <username>@nibi.alliancecan.ca -L 11111:localhost:11111 <username>@<nibi_compute_node>`."
  },
  {
    "question": "Why is the `-T` flag important in the Nibi-specific SSH command for client-server visualization?",
    "answer": "The `-T` flag disables pseudo-terminal allocation and is important to facilitate the initial client-server handshake."
  },
  {
    "question": "How do you configure the ParaView GUI on your local computer to connect to the remote parallel server?",
    "answer": "In ParaView GUI, click `Connect`, then `Add Server`. Set `Server Type = Client/Server`, `Host = localhost`, `Port = 11111`, `Startup Type = Manual`, then `Save` and `Connect`."
  },
  {
    "question": "How can you check if you are performing parallel rendering in ParaView?",
    "answer": "To check for parallel rendering, you can color your dataset by the `Process Id` variable, which is unavailable when running in serial."
  },
  {
    "question": "What is the recommended approach for large-scale and automated ParaView visualization?",
    "answer": "For large-scale and automated visualization, it is strongly recommended to switch from interactive client-server to off-screen batch visualization using ParaView Python scripting."
  },
  {
    "question": "What does a basic Slurm script for serial batch ParaView rendering (`serial.sh`) typically include?",
    "answer": "A serial batch script (`serial.sh`) typically includes `#SBATCH` directives for time, memory per CPU, and account, followed by `pvbatch --force-offscreen-rendering --opengl-window-backend OSMesa script.py`."
  },
  {
    "question": "What are the key components of a Slurm script for parallel batch ParaView rendering (`distributed.sh`)?",
    "answer": "A parallel batch script (`distributed.sh`) includes `#SBATCH` directives for time, memory per CPU, number of tasks (`--ntasks`), and account, followed by `srun pvbatch --force-offscreen-rendering --opengl-window-backend OSMesa script.py`."
  },
  {
    "question": "When should client-server visualization in a cloud VM be considered for ParaView?",
    "answer": "Client-server visualization in a cloud VM is a less common approach and should only be used if you require a custom setup that is not supported by the cluster-installed ParaView."
  },
  {
    "question": "Why is it necessary to compile ParaView with OSMesa support for cloud VMs?",
    "answer": "It's necessary because most Arbutus VMs do not have access to a GPU, so OSMesa support enables offscreen (software) rendering."
  },
  {
    "question": "Which software rasterization library is enabled by OSMesa for OpenGL when compiling ParaView on a cloud VM?",
    "answer": "The default configuration of OSMesa will enable OpenSWR (Intel's software rasterization library) to run OpenGL."
  },
  {
    "question": "Which two drivers for offscreen CPU-based rendering are typically built with OSMesa, and which one is recommended?",
    "answer": "Both `llvmpipe` (older and slower) and `SWR` (newer and faster) drivers are built, and SWR is recommended."
  },
  {
    "question": "What command is used to start the ParaView server on a cloud VM configured with OSMesa?",
    "answer": "The ParaView server on a VM is started with: `./paraview/bin/pvserver --force-offscreen-rendering --opengl-window-backend OSMesa`."
  },
  {
    "question": "How do you establish an SSH tunnel from your local computer to a cloud VM for ParaView client-server connection?",
    "answer": "On your computer, use the command: `ssh centos@vm.ip.address -L 11111:localhost:11111`."
  },
  {
    "question": "What message indicates that SWR rendering is successfully detected during ParaView rendering on a cloud VM?",
    "answer": "During rendering in the console, you should see the message 'SWR detected AVX2'."
  }
]