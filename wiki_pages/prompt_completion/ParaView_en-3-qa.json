[
  {
    "question": "What is the minimum number of cores required for visualization on Trillium using the large-scale interactive workflow?",
    "answer": "On Trillium, you must schedule on whole nodes, i.e., in multiples of 192 cores, so the minimum requirement is 192 cores."
  },
  {
    "question": "What ParaView version compatibility is required between the local client and the remote host for a client-server setup?",
    "answer": "ParaView requires the same major version on the local client and the remote host. For example, if the server is version 6.0.0, the client needs to be 6.0.x."
  },
  {
    "question": "What is the first step to starting a parallel CPU interactive job for large-scale interactive visualization?",
    "answer": "First, install the same ParaView version on your computer as the one available on the cluster you will be using. Then, log into the cluster and start a parallel CPU interactive job."
  },
  {
    "question": "What `salloc` command can be used to start a general parallel CPU interactive job?",
    "answer": "`salloc --time=1:00:0 --ntasks=... --mem-per-cpu=3600 --account=def-someprof`"
  },
  {
    "question": "What is the specific `salloc` command for starting a parallel CPU interactive job on Trillium?",
    "answer": "`salloc --time=1:00:0 --ntasks=192 --account=def-someprof`"
  },
  {
    "question": "What module must be loaded on Trillium before loading `paraview/6.0.0`?",
    "answer": "On Trillium, you must load `StdEnv/2023` before attempting to load `paraview/6.0.0`."
  },
  {
    "question": "How do you load the ParaView module within an interactive job?",
    "answer": "`module load paraview/6.0.0`"
  },
  {
    "question": "How do you start the ParaView server with off-screen rendering inside an interactive job?",
    "answer": "`srun pvserver --force-offscreen-rendering --opengl-window-backend OSMesa`"
  },
  {
    "question": "How do you set up an SSH tunnel from your local computer to a compute node for ParaView client-server connection?",
    "answer": "From your computer, use a terminal to link local port 11111 to the compute node's port 11111 using the command: `ssh <username>@fir.alliancecan.ca -L 11111:fc30669:11111` (replace `fir` with the actual cluster name and `fc30669` with the compute node name)."
  },
  {
    "question": "How do you connect the ParaView client on your computer to a remote server once the SSH tunnel is established?",
    "answer": "Start ParaView on your computer, go to 'File -> Connect' (or click on the green 'Connect' button in the toolbar), click on 'Add Server', set name = fir, server type = Client/Server, host = localhost, port = 11111, click 'Configure', select 'Manual', and click 'Save'. Then, select the server from the list and click 'Connect'."
  },
  {
    "question": "How can you verify that parallel rendering is occurring in ParaView?",
    "answer": "You can color your dataset by the `Process Id` variable; this variable is unavailable when running in serial."
  },
  {
    "question": "What is the recommended approach for large-scale and automated visualization?",
    "answer": "For large-scale and automated visualization, it is strongly recommended to switch from interactive client-server to off-screen batch visualization, using ParaView's Python scripting capabilities."
  },
  {
    "question": "How do you get help with scripting ParaView workflows for batch production?",
    "answer": "If you need any help with this, please contact Technical support."
  },
  {
    "question": "What is the workflow for serial rendering in batch mode?",
    "answer": "First, load the ParaView module (`module load paraview/6.0.0`), then submit the Slurm job script (`sbatch serial.sh`). The `serial.sh` script should contain: `#!/bin/bash #SBATCH --time=3:0:0 #SBATCH --mem-per-cpu=3600 #SBATCH --account=def-someuser pvbatch --force-offscreen-rendering --opengl-window-backend OSMesa script.py`"
  },
  {
    "question": "What is the workflow for parallel rendering in batch mode?",
    "answer": "First, load the ParaView module (`module load paraview/6.0.0`), then submit the Slurm job script (`sbatch distributed.sh`). The `distributed.sh` script should contain: `#!/bin/bash #SBATCH --time=3:0:0 #SBATCH --mem-per-cpu=3600 #SBATCH --ntasks=4 #SBATCH --account=def-someuser srun pvbatch --force-offscreen-rendering --opengl-window-backend OSMesa script.py`"
  },
  {
    "question": "When should client-server visualization in a cloud VM be used?",
    "answer": "This approach is less common and should only be used if you require a custom setup not supported by the cluster-installed ParaView."
  },
  {
    "question": "What guide explains how to launch a new virtual machine (VM) for cloud visualization?",
    "answer": "The Cloud Quick Start Guide explains how to launch a new virtual machine (VM)."
  },
  {
    "question": "Which packages need to be installed on a CentOS VM to compile ParaView or VisIt?",
    "answer": "You need to install `xauth wget gcc gcc-c++ ncurses-devel python-devel libxcb-devel`, `patch imake libxml2-python mesa-libGL mesa-libGL-devel`, `mesa-libGLU mesa-libGLU-devel bzip2 bzip2-libs libXt-devel zlib-devel flex byacc`, and create a symlink: `sudo ln -s /usr/include/GL/glx.h /usr/local/include/GL/glx.h`."
  },
  {
    "question": "How can you copy your public SSH key to a cloud VM to simplify logins?",
    "answer": "From your computer, issue the command: `cat ~/.ssh/id_rsa.pub | ssh -i ~/.ssh/cloudwestkey.pem centos@vm.ip.address 'cat >>.ssh/authorized_keys'`"
  }
]