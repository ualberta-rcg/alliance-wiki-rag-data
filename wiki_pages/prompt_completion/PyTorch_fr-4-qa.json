[
  {
    "question": "Which two parameters are important for GPU performance optimization in PyTorch?",
    "answer": "The two important parameters for GPU performance optimization in PyTorch are `batch_size` and `num_workers`."
  },
  {
    "question": "How does increasing `batch_size` improve GPU performance in PyTorch?",
    "answer": "Increasing `batch_size` improves GPU performance by enhancing the GPU's capacity utilization and increasing the size of inputs processed in each iteration."
  },
  {
    "question": "What is the benefit of `num_workers` for GPU performance in PyTorch?",
    "answer": "The `num_workers` parameter improves performance by facilitating data movement between the CPU (host memory) and the GPU memory, which reduces the GPU's idle time while waiting for data."
  },
  {
    "question": "What is the primary recommendation for setting `batch_size` to optimize GPU performance?",
    "answer": "The primary recommendation is to increase the `batch_size` value to the maximum possible amount that fits within the GPU's memory to optimize performance."
  },
  {
    "question": "How should `num_workers` be configured with `DataLoader` for efficient data transfer to the GPU?",
    "answer": "A `DataLoader` should be used with `num_workers` set to the same value as `cpus-per-task` to efficiently facilitate data input to the GPU."
  },
  {
    "question": "Does `batch_size` solely affect computational performance?",
    "answer": "No, the `batch_size` parameter also impacts a model's performance in terms of accuracy or error, and there are different perspectives on using large batches."
  },
  {
    "question": "Where can users find guidance on optimizing GPU usage with small batch sizes?",
    "answer": "Users can find guidance in the section 'Travailler avec un seul GPU' (PyTorch/fr#Travailler_avec_un_seul_GPU) for maximizing GPU utilization with small data inputs."
  },
  {
    "question": "How does the `pytorch-single-gpu.sh` script request a GPU resource?",
    "answer": "The `pytorch-single-gpu.sh` script requests one GPU using the SLURM directive `#SBATCH --gres=gpu:1`."
  },
  {
    "question": "What is the purpose of `pip install torch torchvision --no-index` in the `pytorch-single-gpu.sh` script?",
    "answer": "This command installs the `torch` and `torchvision` packages into the virtual environment without using an index, typically for offline or local wheel installations."
  },
  {
    "question": "How is the neural network model moved to the GPU in the `cifar10-gpu.py` script?",
    "answer": "The neural network model is moved to the GPU by calling `net = net.cuda()` after it has been defined and compiled."
  },
  {
    "question": "How is the loss function prepared for GPU computation in `cifar10-gpu.py`?",
    "answer": "The loss function is prepared for GPU computation by calling `.cuda()` on the `nn.CrossEntropyLoss()` instance, resulting in `criterion = nn.CrossEntropyLoss().cuda()`."
  },
  {
    "question": "What specific argument is passed to `DataLoader` to enhance data loading efficiency for GPU training in `cifar10-gpu.py`?",
    "answer": "The `pin_memory=True` argument is passed to `DataLoader` to enhance data loading efficiency for GPU training by enabling faster, asynchronous data transfer to the GPU."
  },
  {
    "question": "How are the input `inputs` and `targets` transferred to the GPU within the training loop of `cifar10-gpu.py`?",
    "answer": "Within the training loop, `inputs = inputs.cuda()` and `targets = targets.cuda()` are used to explicitly transfer the input data and targets to the GPU."
  }
]