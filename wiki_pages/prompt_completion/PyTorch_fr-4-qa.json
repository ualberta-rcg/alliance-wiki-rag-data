[
  {
    "question": "Quelles sont les principales mani\u00e8res de parall\u00e9liser les donn\u00e9es avec PyTorch en utilisant plusieurs GPU?",
    "answer": "Il existe plusieurs mani\u00e8res, notamment en utilisant la classe `DistributedDataParallel`, le paquet PyTorch Lightning et le paquet Horovod."
  },
  {
    "question": "Qu'est-ce que la parall\u00e9lisation des donn\u00e9es dans le contexte de l'entra\u00eenement de mod\u00e8les avec plusieurs GPU?",
    "answer": "C'est une m\u00e9thode pour entra\u00eener en parall\u00e8le plusieurs copies d\u2019un mod\u00e8le o\u00f9 chaque copie re\u00e7oit une portion des donn\u00e9es d\u2019entra\u00eenement \u00e0 chaque it\u00e9ration."
  },
  {
    "question": "Comment les gradients et les param\u00e8tres du mod\u00e8le sont-ils g\u00e9r\u00e9s \u00e0 la fin d'une it\u00e9ration en parall\u00e9lisation des donn\u00e9es avec plusieurs GPU?",
    "answer": "\u00c0 la fin d\u2019une it\u00e9ration, les gradients sont agr\u00e9g\u00e9s et les param\u00e8tres de chaque copie sont mis \u00e0 jour de fa\u00e7on synchrone ou asynchrone, selon la m\u00e9thode."
  },
  {
    "question": "Quel est l'avantage de la parall\u00e9lisation des donn\u00e9es avec plusieurs GPU?",
    "answer": "Cette approche peut augmenter la vitesse d\u2019ex\u00e9cution de fa\u00e7on importante, avec une it\u00e9ration qui se fait environ N fois plus rapidement avec un grand jeu de donn\u00e9es, N \u00e9tant le nombre de copies du mod\u00e8le."
  },
  {
    "question": "Quelle est une pr\u00e9caution importante lors de l'utilisation de la parall\u00e9lisation des donn\u00e9es pour maintenir l'\u00e9quivalence avec un mod\u00e8le non-parall\u00e9lis\u00e9?",
    "answer": "Il faut adapter le taux d\u2019apprentissage ou la taille du lot d\u00e9sir\u00e9e en fonction du nombre de copies du mod\u00e8le."
  },
  {
    "question": "Quelle est la contrainte de taille du mod\u00e8le pour la parall\u00e9lisation des donn\u00e9es avec plusieurs GPU?",
    "answer": "Quand plusieurs GPU sont utilis\u00e9s, chacun re\u00e7oit une copie du mod\u00e8le; il doit donc \u00eatre assez petit pour \u00eatre contenu dans la m\u00e9moire d\u2019un GPU."
  },
  {
    "question": "Que doit-on faire si un mod\u00e8le PyTorch d\u00e9passe la m\u00e9moire d'un GPU et doit \u00eatre entra\u00een\u00e9 avec plusieurs GPU?",
    "answer": "Pour entra\u00eener un mod\u00e8le qui d\u00e9passe la quantit\u00e9 de m\u00e9moire d\u2019un GPU, il faut consulter la section 'Parall\u00e9liser un mod\u00e8le avec plusieurs GPU'."
  },
  {
    "question": "Quelle classe est recommand\u00e9e par les d\u00e9veloppeurs PyTorch pour la parall\u00e9lisation des donn\u00e9es avec plusieurs GPU?",
    "answer": "La classe `DistributedDataParallel` est recommand\u00e9e par les d\u00e9veloppeurs PyTorch, que ce soit avec un n\u0153ud unique ou avec plusieurs n\u0153uds."
  },
  {
    "question": "Quel probl\u00e8me est associ\u00e9 \u00e0 PyTorch 1.10 et `DistributedDataParallel` sur les grappes Compute Canada?",
    "answer": "Le code utilisant `DistributedDataParallel` avec PyTorch 1.10 (`torch-1.10.0+computecanada`) pourrait \u00e9chouer de fa\u00e7on impr\u00e9visible si le backend est d\u00e9fini comme \u00e9tant `'nccl'` ou `'gloo'`."
  },
  {
    "question": "Quelle est la recommandation pour \u00e9viter le probl\u00e8me avec PyTorch 1.10 et `DistributedDataParallel`?",
    "answer": "Il est recommand\u00e9 d'utiliser la version la plus r\u00e9cente de PyTorch plut\u00f4t que la version 1.10 sur toutes les grappes d'usage g\u00e9n\u00e9ral."
  },
  {
    "question": "Comment le crit\u00e8re de perte et l'optimiseur sont-ils d\u00e9finis et charg\u00e9s sur le GPU dans l'exemple de code Python pour un seul GPU?",
    "answer": "Le crit\u00e8re de perte est d\u00e9fini comme `nn.CrossEntropyLoss().cuda()` et l'optimiseur est `optim.SGD(net.parameters(), lr=args.lr)`."
  },
  {
    "question": "Comment les donn\u00e9es d'entra\u00eenement sont-elles pr\u00e9par\u00e9es dans l'exemple de code Python pour DistributedDataParallel?",
    "answer": "Les donn\u00e9es sont transform\u00e9es, le jeu de donn\u00e9es CIFAR10 est charg\u00e9, un `torch.utils.data.distributed.DistributedSampler` est cr\u00e9\u00e9, et un `DataLoader` est utilis\u00e9 avec ce sampler."
  },
  {
    "question": "Quelles variables d'environnement sont export\u00e9es dans le script bash `pytorch-ddp-test.sh` pour la configuration DistributedDataParallel?",
    "answer": "Les variables `TORCH_NCCL_ASYNC_HANDLING=1` et `MASTER_ADDR=$(hostname)` sont export\u00e9es."
  },
  {
    "question": "Comment le script Python `pytorch-ddp-test.py` est-il lanc\u00e9 pour une t\u00e2che DistributedDataParallel sur un cluster SLURM?",
    "answer": "Il est lanc\u00e9 avec `srun python pytorch-ddp-test.py --init_method tcp://$MASTER_ADDR:3456 --world_size $((SLURM_NTASKS_PER_NODE * SLURM_JOB_NUM_NODES)) --batch_size 256`."
  }
]