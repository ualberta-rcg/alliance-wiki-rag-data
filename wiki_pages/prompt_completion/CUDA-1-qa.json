[
  {
    "question": "What is CUDA?",
    "answer": "CUDA\u00ae is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs)."
  },
  {
    "question": "Who developed CUDA?",
    "answer": "CUDA was developed by NVIDIA."
  },
  {
    "question": "How can CUDA be understood in terms of programming tools?",
    "answer": "CUDA can be thought of as a set of libraries and associated C, C++, and Fortran compilers that enable writing code for GPUs."
  },
  {
    "question": "Are there other GPU programming tools besides CUDA mentioned in the document?",
    "answer": "Yes, OpenACC Tutorial is mentioned as another set of GPU programming tools."
  },
  {
    "question": "What is the CUDA C/C++ language compiler called?",
    "answer": "The CUDA C/C++ language compiler is called `nvcc`."
  },
  {
    "question": "What is the first step before compiling CUDA code?",
    "answer": "First, load a CUDA module."
  },
  {
    "question": "How do you load a CUDA module using the command line?",
    "answer": "You can load a CUDA module by running `module purge` followed by `module load cuda`."
  },
  {
    "question": "What file extension is important for CUDA C/C++ programs?",
    "answer": "The `cu` file extension is important for CUDA C/C++ programs."
  },
  {
    "question": "How do you compile a CUDA program named `add.cu` to create an executable named `add`?",
    "answer": "You compile the program with `nvcc add.cu -o add`."
  },
  {
    "question": "What does the example `add.cu` program do?",
    "answer": "The example `add.cu` program adds two numbers together on a GPU."
  },
  {
    "question": "What Slurm directives are used for a GPU job?",
    "answer": "Key Slurm directives include `#SBATCH --account=def-someuser`, `#SBATCH --gres=gpu:1`, `#SBATCH --mem=400M`, and `#SBATCH --time=0-00:10`."
  },
  {
    "question": "How do you submit a Slurm GPU job script named `gpu_job.sh`?",
    "answer": "You submit the job with the command `sbatch gpu_job.sh`."
  },
  {
    "question": "What does the `sbatch` command output upon successful job submission?",
    "answer": "It outputs 'Submitted batch job' followed by a job ID, for example, 'Submitted batch job 3127733'."
  },
  {
    "question": "What output would you expect from the `add` program after a successful GPU job?",
    "answer": "You would expect to see output like `2+7=9`."
  },
  {
    "question": "What output might occur if the `add` program is run without a GPU present?",
    "answer": "If run without a GPU, you might see output like `2+7=0`."
  },
  {
    "question": "How do you compile a CUDA program that needs to link libraries like cuBLAS?",
    "answer": "You compile with `nvcc -lcublas -Xlinker=-rpath,$CUDA_PATH/lib64`."
  },
  {
    "question": "What is 'compute capability' of a device?",
    "answer": "The 'compute capability' of a device is a version number that identifies the features supported by the GPU hardware and is used by applications at runtime to determine available hardware features."
  },
  {
    "question": "What is another term for compute capability?",
    "answer": "Compute capability is also sometimes called its 'SM version'."
  },
  {
    "question": "What common errors are connected with compute capability?",
    "answer": "Common errors include `nvcc fatal : Unsupported gpu architecture 'compute_XX'` and `no kernel image is available for execution on the device (209)`."
  },
  {
    "question": "How can you fix `nvcc` compilation errors related to unsupported GPU architecture?",
    "answer": "You can fix it by adding the flag `-gencode arch=compute_XX,code=[sm_XX,compute_XX]` to the `nvcc` call, replacing 'XX' with the correct compute capability."
  },
  {
    "question": "How do you specify compute capability when using `cmake`?",
    "answer": "When using `cmake`, provide the flag `cmake .. -DCMAKE_CUDA_ARCHITECTURES=XX`, replacing 'XX' with the correct compute capability."
  },
  {
    "question": "Where can you find the value for 'XX' representing the compute capability?",
    "answer": "You can find the value to replace 'XX' in the 'Available GPUs table' (e.g., [[Using GPUs with Slurm#Available_GPUs|Available GPUs table]])."
  },
  {
    "question": "What is the correct `nvcc` flag for a Narval A100 node with compute capability 80?",
    "answer": "The correct `nvcc` flag is `-gencode arch=compute_80,code=[sm_80,compute_80]`."
  },
  {
    "question": "What is the correct `cmake` flag for a Narval A100 node with compute capability 80?",
    "answer": "The correct `cmake` flag is `cmake .. -DCMAKE_CUDA_ARCHITECTURES=80`."
  }
]