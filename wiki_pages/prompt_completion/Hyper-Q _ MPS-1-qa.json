[
  {
    "question": "What is Hyper-Q?",
    "answer": "Hyper-Q (or MPS) is a feature of NVIDIA GPUs."
  },
  {
    "question": "What is the minimum CUDA compute capability required for Hyper-Q or MPS?",
    "answer": "It is available in GPUs with CUDA compute capability 3.5 and higher."
  },
  {
    "question": "According to NVIDIA, what is the purpose of the MPS runtime architecture?",
    "answer": "The MPS runtime architecture is designed to transparently enable co-operative multi-process CUDA applications, typically MPI jobs, to utilize Hyper-Q capabilities on the latest NVIDIA (Kepler and later) GPUs."
  },
  {
    "question": "What does Hyper-Q allow CUDA kernels to do?",
    "answer": "Hyper-Q allows CUDA kernels to be processed concurrently on the same GPU."
  },
  {
    "question": "When can Hyper-Q benefit performance?",
    "answer": "Hyper-Q can benefit performance when the GPU compute capacity is underutilized by a single application process."
  },
  {
    "question": "What is a benefit of MPS, even when the GPU is shared by unrelated CPU processes?",
    "answer": "In our tests, MPS may increase the total GPU flop rate even when the GPU is being shared by unrelated CPU processes."
  },
  {
    "question": "For what type of CUDA applications is MPS particularly beneficial?",
    "answer": "MPS is great for CUDA applications with relatively small problem sizes, which on their own cannot efficiently saturate modern GPUs with thousands of cores."
  },
  {
    "question": "Is MPS enabled by default?",
    "answer": "No, MPS is not enabled by default."
  },
  {
    "question": "What commands are needed to enable MPS before running a CUDA application?",
    "answer": "The commands are `export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps`, `export CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log`, and `nvidia-cuda-mps-control -d`."
  },
  {
    "question": "When can the MPS feature be used?",
    "answer": "You can use the MPS feature if you have more than one CPU thread accessing the GPU."
  },
  {
    "question": "What types of applications can utilize the MPS feature?",
    "answer": "The MPS feature can be utilized by hybrid MPI/CUDA applications, hybrid OpenMP/CUDA applications, or multiple instances of a serial CUDA application (GPU farming)."
  },
  {
    "question": "Where can additional details on MPS be found?",
    "answer": "Additional details on MPS can be found at the CUDA Multi Process Service (MPS) - NVIDIA Documentation."
  },
  {
    "question": "When is the MPS feature particularly useful for GPU farming?",
    "answer": "The MPS feature can be very useful when you need to run multiple instances of a CUDA application, but the application is too small to saturate a modern GPU."
  },
  {
    "question": "What is a key requirement for running multiple instances of an application on a single GPU using MPS?",
    "answer": "MPS allows you to run multiple instances of the application sharing a single GPU, as long as there is enough of GPU memory for all of the instances of the application."
  },
  {
    "question": "What is the expected outcome of using MPS for GPU farming?",
    "answer": "In many cases, using MPS for GPU farming should result in a significantly increased throughput from all of your GPU processes."
  },
  {
    "question": "What are the two important elements in the provided GPU farming job script example?",
    "answer": "The two important elements are `&` on the code execution line, which sends the code processes to the background, and the `wait` command at the end of the script, which ensures that the job runs until all background processes end."
  },
  {
    "question": "In the example job script, how many instances of 'my_code' share a single V100 GPU?",
    "answer": "In the example, a single V100 GPU is shared between 8 instances of `my_code`."
  },
  {
    "question": "Why does the example GPU farming script request 8 CPU cores?",
    "answer": "Eight CPU cores are requested so there is one CPU core per application instance."
  }
]