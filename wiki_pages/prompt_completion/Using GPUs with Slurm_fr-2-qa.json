[
  {
    "question": "Quel est le type de GPU disponible sur la grappe Narval et combien y en a-t-il par n\u0153ud?",
    "answer": "Sur la grappe Narval, les GPU sont de type A100 (mod\u00e8le A100-40gb) et il y en a 4 par n\u0153ud."
  },
  {
    "question": "Combien de c\u0153urs CPU et de m\u00e9moire CPU sont disponibles par n\u0153ud sur la grappe Narval?",
    "answer": "Sur la grappe Narval, chaque n\u0153ud dispose de 48 c\u0153urs CPU et de 510000M de m\u00e9moire CPU."
  },
  {
    "question": "Quelle est la m\u00e9moire GPU et l'attribut compute capability des GPU A100 sur Narval?",
    "answer": "Les GPU A100 sur Narval ont une m\u00e9moire de 40 GiB et un attribut compute capability de 80."
  },
  {
    "question": "Comment les GPU sont-ils connect\u00e9s sur les n\u0153uds Narval?",
    "answer": "Sur Narval, il y a deux GPU par socket CPU, et tous les GPU sont connect\u00e9s via NVLink."
  },
  {
    "question": "L'ordonnanceur Slurm g\u00e8re-t-il les ressources infonuagiques sur Arbutus?",
    "answer": "Non, l'ordonnanceur Slurm ne g\u00e8re pas les ressources infonuagiques sur Arbutus. Pour l'information sur le mat\u00e9riel disponible, il faut consulter la page \"Ressources infonuagiques\"."
  },
  {
    "question": "\u00c0 quoi sert le terme 'Compute Capability' d'NVIDIA?",
    "answer": "Le terme 'Compute Capability' est utilis\u00e9 par NVIDIA pour indiquer les fonctionnalit\u00e9s mat\u00e9rielles sp\u00e9cifiques \u00e0 un GPU particulier. Il n'a aucun rapport avec la performance des dispositifs et n'est utile que si vous compilez vos propres programmes GPU."
  },
  {
    "question": "Comment puis-je obtenir un n\u0153ud V100 de 16Go sur Graham?",
    "answer": "Pour acc\u00e9der \u00e0 un n\u0153ud V100 de 16Go sur Graham, utilisez les arguments `--constraint=skylake,v100` dans votre commande sbatch ou salloc."
  },
  {
    "question": "Comment puis-je obtenir un n\u0153ud V100 de 32Go sur Graham?",
    "answer": "Pour acc\u00e9der \u00e0 un n\u0153ud V100 de 32Go sur Graham, utilisez les arguments `--constraint=cascade,v100` dans votre commande sbatch ou salloc."
  },
  {
    "question": "Quelles sont les caract\u00e9ristiques principales de la grappe Mist?",
    "answer": "Mist est une grappe qui utilise des CPU IBM Power9 (et non Intel x86) et des GPU NVIDIA V100."
  },
  {
    "question": "Comment acc\u00e8de-t-on \u00e0 la grappe Mist?",
    "answer": "Si vous avez acc\u00e8s \u00e0 Niagara, vous avez \u00e9galement acc\u00e8s \u00e0 Mist. Les directives pour soumettre des t\u00e2ches se trouvent sur le site web de SciNet."
  },
  {
    "question": "Qu'est-ce que la technologie MIG sur Narval?",
    "answer": "La technologie MIG (Multi-Instance GPU) permet de partitionner un GPU en plusieurs instances et est actuellement disponible sur Narval en tant que projet pilote."
  },
  {
    "question": "Pourquoi est-il important de sp\u00e9cifier le type de GPU?",
    "answer": "Il est important de sp\u00e9cifier le type de GPU car certaines grappes (comme Cedar et Graham) poss\u00e8dent plus d'un type de GPU. Si le type n'est pas sp\u00e9cifi\u00e9, Slurm pourrait acheminer al\u00e9atoirement votre t\u00e2che vers un n\u0153ud \u00e9quip\u00e9 de n'importe quel type de GPU, ce qui pourrait ne pas \u00eatre souhaitable."
  },
  {
    "question": "Quel est un exemple de script pour une t\u00e2che Slurm n\u00e9cessitant un seul c\u0153ur CPU et un GPU?",
    "answer": "Un exemple de script pour une t\u00e2che \u00e0 un seul c\u0153ur avec un GPU inclut les directives `#SBATCH --gpus-per-node=1`, `#SBATCH --mem=4000M` et `#SBATCH --time=0-03:00`."
  },
  {
    "question": "Comment demander des CPU suppl\u00e9mentaires pour une t\u00e2che GPU multifils?",
    "answer": "Pour une t\u00e2che GPU multifils n\u00e9cessitant plusieurs CPU, vous pouvez utiliser `#SBATCH --gpus-per-node=1` et `#SBATCH --cpus-per-task=6` (pour 6 c\u0153urs CPU par t\u00e2che) dans votre script Slurm, puis exporter `OMP_NUM_THREADS`."
  },
  {
    "question": "Quel est le nombre maximum de c\u0153urs CPU recommand\u00e9 par GPU sur B\u00e9luga?",
    "answer": "Sur B\u00e9luga, un maximum de 10 c\u0153urs CPU est recommand\u00e9 par GPU demand\u00e9."
  },
  {
    "question": "Quelle est la recommandation de c\u0153urs CPU par GPU de type P100 sur Cedar?",
    "answer": "Sur Cedar, un maximum de 6 c\u0153urs CPU par GPU de type P100 (p100 et p100l) est recommand\u00e9."
  },
  {
    "question": "Combien de c\u0153urs CPU sont recommand\u00e9s par GPU de type V100 sur Cedar?",
    "answer": "Sur Cedar, un maximum de 8 c\u0153urs CPU par GPU de type V100 (v100l) est recommand\u00e9."
  },
  {
    "question": "Quel est le nombre maximum de c\u0153urs CPU recommand\u00e9 par GPU sur Graham?",
    "answer": "Sur Graham, un maximum de 16 c\u0153urs CPU est recommand\u00e9 par GPU."
  },
  {
    "question": "Quel est un exemple de script Slurm pour une t\u00e2che MPI utilisant plusieurs GPU?",
    "answer": "Un script Slurm pour une t\u00e2che MPI avec GPU pourrait inclure `#SBATCH --gpus=8` (pour un total de 8 GPU), `#SBATCH --ntasks-per-gpu=1` (8 processus MPI), `#SBATCH --cpus-per-task=6` et `#SBATCH --mem-per-cpu=5G`."
  },
  {
    "question": "Comment puis-je demander un n\u0153ud GPU entier sur Graham?",
    "answer": "Pour demander un n\u0153ud GPU entier sur Graham, vous pouvez utiliser un script Slurm avec `#SBATCH --nodes=1`, `#SBATCH --gpus-per-node=p100:2`, `#SBATCH --ntasks-per-node=32` et `#SBATCH --mem=127000M`."
  },
  {
    "question": "Comment demander un n\u0153ud GPU P100 entier sur Cedar?",
    "answer": "Pour demander un n\u0153ud GPU P100 entier sur Cedar, utilisez un script Slurm avec `#SBATCH --nodes=1`, `#SBATCH --gpus-per-node=p100:4`, `#SBATCH --ntasks-per-node=24`, `#SBATCH --exclusive` et `#SBATCH --mem=125G`."
  },
  {
    "question": "Quelles sont les sp\u00e9cificit\u00e9s des n\u0153uds P100-16G (P100L) sur Cedar?",
    "answer": "Les n\u0153uds P100-16G sur Cedar sont un groupe particulier de n\u0153uds ayant chacun quatre cartes Tesla P100 16Go. Leurs GPU utilisent le m\u00eame connecteur PCI pour une latence plus faible entre GPU, mais la bande passante CPU-GPU est plus basse. Ils ont 256Go de m\u00e9moire vive et le temps d'ex\u00e9cution maximal des t\u00e2ches sur ces GPU est de 28 jours."
  },
  {
    "question": "Comment demander un n\u0153ud P100-16G (P100L) entier sur Cedar?",
    "answer": "Pour demander un n\u0153ud P100-16G (P100L) entier sur Cedar, vous devez utiliser des n\u0153uds entiers et indiquer `--gres=gpu:p100l:4` dans votre commande Slurm. Le script doit inclure `#SBATCH --nodes=1`, `#SBATCH --gpus-per-node=p100l:4`, `#SBATCH --cpus-per-task=24` et `#SBATCH --mem=0` pour demander toute la m\u00e9moire du n\u0153ud."
  },
  {
    "question": "Quelle est la m\u00e9thode recommand\u00e9e pour ex\u00e9cuter plusieurs programmes utilisant un seul GPU pendant plus de 24 heures?",
    "answer": "Pour ex\u00e9cuter pendant plus de 24 heures plusieurs programmes utilisant un seul GPU ou deux programmes utilisant deux GPU, la recommandation est d'utiliser GNU Parallel."
  },
  {
    "question": "Comment utiliser GNU Parallel pour regrouper des t\u00e2ches et \u00e9viter la comp\u00e9tition pour les GPU?",
    "answer": "Vous pouvez utiliser `cat params.input | parallel -j4 'CUDA_VISIBLE_DEVICES=$(({%} - 1)) python {} &> {#}.out'`. Le param\u00e8tre `-j4` ex\u00e9cute quatre t\u00e2ches concurremment, et `CUDA_VISIBLE_DEVICES=$(({%} - 1))` attribue un GPU unique \u00e0 chaque t\u00e2che en utilisant l'identifiant de la fente."
  },
  {
    "question": "Comment d\u00e9sactiver DCGM pour le profilage des t\u00e2ches GPU sur B\u00e9luga et Narval?",
    "answer": "Pour d\u00e9sactiver DCGM (NVIDIA Data Center GPU Manager) sur B\u00e9luga et Narval lors de la soumission d'une t\u00e2che de profilage, utilisez le param\u00e8tre `--export=ALL,DISABLE_DCGM=1` dans votre script Slurm."
  }
]