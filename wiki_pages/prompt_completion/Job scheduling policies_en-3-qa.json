[
  {
    "question": "How many idle large memory nodes are available for whole-node jobs with a 3-hour runtime limit?",
    "answer": "According to the sample `partition-stats` output, there are 3 idle large memory nodes available for whole-node jobs with a 3-hour runtime limit."
  },
  {
    "question": "How many total 'regular' (base) nodes are available for whole-node jobs with a maximum walltime of 3 hours?",
    "answer": "There are 871 'regular' nodes available for whole-node jobs with a maximum walltime of 3 hours."
  },
  {
    "question": "What is the total number of GPU nodes that can receive by-core jobs with a 7-day (168 hr) walltime limit?",
    "answer": "There are 12 GPU nodes that can receive by-core jobs with a 7-day (168 hr) walltime limit."
  },
  {
    "question": "Based on the sample output, how many jobs were waiting that requested whole nodes, less than 8GB of memory per core, and 3 hours or less of run time?",
    "answer": "There were 12 jobs waiting to run that met these criteria."
  },
  {
    "question": "How many jobs were waiting that requested individual cores (less than whole nodes), less than 8GB memory per core, and 3 hours or less of run time?",
    "answer": "There were 170 such jobs waiting."
  },
  {
    "question": "How many jobs were waiting that requested a whole node equipped with GPUs and 3 hours or less of run time?",
    "answer": "There were 5 jobs waiting that requested a whole node equipped with GPUs and 3 hours or less of run time."
  },
  {
    "question": "How many jobs were waiting that requested single GPUs and 3 hours or less of run time?",
    "answer": "There were 14 jobs waiting that requested single GPUs and 3 hours or less of run time."
  },
  {
    "question": "Were there any jobs waiting or running that requested large-memory nodes and 3 hours of run time in the provided sample?",
    "answer": "No, there were no jobs running or waiting that requested large-memory nodes and 3 hours of run time in the provided `partition-stats` sample."
  },
  {
    "question": "What analogy is used to describe the hierarchy of partitions based on walltime?",
    "answer": "The partitions are described as being like Matryoshka (Russian) dolls, where shorter-duration partitions contain the nodes for longer-duration partitions as subsets."
  },
  {
    "question": "What kind of information does the `partition-stats` utility not provide?",
    "answer": "The `partition-stats` utility does not provide information about the number of cores represented by running or waiting jobs, the number of cores free in partly-assigned nodes in by-core partitions, or available memory associated with free cores."
  },
  {
    "question": "Is it advisable to repeatedly call the `partition-stats` utility automatically?",
    "answer": "No, running `partition-stats` is somewhat costly to the scheduler, so writing a script that automatically calls it repeatedly is discouraged."
  },
  {
    "question": "Who should a user contact if they believe their workflow would benefit from automatic parsing of `partition-stats` information?",
    "answer": "Users should contact Technical support for guidance if they believe their workflow would benefit from automatic parsing of the information from `partition-stats`."
  },
  {
    "question": "Is there a limit on the number of jobs a user can have in the system at any one time?",
    "answer": "Yes, there may be a limit on the number of jobs a user can have in the system at any one time."
  },
  {
    "question": "What is the maximum number of jobs a normal account can have in a pending or running state on Graham and B\u00e9luga?",
    "answer": "On Graham and B\u00e9luga, normal accounts can have no more than 1000 jobs in a pending or running state at any time."
  },
  {
    "question": "How are tasks within a job array counted towards the overall job limit?",
    "answer": "Each task of a job array counts as one job towards the limit."
  },
  {
    "question": "Which Slurm parameter is used to enforce the job submission limit?",
    "answer": "The job submission limit is applied using Slurm's `MaxSubmit` parameter."
  }
]