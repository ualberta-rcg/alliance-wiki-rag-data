[
  {
    "question": "What is RAPIDS?",
    "answer": "RAPIDS is a suite of open source software libraries from NVIDIA mainly for executing data science and analytics pipelines in Python on GPUs."
  },
  {
    "question": "What does RAPIDS rely on for low-level compute optimization?",
    "answer": "RAPIDS relies on NVIDIA CUDA primitives for low-level compute optimization."
  },
  {
    "question": "What are the Python APIs in RAPIDS similar to?",
    "answer": "The Python APIs in RAPIDS are similar to those found in Pandas or Scikit-learn."
  },
  {
    "question": "What is cuDF used for in RAPIDS?",
    "answer": "cuDF is a Python GPU DataFrame library used for loading, joining, aggregating, filtering, and otherwise manipulating data, built on the Apache Arrow columnar memory format."
  },
  {
    "question": "What is cuML?",
    "answer": "cuML is a suite of libraries that implement machine learning algorithms and mathematical primitive functions with compatible APIs with other RAPIDS projects."
  },
  {
    "question": "What functionality does cuGraph provide?",
    "answer": "cuGraph is a GPU accelerated graph analytics library with functionality like NetworkX, seamlessly integrated into the RAPIDS data science platform."
  },
  {
    "question": "What are Cyber Log Accelerators (CLX)?",
    "answer": "CLX, or 'clicks,' are a collection of RAPIDS examples for security analysts, data scientists, and engineers to quickly apply RAPIDS and GPU acceleration to cybersecurity use cases."
  },
  {
    "question": "What is cuxFilter's purpose?",
    "answer": "cuxFilter is a connector library that provides connections between different visualization libraries and a GPU dataframe, allowing charts from different libraries to be used in a single dashboard with interaction."
  },
  {
    "question": "What does cuSpatial accelerate?",
    "answer": "cuSpatial accelerates GIS workflows including point-in-polygon, spatial join, coordinate systems, shape primitives, distances, and trajectory analysis."
  },
  {
    "question": "How does cuSignal achieve GPU acceleration for signal processing?",
    "answer": "cuSignal leverages CuPy, Numba, and the RAPIDS ecosystem for GPU accelerated signal processing, sometimes by directly porting Scipy Signal or using Numba CUDA kernels."
  },
  {
    "question": "What is cuCIM designed for?",
    "answer": "cuCIM is an extensible toolkit designed to provide GPU accelerated I/O, computer vision & image processing primitives for N-Dimensional images, with a focus on biomedical imaging."
  },
  {
    "question": "What is the function of the RAPIDS Memory Manager (RMM)?",
    "answer": "RMM is a central place for all device memory allocations in cuDF and other RAPIDS libraries. It also replaces the CUDA Device Memory allocator and acts as a pool allocator for faster, asynchronous CUDA device memory allocation/deallocation."
  },
  {
    "question": "What is the first step to build an Apptainer image for RAPIDS?",
    "answer": "The first step is to find and select a Docker image provided by NVIDIA."
  },
  {
    "question": "What was Apptainer formerly known as?",
    "answer": "Apptainer was formerly called Singularity."
  },
  {
    "question": "What are the two types of RAPIDS Docker images available from v23.08 onwards?",
    "answer": "Starting with the RAPIDS v23.08 release, there are 'base' and 'notebooks' types of RAPIDS Docker images."
  },
  {
    "question": "Where can you find the image tag for a selected Docker image?",
    "answer": "You can find the image tag of a selected image under the 'Tags' tab on each site in the NVIDIA NGC catalog."
  },
  {
    "question": "When should you use a RAPIDS Base Docker image?",
    "answer": "Use a RAPIDS Base image if you want a RAPIDS environment ready for use, especially if you plan to submit a job to the Slurm scheduler."
  },
  {
    "question": "When is a RAPIDS Notebooks Docker image recommended?",
    "answer": "Use a RAPIDS Notebooks image if you want to interactively work with RAPIDS through notebooks and examples, as it extends the base image by adding a Jupyter notebook server."
  },
  {
    "question": "What command is used to build an Apptainer image from a Docker image tag?",
    "answer": "You can build an Apptainer image with the command: `apptainer build rapids.sif docker://nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.0-py3.12` (using the example tag provided)."
  },
  {
    "question": "How long does it typically take to build a RAPIDS Apptainer image?",
    "answer": "It usually takes from thirty to sixty minutes to complete the image-building process."
  },
  {
    "question": "What resources are required to build a RAPIDS Apptainer image?",
    "answer": "You need to have enough memory and disk space on the server to build such an image, as its size is relatively large."
  },
  {
    "question": "What can you do with a RAPIDS Apptainer image on a cluster?",
    "answer": "Once you have an Apptainer image for RAPIDS, you can request an interactive session on a GPU node or submit a batch job to Slurm."
  },
  {
    "question": "How do you start the RAPIDS shell on a GPU node after loading Apptainer?",
    "answer": "Start the RAPIDS shell with `apptainer shell --nv rapids.sif` after loading the Apptainer module."
  },
  {
    "question": "What is the function of the `--nv` option when running `apptainer shell`?",
    "answer": "The `--nv` option binds the GPU driver on the host to the container, allowing the GPU device to be accessed from inside the Apptainer container."
  },
  {
    "question": "How can you check GPU statistics within the Apptainer container?",
    "answer": "After the shell prompt changes to `Apptainer>`, you can check GPU stats with `nvidia-smi`."
  },
  {
    "question": "How do you launch a Jupyter Notebook server in the RAPIDS Apptainer environment?",
    "answer": "Launch the Jupyter Notebook server with `jupyter-lab --ip $(hostname -f) --no-browser` from the Apptainer prompt."
  },
  {
    "question": "What is a key feature of RAPIDS v23.08 release regarding packages in the container?",
    "answer": "Starting with the RAPIDS v23.08 release, all packages are included in the base conda environment which is activated by default in the container shell."
  },
  {
    "question": "What should be done if a compute node lacks a direct Internet connection for JupyterLab?",
    "answer": "You would need to set up an SSH tunnel with port forwarding between your local computer and the GPU node."
  },
  {
    "question": "What is a good practice for RAPIDS jobs submitted to the Slurm scheduler when using containers?",
    "answer": "It is a good practice to use the local disk on a compute node when working via a container."
  },
  {
    "question": "What command is used to execute a Python RAPIDS script within an Apptainer container in a Slurm job?",
    "answer": "The command `apptainer exec --nv rapids.sif python ./my_rapids_code.py` is used to execute the script."
  },
  {
    "question": "What should be done with results from a RAPIDS job before it terminates on Slurm?",
    "answer": "Any results should be saved to your `/project` or user's project directory (e.g., `~/projects/def-someuser/username/`) before the job terminates."
  },
  {
    "question": "Where can users find documentation for RAPIDS?",
    "answer": "Users can find documentation at the RAPIDS Docs link, which is a collection of all documentation for RAPIDS, how to stay connected and report issues."
  },
  {
    "question": "Where can one find example notebooks for RAPIDS?",
    "answer": "A collection of example notebooks for getting started quickly can be found on GitHub at RAPIDS Notebooks."
  },
  {
    "question": "Where can users find use cases and blogs related to RAPIDS applications?",
    "answer": "A collection of use cases and blogs for RAPIDS applications is available on RAPIDS on Medium."
  }
]