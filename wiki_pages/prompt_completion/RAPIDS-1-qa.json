[
  {
    "question": "What is RAPIDS?",
    "answer": "RAPIDS is a suite of open-source software libraries from NVIDIA designed for executing data science and analytics pipelines in Python on GPUs."
  },
  {
    "question": "What low-level optimization does RAPIDS rely on?",
    "answer": "RAPIDS relies on NVIDIA CUDA primitives for low-level compute optimization."
  },
  {
    "question": "What kind of APIs does RAPIDS provide?",
    "answer": "RAPIDS provides friendly Python APIs, similar to those found in Pandas or Scikit-learn."
  },
  {
    "question": "What is cuDF used for in RAPIDS?",
    "answer": "cuDF is a Python GPU DataFrame library, built on the Apache Arrow columnar memory format, used for loading, joining, aggregating, filtering, and manipulating data."
  },
  {
    "question": "What is cuML?",
    "answer": "cuML is a suite of libraries within RAPIDS that implement machine learning algorithms and mathematical primitive functions, sharing compatible APIs with other RAPIDS projects."
  },
  {
    "question": "What is the purpose of cuGraph?",
    "answer": "cuGraph is a GPU accelerated graph analytics library, similar to NetworkX, that is seamlessly integrated into the RAPIDS data science platform."
  },
  {
    "question": "What does CLX stand for and what is its function?",
    "answer": "CLX stands for Cyber Log Accelerators and is a collection of RAPIDS examples for security analysts, data scientists, and engineers to apply RAPIDS and GPU acceleration to cybersecurity use cases."
  },
  {
    "question": "How does cuxFilter help with visualization?",
    "answer": "cuxFilter is a connector library that provides connections between different visualization libraries and a GPU dataframe, allowing charts from various libraries to be used in a single, interactive dashboard."
  },
  {
    "question": "What kind of workflows does cuSpatial accelerate?",
    "answer": "cuSpatial is a GPU accelerated C++/Python library that accelerates GIS workflows, including point-in-polygon, spatial join, coordinate systems, shape primitives, distances, and trajectory analysis."
  },
  {
    "question": "How does cuSignal achieve GPU acceleration for signal processing?",
    "answer": "cuSignal leverages CuPy, Numba, and the RAPIDS ecosystem for GPU accelerated signal processing. It can be a direct port of Scipy Signal and also contains Numba CUDA kernels for additional speedups."
  },
  {
    "question": "What is cuCIM designed for?",
    "answer": "cuCIM is an extensible toolkit providing GPU accelerated I/O, computer vision, and image processing primitives for N-Dimensional images, with a specific focus on biomedical imaging."
  },
  {
    "question": "What is the role of RAPIDS Memory Manager (RMM)?",
    "answer": "RMM is a central place for all device memory allocations in cuDF (C++ and Python) and other RAPIDS libraries. It acts as a replacement allocator for CUDA Device Memory and a pool allocator for faster, asynchronous allocations."
  },
  {
    "question": "What is the first step to build an Apptainer image for RAPIDS?",
    "answer": "The first step is to find and select a Docker image provided by NVIDIA."
  },
  {
    "question": "What are the two types of RAPIDS Docker images available starting with v23.08 release?",
    "answer": "Starting with the RAPIDS v23.08 release, there are two types of RAPIDS Docker images: 'base' and 'notebooks'."
  },
  {
    "question": "When should you use a RAPIDS 'base' Docker image?",
    "answer": "You should use a 'base' type of RAPIDS Docker image if you want to submit a job to the Slurm scheduler, as it contains a RAPIDS environment ready for use."
  },
  {
    "question": "When should you use a RAPIDS 'notebooks' Docker image?",
    "answer": "You should use a 'notebooks' type of RAPIDS Docker image if you want to interactively work with RAPIDS through notebooks and examples, as it extends the base image with a Jupyter notebook server and example notebooks."
  },
  {
    "question": "Where can you find the Docker pull command for a selected RAPIDS image?",
    "answer": "You can find the Docker `pull` command for a selected image under the 'Tags' tab on the NVIDIA catalog site for RAPIDS Base or RAPIDS Notebooks containers."
  },
  {
    "question": "How do you build an Apptainer image from a Docker pull command?",
    "answer": "You can build an Apptainer image using a command like `apptainer build rapids.sif docker://nvcr.io/nvidia/rapidsai/rapidsai:cuda11.0-runtime-centos7`, replacing the example Docker pull tag with your selected one."
  },
  {
    "question": "How long does it typically take to build an Apptainer image for RAPIDS?",
    "answer": "It usually takes from thirty to sixty minutes to complete the image-building process."
  },
  {
    "question": "What resources are needed to build a RAPIDS Apptainer image?",
    "answer": "You need to have enough memory and disk space on the server to build such an image, as the image size is relatively large."
  }
]