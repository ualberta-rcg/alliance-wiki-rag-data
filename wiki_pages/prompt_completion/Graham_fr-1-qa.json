[
  {
    "question": "What system has replaced Graham?",
    "answer": "Graham has been replaced by a new cluster named Nibi."
  },
  {
    "question": "Where can I find information about Graham's capacity or service reductions during its transition period?",
    "answer": "Information on the capacity of each system as well as service interruptions or reductions will be available on the Infrastructure renewal page."
  },
  {
    "question": "When did Graham become available?",
    "answer": "Graham has been available since 2017."
  },
  {
    "question": "What is the login node address for Graham?",
    "answer": "The login node for Graham is graham.alliancecan.ca."
  },
  {
    "question": "What is the Globus collection identifier for Graham?",
    "answer": "The Globus collection for Graham is computecanada#graham-globus."
  },
  {
    "question": "Which nodes should be used for copying data via rsync, scp, or sftp on Graham?",
    "answer": "For copying data via rsync, scp, or sftp, you should use a login node or the robot node."
  },
  {
    "question": "Where is the Graham system located and what type of system is it?",
    "answer": "Graham is a heterogeneous system located at the Universit\u00e9 de Waterloo, adapted for a wide variety of task types."
  },
  {
    "question": "After whom is the Graham system named?",
    "answer": "Graham is named after Wes Graham, the first director of the Computing Centre at the Universit\u00e9 de Waterloo."
  },
  {
    "question": "What kind of cooling system does Graham utilize?",
    "answer": "Graham uses a liquid cooling system with heat exchangers located within the rear doors."
  },
  {
    "question": "Do Graham's compute nodes have internet access by default?",
    "answer": "No, according to policy, Graham's compute nodes do not have access to the internet."
  },
  {
    "question": "What information is needed to request an exception for internet access on Graham's compute nodes?",
    "answer": "To request an exception for internet access, contact technical support with the IP address, port(s), protocol (TCP or UDP), contact person, and end date."
  },
  {
    "question": "Is Crontab functionality available on Graham?",
    "answer": "No, Crontab is not offered on Graham."
  },
  {
    "question": "What is the minimum duration for a regular task on Graham, and for a test task?",
    "answer": "A regular task should have a minimum duration of one hour, and a test task has a minimum of five minutes."
  },
  {
    "question": "What is the maximum duration for a task on Graham?",
    "answer": "The maximum duration for a task on Graham is 168 hours, or seven days."
  },
  {
    "question": "What is the limit for the total number of running and pending tasks on Graham?",
    "answer": "The total number of tasks in execution and pending at the same time cannot exceed 1000, with array jobs counted individually."
  },
  {
    "question": "What is the total volume of the /home space on Graham?",
    "answer": "The total volume of the /home space on Graham is 133To."
  },
  {
    "question": "How are /home directories managed on Graham, and are they backed up?",
    "answer": "Each /home directory has a small fixed quota, is not allocated via the rapid access service or resource allocation competition, and is backed up daily."
  },
  {
    "question": "What is the total volume of the /scratch space on Graham?",
    "answer": "The total volume of the /scratch space on Graham is 3.2Po."
  },
  {
    "question": "Describe the purpose and characteristics of the /scratch space on Graham.",
    "answer": "The /scratch space is a high-performance parallel file system used for active or temporary storage, not allocated, with a large fixed quota per user, and inactive data is purged."
  },
  {
    "question": "What is the total volume of the /project space on Graham?",
    "answer": "The total volume of the /project space on Graham is 16Po."
  },
  {
    "question": "How is /project space allocated, and is it suitable for parallel read/write tasks?",
    "answer": "/project space is allocated via the rapid access service or resource allocation competition, and is not suitable for parallel read/write tasks; /scratch should be used instead."
  },
  {
    "question": "Does /project space on Graham have quotas, and is it backed up?",
    "answer": "Yes, /project space has a large adjustable quota per project and is backed up daily."
  },
  {
    "question": "What are the speeds of the InfiniBand Mellanox interconnects on Graham?",
    "answer": "Graham uses InfiniBand Mellanox FDR (56Go/s) and EDR (100Go/s) interconnects."
  },
  {
    "question": "Which types of nodes on Graham use FDR interconnects, and which use EDR?",
    "answer": "FDR serves GPU and cloud nodes, while all other node types use EDR."
  },
  {
    "question": "What network connections do cloud service nodes on Graham possess?",
    "answer": "Nodes configured for cloud service also have a 10Go/s Ethernet network and 40Go/s links to the /scratch storage."
  },
  {
    "question": "What is the dedicated VNC connection node for visualization on Graham?",
    "answer": "Graham offers dedicated nodes for visualization that allow only VNC connections, accessible via gra-vdi.alliancecan.ca."
  },
  {
    "question": "Why was Graham's capacity reduced at the beginning of 2025?",
    "answer": "Graham's capacity was reduced at the beginning of 2025 to allow for the installation of the new Nibi system."
  },
  {
    "question": "Do Graham's nodes support Intel Turbo Boost?",
    "answer": "Yes, all nodes on Graham are equipped with the Intel Turbo Boost functionality."
  },
  {
    "question": "Why is the 'available memory' value lower than the 'rounded suggested value' in Graham's node configurations?",
    "answer": "The available memory is lower because a certain amount is constantly used by the kernel and the operating system."
  },
  {
    "question": "How does the scheduler prevent swapping or paging due to memory overuse on Graham?",
    "answer": "The scheduler will never allocate a task whose requirements exceed the available memory indicated in the table to avoid swapping or paging."
  },
  {
    "question": "What is recommended for memory requests when running I/O intensive tasks on Graham?",
    "answer": "When I/O operations are numerous, it is preferable to ask for more memory than the total amount required by the processes to account for kernel and file system buffer operations."
  },
  {
    "question": "List the three generations of Tesla GPUs available on Graham, from oldest to newest.",
    "answer": "The three generations of Tesla GPUs, from oldest to newest, are V100 Volta, GPU Turing Ts4, and A100 Ampere."
  },
  {
    "question": "Are Pascal P100 GPU nodes still in service on Graham?",
    "answer": "No, the P100 GPUs are no longer in service."
  },
  {
    "question": "What performance benefits do V100 GPUs offer over P100 GPUs?",
    "answer": "V100 GPUs offer twice the performance for standard calculations and eight times more performance for deep learning calculations using their Tensor cores compared to P100s."
  },
  {
    "question": "What are the key strengths of T4 GPUs on Graham?",
    "answer": "T4 GPUs are adapted for deep learning tasks, offer good single-precision performance, possess Tensor cores, and can process reduced-precision integer calculations."
  },
  {
    "question": "How many Volta GPU nodes does Graham have, and do they feature NVLINK?",
    "answer": "Graham has two Volta GPU nodes in total that feature a wide-bandwidth NVLINK interconnect."
  },
  {
    "question": "What is the maximum duration for tasks submitted to Volta GPU nodes on Graham?",
    "answer": "Volta GPU nodes are available to all users for a maximum execution duration of 7 days."
  },
  {
    "question": "What CPU/GPU ratio is recommended for Volta nodes with 28 cores?",
    "answer": "For Volta nodes with 28 cores, it's recommended to apply a CPU/GPU ratio of 3.5 or less, e.g., at most 14 CPU cores for 4 GPUs, or at most 3 CPU cores for 1 GPU."
  },
  {
    "question": "How do you specifically request the newer 40-core Volta nodes for a job?",
    "answer": "To use one of these newer 40-core Volta nodes, you must add the parameter `constraint=cascade,v100` to the job submission script."
  },
  {
    "question": "How should the fast local disk on Volta nodes be used for I/O-intensive jobs?",
    "answer": "For I/O-intensive jobs, the fast local disk should be used via the `$SLURM_TMPDIR` environment variable, where data files can be copied."
  },
  {
    "question": "What happens to files in `$SLURM_TMPDIR` on Volta nodes after a job completes?",
    "answer": "All files contained in `$SLURM_TMPDIR` are deleted when the task is finished."
  },
  {
    "question": "What Slurm option is used to request two Turing T4 GPU cards per node?",
    "answer": "To request two Turing T4 GPU cards per node, use `--gres=gpu:t4:2`."
  },
  {
    "question": "What Slurm option is used to request two Ampere A100 GPU cards per node?",
    "answer": "To request two Ampere A100 GPU cards per node, use `--gres=gpu:a100:2`."
  },
  {
    "question": "What Slurm option is used to request two Ampere RTX A5000 GPU cards per node?",
    "answer": "To request two Ampere RTX A5000 GPU cards per node, use `--gres=gpu:a5000:2`."
  },
  {
    "question": "From what date will Graham's capacity be limited to approximately 25%?",
    "answer": "Graham's capacity will be limited to approximately 25% starting from January 13, 2025."
  },
  {
    "question": "Why will Graham's capacity be limited to 25% starting January 13, 2025?",
    "answer": "Graham's capacity will be limited to approximately 25% until Nibi is available."
  },
  {
    "question": "Which node configuration on Graham includes 8x NVIDIA V100 Volta GPUs with NVLINK?",
    "answer": "The configuration with 2 nodes, 40 cores, 377G memory, 2x Intel Xeon Gold 6248 Cascade Lake CPUs, and 5.0TB NVMe SSD includes 8x NVIDIA V100 Volta GPUs with NVLINK."
  },
  {
    "question": "What are the specifications of the nodes equipped with 4x NVIDIA T4 Turing GPUs and 11.0TB SATA SSD storage?",
    "answer": "There are 6 such nodes, each with 16 cores, 187G memory, and 2x Intel Xeon Silver 4110 Skylake CPUs."
  },
  {
    "question": "Which Graham node configuration provides 8x NVIDIA A100 Ampere GPUs?",
    "answer": "There is 1 node with 128 cores, 2000G memory, 2x AMD EPYC 7742 CPUs, and 3.5TB SATA SSD storage, featuring 8x NVIDIA A100 Ampere GPUs."
  },
  {
    "question": "What are the characteristics of the nodes equipped with 4x NVIDIA RTX A5000 Ampere GPUs?",
    "answer": "There are 11 such nodes, each with 64 cores, 128G memory, 1x AMD EPYC 7713 CPU, and 1.8TB SATA SSD storage."
  },
  {
    "question": "Describe the non-GPU nodes on Graham that feature 1024G of memory.",
    "answer": "There are 6 such nodes, each with 32 cores, 1x AMD EPYC 7543 CPU, and 8x2TB NVMe storage."
  },
  {
    "question": "How can a user specify that a job must be executed with a Cascade Lake CPU architecture?",
    "answer": "To specify a Cascade Lake CPU architecture for a job, use `--constraint=cascade`."
  },
  {
    "question": "What is Graham's architectural design goal regarding parallel tasks?",
    "answer": "Graham's architecture was planned to support multiple parallel tasks up to 1024 cores thanks to a non-blocking network."
  },
  {
    "question": "For most applications, should users prioritize selecting a specific CPU type on Graham?",
    "answer": "For most applications, differences in performance between Broadwell, Skylake, or Cascade Lake nodes are minimal compared to wait times, so selecting a particular node type is not recommended."
  }
]