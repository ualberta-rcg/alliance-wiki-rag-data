[
  {
    "question": "What is the current status of the Graham cluster?",
    "answer": "Graham has been retired and replaced by a new system, Nibi."
  },
  {
    "question": "When did the Graham cluster become available?",
    "answer": "Graham has been in production since June 2017."
  },
  {
    "question": "What is the login node address for Graham?",
    "answer": "The login node for Graham is graham.alliancecan.ca."
  },
  {
    "question": "What is the Globus collection identifier for Graham?",
    "answer": "The Globus collection identifier is computecanada#graham-globus."
  },
  {
    "question": "How should data transfers be performed on Graham using tools like rsync or scp?",
    "answer": "For data transfer using rsync, scp, sftp, etc., use the robot or login nodes."
  },
  {
    "question": "What type of cluster is Graham and where is it located?",
    "answer": "Graham is a heterogeneous cluster, suitable for a variety of workloads, and located at the University of Waterloo."
  },
  {
    "question": "Who was the Graham cluster named after?",
    "answer": "It is named after Wes Graham, the first director of the Computing Centre at Waterloo."
  },
  {
    "question": "How does Graham manage its cooling?",
    "answer": "Graham is entirely liquid cooled, using rear-door heat exchangers."
  },
  {
    "question": "What is the policy regarding internet access for Graham's compute nodes?",
    "answer": "By policy, Graham's compute nodes cannot access the internet."
  },
  {
    "question": "How can one request an exception for internet access on Graham's compute nodes?",
    "answer": "To request an exception, contact technical support with the IP, Port/s, Protocol (TCP or UDP), Contact, and Removal Date."
  },
  {
    "question": "Is Crontab functionality available on Graham?",
    "answer": "Crontab is not offered on Graham."
  },
  {
    "question": "What are the duration requirements for jobs on Graham?",
    "answer": "Each job on Graham should have a duration of at least one hour (five minutes for test jobs) and no more than 168 hours (seven days)."
  },
  {
    "question": "What is the maximum number of simultaneous jobs a user can have on Graham?",
    "answer": "A user cannot have more than 1000 jobs, running and queued, at any given moment, with an array job counting as the number of tasks in the array."
  },
  {
    "question": "What is the total volume and primary purpose of Home space on Graham?",
    "answer": "Home space has a 133TB total volume, is the location of home directories, has a small fixed quota, and daily backup."
  },
  {
    "question": "What is the total volume and primary purpose of Scratch space on Graham?",
    "answer": "Scratch space has a 3.2PB total volume, is a parallel high-performance filesystem for active or temporary storage, has a large fixed quota per user, and inactive data will be purged."
  },
  {
    "question": "How is Project space allocated on Graham?",
    "answer": "Project space is allocated via RAS (Rapid Access Service) or RAC (Resource Allocation Competition)."
  },
  {
    "question": "Is Project space recommended for parallel I/O workloads?",
    "answer": "No, Project space is not designed for parallel I/O workloads; users should use Scratch space instead."
  },
  {
    "question": "What types of InfiniBand interconnects are used on Graham and for which nodes?",
    "answer": "Mellanox FDR (56Gb/s) is used for GPU and cloud nodes, while EDR (100Gb/s) is used for other node types."
  },
  {
    "question": "What is the high-performance interconnect design for parallel jobs on Graham?",
    "answer": "The design of Graham is to support multiple simultaneous parallel jobs of up to 1024 cores in a fully non-blocking manner."
  },
  {
    "question": "What is the blocking factor for larger jobs on Graham's interconnect?",
    "answer": "For larger jobs, the interconnect has an 8:1 blocking factor."
  },
  {
    "question": "How can users access visualization nodes on Graham?",
    "answer": "Graham has dedicated visualization nodes available at gra-vdi.alliancecan.ca that allow only VNC connections."
  },
  {
    "question": "Is Intel Turbo Boost enabled on Graham nodes?",
    "answer": "Yes, Turbo Boost is enabled for all Graham nodes."
  },
  {
    "question": "What are the specifications of the two Graham nodes equipped with 8x NVIDIA V100 Volta GPUs?",
    "answer": "These 2 nodes have 40 cores, 377GB (or 386048M) available memory, 2 x Intel Xeon Gold 6248 Cascade Lake @ 2.5GHz CPUs, and 5.0TB NVMe SSD storage."
  },
  {
    "question": "Which GPU generations are available on Graham, listed from oldest to newest?",
    "answer": "Graham contains V100 Volta, T4 Turing, and A100 Ampere GPUs."
  },
  {
    "question": "What GPU generation has been decommissioned from Graham?",
    "answer": "P100 GPUs have been decommissioned."
  },
  {
    "question": "What is the maximum job duration for Volta GPU nodes?",
    "answer": "The maximum job duration for Volta GPU nodes is seven days."
  },
  {
    "question": "What CPU to GPU ratio is recommended for Volta nodes with 28 cores?",
    "answer": "You should scale the number of CPUs requested, keeping the ratio of CPUs to GPUs at 3.5 or less on 28 core nodes."
  },
  {
    "question": "How do you explicitly request one of the newest Volta NVLINK nodes in a job script?",
    "answer": "You should request it directly by adding the `--constraint=cascade,v100` parameter to the job submission script."
  },
  {
    "question": "What is the best practice for using local on-node storage for jobs on Graham?",
    "answer": "Best practice for local on-node storage is to use the temporary directory generated by Slurm, `$SLURM_TMPDIR`."
  },
  {
    "question": "How do you request Turing GPU cards in a job submission script?",
    "answer": "When requesting Turing GPU nodes, you should specify `--gres=gpu:t4:2` (as an example for two cards)."
  },
  {
    "question": "How do you request Ampere GPU cards in a job submission script?",
    "answer": "When requesting Ampere GPU nodes, you should specify `--gres=gpu:a100:2` or `--gres=gpu:a5000:2` (as examples for two cards)."
  },
  {
    "question": "What reduction in capacity did Graham experience starting in January 2025?",
    "answer": "Starting January 13, 2025, the Graham cluster began operating at approximately 25% capacity."
  },
  {
    "question": "Why is the available memory on Graham nodes less than the 'round number' suggested by hardware configuration?",
    "answer": "Some of the memory is permanently occupied by the kernel and OS, so the scheduler will never allocate jobs whose memory requirements exceed the specified available amount."
  },
  {
    "question": "Should users select a specific node type (Skylake or Cascade Lake) for their jobs on Graham?",
    "answer": "Most applications will run on either Skylake or Cascade Lake nodes with small performance differences, so it's recommended not to select a specific node type unless necessary."
  }
]