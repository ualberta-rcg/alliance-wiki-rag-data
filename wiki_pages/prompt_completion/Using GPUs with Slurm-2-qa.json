[
  {
    "question": "What is the default number of CPU cores allocated per GPU instance for a job?",
    "answer": "The default number of CPU cores along with each GPU instance is 1."
  },
  {
    "question": "Where can I find the recommended maximum CPU cores and system memory per GPU instance?",
    "answer": "The recommended maximum numbers of CPU cores and gigabytes of system memory per GPU instance are listed in the table of bundle characteristics."
  },
  {
    "question": "How do you request a single CPU core and one GPU for a Slurm job?",
    "answer": "For a single CPU core and one GPU, you can use a script with `#SBATCH --gpus-per-node=1` and `#SBATCH --mem=4000M` for memory, as shown in the single-core job example."
  },
  {
    "question": "What Slurm directives are used for a multi-threaded GPU job within a single node?",
    "answer": "For a multi-threaded GPU job needing multiple CPUs in a single node, you would typically use `#SBATCH --gpus-per-node=1` for the number of GPUs and `#SBATCH --cpus-per-task=6` for CPU cores/threads, along with `export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK`."
  },
  {
    "question": "What is the recommended maximum number of CPU cores per GPU on the Fir cluster?",
    "answer": "On Fir, it is recommended to use no more than 12 CPU cores per GPU requested."
  },
  {
    "question": "What is the recommended maximum number of CPU cores per GPU on the Narval cluster?",
    "answer": "On Narval, it is recommended to use no more than 12 CPU cores per GPU requested."
  },
  {
    "question": "What is the recommended maximum number of CPU cores per GPU on the Nibi cluster?",
    "answer": "On Nibi, it is recommended to use no more than 14 CPU cores per GPU requested."
  },
  {
    "question": "What is the recommended maximum number of CPU cores per GPU on the Rorqual cluster?",
    "answer": "On Rorqual, it is recommended to use no more than 16 CPU cores per GPU requested."
  },
  {
    "question": "How do you request 8 total GPUs, 8 MPI processes, and specific CPU and memory settings for an MPI job?",
    "answer": "You can use the following Slurm directives: `#SBATCH --gpus=8`, `#SBATCH --ntasks-per-gpu=1`, `#SBATCH --cpus-per-task=6`, and `#SBATCH --mem-per-cpu=5G`."
  },
  {
    "question": "When might it be beneficial to request a whole node for a Slurm job?",
    "answer": "If your application can efficiently use an entire node and its associated GPUs, you will probably experience shorter wait times if you ask Slurm for a whole node."
  },
  {
    "question": "What tool is recommended for packing multiple single-GPU jobs or two 2-GPU programs that run longer than 24 hours?",
    "answer": "GNU Parallel is recommended for packing single-GPU jobs or two 2-GPU programs that run for longer than 24 hours."
  },
  {
    "question": "How can GNU Parallel be used to run four concurrent single-GPU programs?",
    "answer": "A simple example is `cat params.input | parallel -j4 'CUDA_VISIBLE_DEVICES=$(({%} - 1)) python {} &> {#}.out'`, where `-j4` allows four concurrent tasks and `CUDA_VISIBLE_DEVICES` manages GPU allocation."
  },
  {
    "question": "What is the purpose of the `-j4` parameter in a GNU Parallel command?",
    "answer": "The `-j4` parameter in a GNU Parallel command means that GNU Parallel can run a maximum of four concurrent tasks, launching another as soon as one ends."
  },
  {
    "question": "Why is `CUDA_VISIBLE_DEVICES` used with GNU Parallel for GPU jobs?",
    "answer": "`CUDA_VISIBLE_DEVICES` is used with GNU Parallel to ensure that two tasks do not try to use the same GPU at the same time."
  },
  {
    "question": "Is GPU profiling available on Fir and Nibi clusters?",
    "answer": "No, GPU profiling is not available on Fir and Nibi clusters since performance counters are not accessible."
  },
  {
    "question": "How can GPU profiling be done on Narval and Rorqual clusters?",
    "answer": "On Narval and Rorqual, profiling is possible but requires disabling the NVIDIA Data Center GPU Manager (DCGM) by setting the `DISABLE_DCGM` environment variable during job submission."
  },
  {
    "question": "How do you disable NVIDIA Data Center GPU Manager (DCGM) for GPU profiling during job submission?",
    "answer": "You disable DCGM by setting the `DISABLE_DCGM` environment variable, for example: `DISABLE_DCGM=1 salloc --account=def-someuser --gpus-per-node=1 --mem=4000M --time=03:00`."
  },
  {
    "question": "What command can be used in an interactive job to wait until DCGM is disabled on the node?",
    "answer": "You can use the command `while [ ! -z \"$(dcgmi -v | grep 'Hostengine build info:')\" ]; do sleep 5; done` to wait until DCGM is disabled on the node in an interactive job."
  }
]