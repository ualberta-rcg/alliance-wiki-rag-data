[
  {
    "question": "What is Trillium?",
    "answer": "Trillium is a large parallel cluster built by Lenovo Canada and hosted by SciNet at the University of Toronto."
  },
  {
    "question": "What are the three main components of Trillium?",
    "answer": "The three main components of Trillium are the CPU Subcluster, the GPU Subcluster, and the Storage System."
  },
  {
    "question": "How many cores are in the Trillium CPU Subcluster?",
    "answer": "The CPU Subcluster has 235,008 cores provided by 1224 CPU compute nodes."
  },
  {
    "question": "What type of CPUs are used in each Trillium CPU compute node?",
    "answer": "Each CPU compute node has two 96-core AMD EPYC 9655 CPUs (\"Zen 5\" a.k.a. \"Turin\") at 2.6 GHz (base frequency)."
  },
  {
    "question": "How much memory is available on each Trillium CPU compute node?",
    "answer": "Each CPU compute node has 755 GiB / 810 GB of available memory."
  },
  {
    "question": "What interconnect technology connects the CPU nodes in Trillium?",
    "answer": "The CPU nodes are connected by a non-blocking (1:1) 400 Gb/s InfiniBand NDR interconnect."
  },
  {
    "question": "What is the CPU subcluster designed for?",
    "answer": "The CPU subcluster is designed for large-scale parallel workloads."
  },
  {
    "question": "How many GPUs are available in the Trillium GPU Subcluster?",
    "answer": "The GPU Subcluster has 252 GPUs provided by 63 GPU compute nodes."
  },
  {
    "question": "What kind of GPUs are in each Trillium GPU compute node?",
    "answer": "Each GPU compute node has 4 NVIDIA H100 (SXM) GPUs with 80 GB of dedicated VRAM."
  },
  {
    "question": "What CPUs are installed in each Trillium GPU compute node?",
    "answer": "Each GPU compute node also has 96 cores from one 96-core AMD EPYC 9654 CPU (\"Zen 4\" a.k.a. \"Genoa\") at 2.4 GHz (base frequency)."
  },
  {
    "question": "What is the interconnect speed for the GPU nodes in Trillium?",
    "answer": "The GPU nodes are connected by a non-blocking (1:1) 800 Gb/s InfiniBand NDR interconnect, which is 200 Gb/s per GPU."
  },
  {
    "question": "Does the GPU subcluster have a dedicated login node?",
    "answer": "Yes, it has a dedicated login node (trig-login01) with 4 NVIDIA H100 (SXM) GPUs."
  },
  {
    "question": "What types of workloads is the GPU subcluster optimized for?",
    "answer": "The GPU subcluster is optimized for AI/ML and accelerated science workloads."
  },
  {
    "question": "What kind of storage system does Trillium use?",
    "answer": "Trillium has a unified 29 PB VAST NVMe storage system for all workloads."
  },
  {
    "question": "How is Trillium's storage system characterized in terms of performance?",
    "answer": "It is all flash-based for consistent performance and accessible as a standard shared parallel file system."
  },
  {
    "question": "What is required to get access to Trillium?",
    "answer": "You need an active CCDB account from the Digital Research Alliance of Canada."
  },
  {
    "question": "Where can users request access to Trillium?",
    "answer": "Users can request access to Trillium on the 'Access Systems' page on the CCDB site."
  },
  {
    "question": "How long does it typically take for a Trillium account to be created after requesting access?",
    "answer": "It usually takes about an hour for your account to be actually created and available on Trillium after clicking the 'I request access' button."
  },
  {
    "question": "How can users contact for assistance with Trillium?",
    "answer": "Users can contact trillium@tech.alliancecan.ca for assistance."
  },
  {
    "question": "What are the two ways to access Trillium?",
    "answer": "The two ways to access Trillium are via your browser with Open OnDemand or via terminal access with SSH."
  },
  {
    "question": "Which Trillium access method is recommended for users unfamiliar with Linux?",
    "answer": "Open OnDemand is recommended for users who are not familiar with Linux or the command line."
  },
  {
    "question": "What is the primary authentication method for Trillium via SSH?",
    "answer": "Authentication for Trillium is only allowed via SSH keys that are uploaded to the CCDB."
  },
  {
    "question": "What operating system does Trillium run?",
    "answer": "Trillium runs Rocky Linux 9.6."
  },
  {
    "question": "How do you log into a CPU subcluster login node on Trillium?",
    "answer": "You use the command: `ssh -i /PATH/TO/SSH_PRIVATE_KEY MYALLIANCEUSERNAME@trillium.scinet.utoronto.ca`."
  },
  {
    "question": "How do you log into the GPU cluster login node on Trillium?",
    "answer": "You use the command: `ssh -i /PATH/TO/SSH_PRIVATE_KEY MYALLIANCEUSERNAME@trillium-gpu.scinet.utoronto.ca`."
  },
  {
    "question": "What do the Trillium login nodes allow users to do?",
    "answer": "The Trillium login nodes are where you develop, edit, compile, prepare and submit jobs."
  },
  {
    "question": "Do the CPU and GPU login nodes have the same architecture as their respective compute nodes?",
    "answer": "Yes, the CPU login nodes and the GPU login node have the same architecture, operating system, and software stack as the CPU and GPU compute nodes, respectively."
  },
  {
    "question": "How can one SSH between login nodes within Trillium?",
    "answer": "You can ssh from one login node to another using their internal hostnames like `tri-login01, ..., tri-login06` for CPU and `trig-login01` for GPU."
  },
  {
    "question": "What is the purpose of the '-Y' option when using SSH to access Trillium?",
    "answer": "Adding the option `-Y` enables X11 forwarding, which allows graphical programs on Trillium to open windows on your local computer."
  },
  {
    "question": "How must users run processes on Trillium's compute nodes?",
    "answer": "To run on compute nodes, you must submit a batch job."
  }
]