[
  {
    "question": "In WHOLE_NODE mode, what does a positive integer argument for `submit.run` signify?",
    "answer": "In WHOLE_NODE mode, a positive integer argument for the `submit.run` command represents the number of whole nodes to be used in META mode, rather than the number of meta-jobs."
  },
  {
    "question": "What happens if you run `submit.run 2` with WHOLE_NODE mode enabled?",
    "answer": "If WHOLE_NODE mode is enabled, the command `submit.run 2` will allocate 2 whole nodes, which will then be used to run up to 384 concurrent serial tasks (192 tasks on each node) using META mode with dynamic workload balancing."
  },
  {
    "question": "What is the meaning of the `-1` argument for `submit.run` in WHOLE_NODE mode?",
    "answer": "The `-1` argument for `submit.run` retains its original meaning, which is to run the farm using the SIMPLE mode."
  },
  {
    "question": "How are the number of actual whole node jobs calculated in SIMPLE mode with WHOLE_NODE enabled?",
    "answer": "The number of actual (whole node) jobs is computed as `Number_of_cases / NWHOLE`."
  },
  {
    "question": "What is required for advanced features like 'Automatic job resubmission' and 'Automatic post-processing job' to work on Trillium?",
    "answer": "To enable these features on Trillium, you must add the line `module load StdEnv` at the end of your `~/.bashrc` file."
  },
  {
    "question": "What type of farming can be used with WHOLE_NODE mode?",
    "answer": "The WHOLE_NODE mode can only be used for serial farming; it is not compatible with multi-threaded, MPI, or GPU farming."
  },
  {
    "question": "When might using WHOLE_NODE mode be advantageous on clusters other than Trillium?",
    "answer": "WHOLE_NODE mode may be advantageous on other clusters when the queue wait time for whole node jobs becomes shorter than for serial jobs."
  },
  {
    "question": "How can you use the META package on a cluster where it is not installed as a module?",
    "answer": "You can clone the package from its git repository using `git clone https://git.computecanada.ca/syam/meta-farm.git` and then modify your `$PATH` variable to include the `bin` subdirectory."
  },
  {
    "question": "What command should be used to add the `meta-farm/bin` directory to your PATH if `meta-farm` is in your home directory?",
    "answer": "You should use `export PATH=~/meta-farm/bin:$PATH` to add the `bin` subdirectory to your `$PATH`."
  },
  {
    "question": "What are two ways to pass additional `sbatch` arguments (like `--mem 4G`) to jobs?",
    "answer": "You can add additional `sbatch` arguments as separate `#SBATCH` lines in `job_script.sh`, or append them to the `submit.run` or `resubmit.run` command (e.g., `submit.run -1 --mem 4G`)."
  },
  {
    "question": "Which lines should be added to `job_script.sh` for multi-threaded or OpenMP applications?",
    "answer": "For multi-threaded applications, add the following lines to `job_script.sh`: `#SBATCH --cpus-per-task=N`, `#SBATCH --mem=M`, and `export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK`."
  },
  {
    "question": "What do `N` and `M` represent in the `job_script.sh` configuration for multi-threaded applications?",
    "answer": "`N` represents the number of CPU cores to use, and `M` is the total memory to reserve in megabytes."
  },
  {
    "question": "How can you provide CPU core and memory arguments for multi-threaded applications via the `submit.run` command?",
    "answer": "You can supply `--cpus-per-task=N` and `--mem=M` as arguments directly to `(re)submit.run`."
  },
  {
    "question": "Which lines should be added to `job_script.sh` for MPI applications?",
    "answer": "For MPI applications, add the lines `#SBATCH --ntasks=N` and `#SBATCH --mem-per-cpu=M` to `job_script.sh`."
  },
  {
    "question": "What do `N` and `M` represent in the `job_script.sh` configuration for MPI applications?",
    "answer": "`N` is the number of CPU cores to use, and `M` is the memory to reserve for each core, in megabytes."
  },
  {
    "question": "How can `srun` be used with MPI applications within the META farm?",
    "answer": "You can either add `srun` before the path to your code inside `single_case.sh` (e.g., `srun $COMM`) or prepend `srun` to each line of `table.dat`."
  },
  {
    "question": "How should `job_script.sh` be modified for applications using GPUs?",
    "answer": "For GPU applications, modify `job_script.sh` by adding `#SBATCH --gres=gpu[[:type]:number]`."
  },
  {
    "question": "What is the purpose of copying `~syam/bin/gpu_test` and adding specific lines to `job_script.sh` for GPU applications?",
    "answer": "This utility helps detect problems with a node that might render the GPU unavailable, preventing meta-jobs from attempting and failing to run cases when a GPU is not present."
  },
  {
    "question": "Do jobs generated by the META package inherit environment variables and loaded modules?",
    "answer": "Yes, all jobs generated by the META package inherit the environment present when `submit.run` or `resubmit.run` is executed, including loaded modules and environment variables."
  },
  {
    "question": "What is important to remember if you need to use the `--export` switch with META jobs?",
    "answer": "If you need to use `--export`, ensure that `ALL` is one of the arguments to this command, for example, `--export=ALL,X=1,Y=2`."
  },
  {
    "question": "How should custom environment variables be passed to all farm jobs, including auto-resubmitted and post-processing jobs?",
    "answer": "Do not use `--export`; instead, set the variables on the command line, such as `$ VAR1=1 VAR2=5 VAR3=3.1416 submit.run ...`."
  },
  {
    "question": "How would you create `table.dat` for an application named `fcode` that reads input from `data.X` files in `/home/user/IC`?",
    "answer": "You would create `table.dat` with entries like `fcode < /home/user/IC/data.1`, `fcode < /home/user/IC/data.2`, etc. A shell loop can automate this, e.g., `for ((i=1; i<=100; i++)); do echo \"fcode < /home/user/IC/data.$i\"; done >table.dat`."
  },
  {
    "question": "What is required if an application expects a specific, unchangeable input file name (e.g., `INPUT`) for each case?",
    "answer": "Each case must run in its own subdirectory, and an input file with the prescribed name (e.g., `INPUT`) must be created in each subdirectory."
  },
  {
    "question": "When an application requires a fixed input file name, how should `single_case.sh` be modified?",
    "answer": "A line should be added to `single_case.sh` to copy the appropriate input file into the farm subdirectory for each case, for example: `cp /path/to/data.$ID INPUT`."
  }
]