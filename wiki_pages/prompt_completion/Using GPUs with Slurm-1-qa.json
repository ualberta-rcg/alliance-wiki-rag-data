[
  {
    "question": "What is the recommended form for requesting one or more GPUs for a Slurm job?",
    "answer": "The recommended form is `--gpus-per-node=[type:]number`."
  },
  {
    "question": "In the `--gpus-per-node=[type:]number` syntax, which parts are mandatory and which are optional?",
    "answer": "The 'number' of GPUs must be specified, while the 'type' of GPU is optional."
  },
  {
    "question": "How do you request two GPUs per node of any type available on the cluster?",
    "answer": "You can request two GPUs of any type using the command `--gpus-per-node=2`."
  },
  {
    "question": "How can a user request one V100 type GPU per node?",
    "answer": "A user can request one V100 GPU per node using the command `--gpus-per-node=v100:1`."
  },
  {
    "question": "Is the `--gres=gpu[[:type]:number]` form recommended for requesting GPU resources?",
    "answer": "No, the `--gres=gpu[[:type]:number]` form is older and is expected to no longer be supported in some future Slurm release. It is recommended to replace it with the `--gpus-per-node` form."
  },
  {
    "question": "What are some other directives available for requesting GPU resources in Slurm?",
    "answer": "Other directives for requesting GPU resources include `--gpus`, `--gpus-per-socket`, `--gpus-per-task`, `--mem-per-gpu`, and `--ntasks-per-gpu`."
  },
  {
    "question": "Where can users find more information about Slurm directives like `--gpus`?",
    "answer": "Users can find more information in the Slurm documentation for `sbatch`."
  },
  {
    "question": "What should a user do if they don't get the expected result when using GPU resource directives?",
    "answer": "If a user doesn't get the expected result, they should contact technical support."
  },
  {
    "question": "What GPU model is available on the Fir cluster?",
    "answer": "The Fir cluster offers H100-80gb GPU models."
  },
  {
    "question": "Which GPU model is found on the Narval cluster?",
    "answer": "The Narval cluster has A100-40gb GPU models."
  },
  {
    "question": "What GPU models are available on the Nibi cluster?",
    "answer": "The Nibi cluster has H100-80gb and MI300A-128gb GPU models."
  },
  {
    "question": "What GPU model is available on the Rorqual and Trillium clusters?",
    "answer": "Both Rorqual and Trillium clusters offer H100-80gb GPU models."
  },
  {
    "question": "Are cloud resources like Arbutus schedulable via Slurm?",
    "answer": "No, cloud resources such as Arbutus are not schedulable via Slurm. Details can be found in the 'Cloud resources' documentation."
  },
  {
    "question": "What is 'Compute Capability' according to NVIDIA?",
    "answer": "Compute Capability is a technical term created by NVIDIA to describe what hardware functions are available on some GPU models. It is not a measure of performance."
  },
  {
    "question": "When is 'Compute Capability' relevant for users?",
    "answer": "Compute Capability is relevant only if you are compiling your own GPU programs."
  },
  {
    "question": "What is Multi-Instance GPU (MIG) technology?",
    "answer": "MIG is a technology that allows partitioning a GPU into multiple instances."
  },
  {
    "question": "What can happen if you do not specify a GPU type specifier for your Slurm job?",
    "answer": "If you do not supply a type specifier, Slurm may send your job to a node equipped with any type of GPU available on the cluster."
  },
  {
    "question": "Why might it be undesirable for Slurm to assign any type of GPU if a type specifier is not provided?",
    "answer": "For workflows requiring specific performance, such as molecular dynamics which needs high double-precision performance, a job might be sent to an unsuitable GPU type like T4, which is not appropriate."
  }
]