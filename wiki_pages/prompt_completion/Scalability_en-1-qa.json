[
  {
    "question": "What is scalability in the context of parallel programming?",
    "answer": "In parallel programming, scalability refers to a program's ability to efficiently utilize additional computing resources, specifically CPU cores."
  },
  {
    "question": "Does doubling CPU cores always halve calculation duration?",
    "answer": "No, one might naively imagine that, but it is rarely the case. The gain in performance depends on factors like the problem's nature, the algorithm, hardware, and the number of CPU cores used."
  },
  {
    "question": "What is recommended when planning to use a parallel program on a cluster?",
    "answer": "It is recommended to conduct a scalability analysis where the software is tested using a fixed problem while varying the number of CPU cores (e.g., 2, 4, 8, 16, 32, 64 cores), obtaining the run time for each and plotting the resulting curve."
  },
  {
    "question": "What are the two major reasons why scalability is often worse than expected?",
    "answer": "The two major reasons are: firstly, a percentage of the program's execution remains serial because not all operations can be parallelized; and secondly, parallelization incurs 'parallel overhead' due to communication and synchronization among processes."
  },
  {
    "question": "How does the serial percentage affect parallel efficiency?",
    "answer": "The serial percentage of a program's execution represents an ultimate limit for its parallel efficiency. Even with an infinite number of cores, the program's duration cannot go below the time spent on serial operations."
  },
  {
    "question": "Can the serial percentage be improved?",
    "answer": "The best hope is that the 'serial percentage' shrinks as the size of the problem the software is working on increases."
  },
  {
    "question": "How does 'parallel overhead' impact program duration?",
    "answer": "Parallel overhead, which increases with the number of processes working together (typically as a power of the number of cores), ultimately dominates the total program duration as the number of cores approaches infinity."
  },
  {
    "question": "What does a typical run time curve for a parallel program look like?",
    "answer": "For smaller numbers of cores, the run time falls, but a minimum is reached at a certain number of cores (e.g., n\u224822), after which the program duration starts to increase as more processes are added due to parallel overhead."
  },
  {
    "question": "Why is it crucial to perform a scalability analysis for parallel programs?",
    "answer": "It's crucial to carry out a scalability analysis to determine the optimal choice of CPU cores for a given problem nature, size, and cluster, as too many cores can actually increase run time."
  },
  {
    "question": "What are the characteristics of a good test problem for scalability analysis?",
    "answer": "A good test problem should be relatively small for quick tests but not unrepresentative of a production run. A problem requiring 30 to 60 minutes on one or two cores is a good choice, while one under ten minutes is usually too short. For weak scaling analysis, the problem size should be easily and continuously increasable."
  },
  {
    "question": "What are 'embarrassingly parallel' problems?",
    "answer": "Embarrassingly parallel problems are a class of problems where there is no parallel overhead (the factor C is zero). This means there's no need for communication or synchronization among parallel processes."
  },
  {
    "question": "Can you give an example of an embarrassingly parallel problem?",
    "answer": "A good example is running an analysis on 500 different files, where the analysis of each file is independent and simply generates a single number, requiring no synchronization or communication between processes."
  },
  {
    "question": "What is the limitation for scaling in embarrassingly parallel problems?",
    "answer": "In embarrassingly parallel problems, perfect scaling can be achieved out to any number of processes; the only limitation is the number of files or independent tasks available."
  }
]