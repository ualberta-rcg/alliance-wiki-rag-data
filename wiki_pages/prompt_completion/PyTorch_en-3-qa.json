[
  {
    "question": "What are the two main recommendations for optimizing performance when using PyTorch with a single GPU?",
    "answer": "To optimize performance, you should increase your `batch_size` to as much as you can fit in the GPU's memory and use a `DataLoader` with as many workers as you have `cpus-per-task` to streamline feeding data to the GPU."
  },
  {
    "question": "When is Data Parallelism with a single GPU a viable option, especially for a small model?",
    "answer": "It is a viable option when a model is fairly small, not taking up much GPU memory or compute capacity, but you have a very large dataset and need to perform training with a small batch size."
  },
  {
    "question": "What does Data Parallelism mean in the context of single GPU training?",
    "answer": "Data Parallelism refers to training over multiple replicas of a model in parallel, where each replica receives a different chunk of training data at each iteration, and gradients are aggregated to update the parameters."
  },
  {
    "question": "What is the primary benefit of using Data Parallelism?",
    "answer": "Data Parallelism can provide a significant speed-up by iterating through all examples in a large dataset approximately 'N' times faster, where 'N' is the number of model replicas."
  },
  {
    "question": "What is an important consideration for Data Parallelism to ensure the trained model is equivalent to one trained without it?",
    "answer": "An important caveat is that the user must scale either the learning rate or the desired batch size in function of the number of replicas."
  },
  {
    "question": "Which PyTorch class is recommended for best performance when implementing Data Parallelism, even with a single GPU?",
    "answer": "The `DistributedDataParallel` class is recommended by PyTorch maintainers for best performance."
  },
  {
    "question": "How does the provided example for single-GPU Data Parallelism handle a small model that doesn't fully utilize a GPU?",
    "answer": "The example uses Nvidia's Multi-Process Service (MPS) along with MPI to efficiently place multiple model replicas (e.g., 14 or 15 replicas of a small model on a V100 GPU) on a single GPU, thereby increasing resource utilization and speed."
  },
  {
    "question": "What are the key steps in the `pytorch-gpu-mps.sh` job submission script for single GPU data parallelism?",
    "answer": "The script requests a single GPU, sets `--tasks-per-node` to the number of model replicas, loads the Python module, creates and activates a virtual environment, installs `torch` and `torchvision`, activates Nvidia MPS, and then executes the Python training script using `srun`."
  },
  {
    "question": "What PyTorch components are used in the `cifar10-gpu-mps.py` script for single-GPU data parallelism?",
    "answer": "The script uses `torch.cuda.set_device`, `dist.init_process_group` with `backend=\"mpi\"`, `torch.nn.parallel.DistributedDataParallel` to wrap the model, and `torch.utils.data.distributed.DistributedSampler` for the `DataLoader`."
  }
]