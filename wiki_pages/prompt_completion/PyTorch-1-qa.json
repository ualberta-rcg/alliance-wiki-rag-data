[
  {
    "question": "What are the two high-level features provided by PyTorch?",
    "answer": "PyTorch offers Tensor computation (like NumPy) with strong GPU acceleration and Deep neural networks built on a tape-based autograd system."
  },
  {
    "question": "What is the relationship between PyTorch and Torch?",
    "answer": "PyTorch has a distant connection with Torch, but for all practical purposes, they can be treated as separate projects."
  },
  {
    "question": "What is LibTorch?",
    "answer": "LibTorch allows developers to implement C++ extensions to PyTorch and pure C++ machine learning applications, and models written in Python using PyTorch can be converted and used in pure C++ through TorchScript."
  },
  {
    "question": "How can you check the latest available version of PyTorch that has been built?",
    "answer": "You can see the latest version by using the command `avail_wheels torch`."
  },
  {
    "question": "What is the preferred way to install PyTorch?",
    "answer": "The preferred option is to install it using the Python wheel."
  },
  {
    "question": "What are the steps to install PyTorch using a Python wheel?",
    "answer": "First, load a Python module (e.g., `module load python`), then create and start a virtual environment, and finally, install PyTorch within the virtual environment using `pip install`."
  },
  {
    "question": "What is the command to install PyTorch for GPU and CPU acceleration within a virtual environment?",
    "answer": "The command is `pip install --no-index torch`."
  },
  {
    "question": "Which PyTorch version is required for H100 GPUs?",
    "answer": "Torch 2.3 and higher is required with H100 GPUs."
  },
  {
    "question": "What additional PyTorch-related packages can be installed?",
    "answer": "In addition to `torch`, you can install `torchvision`, `torchtext`, and `torchaudio`."
  },
  {
    "question": "How do you install extra PyTorch packages like torchvision, torchtext, and torchaudio?",
    "answer": "Run `pip install --no-index torch torchvision torchtext torchaudio` within your virtual environment."
  },
  {
    "question": "How do you submit a PyTorch job script?",
    "answer": "You can submit a PyTorch job with the command `sbatch pytorch-test.sh`."
  },
  {
    "question": "What are the key features of Nvidia's TensorFloat-32 (TF32) Mode in PyTorch?",
    "answer": "TF32 mode, introduced in PyTorch 1.7.0, is available on Ampere and later Nvidia GPU architectures, offers up to 20x speed-ups for tensor operations compared to FP32, but may decrease accuracy."
  },
  {
    "question": "What is the default behavior of TF32 for matrix multiplications and convolutions in PyTorch version 1.12.0 and later?",
    "answer": "Starting with PyTorch version 1.12.0, TF32 is disabled by default for matrix multiplications but still enabled by default for convolutions."
  },
  {
    "question": "How can you programmatically enable or disable TF32 for matrix multiplications in PyTorch version 1.12.0 and above?",
    "answer": "You can set `torch.backends.cuda.matmul.allow_tf32 = True` to enable or `False` to disable TF32 for matrix multiplications."
  },
  {
    "question": "How can you programmatically enable or disable TF32 for convolutions in PyTorch version 1.12.0 and above?",
    "answer": "You can set `torch.backends.cudnn.allow_tf32 = True` to enable or `False` to disable TF32 for convolutions."
  },
  {
    "question": "What impact might users see when migrating from PyTorch versions older than 1.12.0 to 1.12.0 or newer on A100/H100 GPUs?",
    "answer": "Users may notice a significant slowdown and get different results when running the exact same GPU-enabled code."
  }
]