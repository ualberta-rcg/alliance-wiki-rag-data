[
  {
    "question": "Who is this page primarily intended for?",
    "answer": "This page is intended for users already familiar with job scheduling and job scripts, who are looking for guidance on submitting jobs to our clusters."
  },
  {
    "question": "What should a new user to large shared computer clusters read first?",
    "answer": "Users new to large shared computer clusters should probably read 'What is a scheduler?' first."
  },
  {
    "question": "How must all jobs be submitted on these clusters?",
    "answer": "All jobs must be submitted via the scheduler."
  },
  {
    "question": "What are the exceptions to submitting jobs via the scheduler?",
    "answer": "Exceptions are made for compilation and other tasks not expected to consume more than about 10 CPU-minutes and about 4 gigabytes of RAM; such tasks may be run on a login node."
  },
  {
    "question": "Is it permissible to run processes on compute nodes without using the scheduler?",
    "answer": "No, in no case should you run processes on compute nodes except via the scheduler."
  },
  {
    "question": "What job scheduler is used on these clusters?",
    "answer": "The job scheduler used on our clusters is the Slurm Workload Manager."
  },
  {
    "question": "Where can users find comprehensive documentation for Slurm?",
    "answer": "Comprehensive documentation for Slurm is maintained by SchedMD."
  },
  {
    "question": "What command is used to submit a job?",
    "answer": "The command to submit a job is `sbatch`."
  },
  {
    "question": "How do you submit a job script named `simple_job.sh`?",
    "answer": "You submit it using the command `$ sbatch simple_job.sh`."
  },
  {
    "question": "What does a minimal Slurm job script typically include?",
    "answer": "A minimal Slurm job script includes a shebang, #SBATCH directives for time and account, and executable commands like 'echo' or 'sleep'."
  },
  {
    "question": "What resources does a minimal Slurm job (like the example provided) reserve on general-purpose (GP) clusters?",
    "answer": "On general-purpose (GP) clusters, a minimal job reserves 1 core and 256MB of memory for 15 minutes."
  },
  {
    "question": "How does a minimal Slurm job differ on Niagara compared to GP clusters regarding resource allocation?",
    "answer": "On Niagara, a minimal Slurm job reserves the whole node with all its memory, unlike GP clusters where it reserves 1 core and 256MB."
  },
  {
    "question": "How are directives (options) identified within a job script?",
    "answer": "Directives (or options) in the job script are prefixed with `#SBATCH`."
  },
  {
    "question": "Where must `#SBATCH` directives be placed in a job script?",
    "answer": "Directives prefixed with `#SBATCH` must precede all executable commands in the job script."
  },
  {
    "question": "What are the minimum required directives for each job according to cluster policies?",
    "answer": "Cluster policies require users to supply at least a time limit (`--time`) for each job, and potentially an account name (`--account`)."
  },
  {
    "question": "Can job directives be specified as command-line arguments?",
    "answer": "Yes, directives can also be specified as command-line arguments to `sbatch`."
  },
  {
    "question": "How can you specify a 30-minute time limit for a job using a command-line argument?",
    "answer": "You can specify a 30-minute time limit using `$ sbatch --time=00:30:00 simple_job.sh`."
  },
  {
    "question": "What are the acceptable time formats for the `--time` directive?",
    "answer": "Acceptable time formats include 'minutes', 'minutes:seconds', 'hours:minutes:seconds', 'days-hours', 'days-hours:minutes', and 'days-hours:minutes:seconds'."
  },
  {
    "question": "How does the time limit chosen for a job affect its start time?",
    "answer": "The time limit will strongly affect how quickly the job is started, since longer jobs are eligible to run on fewer nodes."
  },
  {
    "question": "What caution should be exercised when submitting many Slurm jobs in a short time?",
    "answer": "Submitting thousands of jobs at a time can cause Slurm to become unresponsive to other users, so users should be cautious."
  },
  {
    "question": "What alternatives are recommended for submitting many jobs to avoid making Slurm unresponsive?",
    "answer": "Users should consider using an array job instead, or use `sleep` to space out calls to `sbatch` by one second or more."
  },
  {
    "question": "How can memory be requested for a job?",
    "answer": "Memory may be requested with `--mem-per-cpu` (memory per core) or `--mem` (memory per node)."
  },
  {
    "question": "What is the default memory allocation per core on general-purpose (GP) clusters?",
    "answer": "On general-purpose (GP) clusters, a default memory amount of 256 MB per core will be allocated unless you make some other request."
  },
  {
    "question": "Is a memory specification required for jobs on Niagara?",
    "answer": "No, a memory specification is not required on Niagara because only whole nodes are allocated along with all available memory."
  },
  {
    "question": "Why might less memory be available to a job than a node's nominal memory?",
    "answer": "Some memory on a node is not available to the job (reserved for the OS, etc.), so each node type has a maximum amount available to jobs that is typically less than its nominal memory."
  },
  {
    "question": "What happens if a job requests more memory than a node type provides?",
    "answer": "If a job requests more memory than a node-type provides, your job will be constrained to run on higher-memory nodes, which may be fewer in number."
  },
  {
    "question": "How does Slurm interpret memory unit prefixes like K, M, and G?",
    "answer": "Slurm interprets K, M, G, etc., as binary prefixes, so `--mem=125G` is equivalent to `--mem=128000M`."
  },
  {
    "question": "Where can users find the maximum memory they can request on each node for GP clusters?",
    "answer": "Users can find the maximum memory they can request on each node for GP clusters in the 'Available memory' column of the 'Node characteristics' table for B\u00e9luga, Cedar, Graham, and Narval."
  }
]