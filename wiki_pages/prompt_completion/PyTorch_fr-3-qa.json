[
  {
    "question": "What is the architecture of the `Net` class defined in the `cifar10-cpu.py` example?",
    "answer": "The `Net` class has two convolutional layers (`conv1` and `conv2`) interspersed with max-pooling, followed by three fully connected layers (`fc1`, `fc2`, and `fc3`)."
  },
  {
    "question": "How is the forward pass implemented in the `Net` class within `cifar10-cpu.py`?",
    "answer": "In the forward pass, input `x` goes through `conv1`, ReLU activation, and pooling, then `conv2`, ReLU activation, and pooling. The output is flattened (`x.view(-1, 16 * 5 * 5)`) before passing through `fc1`, `fc2`, and `fc3` with ReLU activations between the fully connected layers."
  },
  {
    "question": "What loss function and optimizer are used in the `cifar10-cpu.py` script?",
    "answer": "The script uses `nn.CrossEntropyLoss()` as the criterion and `optim.SGD(net.parameters(), lr=args.lr)` as the optimizer."
  },
  {
    "question": "What data transformations are applied to the training dataset in `cifar10-cpu.py`?",
    "answer": "The training data is transformed using `transforms.ToTensor()` and `transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))`."
  },
  {
    "question": "What dataset is used for training in the `cifar10-cpu.py` example?",
    "answer": "The CIFAR10 dataset is used for training in the `cifar10-cpu.py` example."
  },
  {
    "question": "How can one download and prepare the CIFAR10 dataset for the `cifar10-cpu.py` example?",
    "answer": "To prepare the CIFAR10 dataset, you need to create a `data` directory (`mkdir -p data && cd data`), download the `cifar-10-python.tar.gz` file using `wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz`, extract it with `tar zxf cifar-10-python.tar.gz`, and then navigate back up (`cd ..`)."
  },
  {
    "question": "What performance metric is calculated during the training loop in `cifar10-cpu.py`?",
    "answer": "The script calculates `images_per_sec` (images per second) by dividing the `batch_size` by the `batch_time`."
  },
  {
    "question": "What is the purpose of the `pytorch-multi-cpu.sh` script?",
    "answer": "The `pytorch-multi-cpu.sh` script is an example submission script used to observe the effect on performance when requesting more CPUs without modifying the Python code."
  },
  {
    "question": "How can the number of CPUs per task be modified in the `pytorch-multi-cpu.sh` script?",
    "answer": "The `--cpus-per-task` parameter in the SBATCH directive can be changed to values like 2, 4, 6, etc., to see the effect on performance."
  },
  {
    "question": "Which environment variable is set in `pytorch-multi-cpu.sh` to control OpenMP threads?",
    "answer": "The `OMP_NUM_THREADS` environment variable is set to `$SLURM_CPUS_PER_TASK`."
  },
  {
    "question": "When should one avoid requesting a GPU for deep learning tasks on clusters?",
    "answer": "You should avoid requesting a GPU if your code cannot make reasonable use of its compute capacity, especially for very small models, which might train faster on one or more CPUs."
  },
  {
    "question": "What are the two primary reasons for the performance advantage of GPUs in deep learning?",
    "answer": "The two primary reasons are the ability to parallelize key operations (like multiplier-accumulators) on thousands of cores and a much larger memory bandwidth compared to CPUs."
  },
  {
    "question": "What specialized libraries does PyTorch use for parallel operations on GPUs?",
    "answer": "PyTorch uses specialized libraries for GPUs such as CUDNN or MIOpen, depending on the hardware platform."
  },
  {
    "question": "What characteristics make a deep learning task suitable for GPU usage?",
    "answer": "For a deep learning task to effectively use a GPU, it must involve elements that can be massively parallelized, either due to the number of operations, the quantity of data to be processed, or ideally both, such as a large model with many units and layers or extensive input data."
  }
]