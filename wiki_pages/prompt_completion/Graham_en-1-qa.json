[
  {
    "question": "What is the future plan for the Graham system?",
    "answer": "Graham will soon be retired and replaced by a new system named Nibi."
  },
  {
    "question": "Where can users find information about system capacity changes, reductions, and outages during the transition to Nibi?",
    "answer": "Users should check the Infrastructure renewal page for system capacity, reductions, and outages during the installation and transition to the new systems."
  },
  {
    "question": "When did the Graham system become available for production?",
    "answer": "Graham has been in production since June 2017."
  },
  {
    "question": "What is the login node address for the Graham cluster?",
    "answer": "The login node for Graham is graham.alliancecan.ca."
  },
  {
    "question": "What is the Globus collection identifier for Graham?",
    "answer": "The Globus collection identifier for Graham is computecanada#graham-globus."
  },
  {
    "question": "Which nodes should be used for data transfer operations like rsync, scp, or sftp on Graham?",
    "answer": "For data transfer operations such as rsync, scp, or sftp, users should utilize the robot or login nodes."
  },
  {
    "question": "Where is the Graham cluster located?",
    "answer": "Graham is a heterogeneous cluster located at the University of Waterloo."
  },
  {
    "question": "Who is the Graham cluster named after?",
    "answer": "The Graham cluster is named after Wes Graham, the first director of the Computing Centre at Waterloo."
  },
  {
    "question": "How is Graham's cooling system designed?",
    "answer": "Graham is entirely liquid cooled, employing rear-door heat exchangers."
  },
  {
    "question": "Is internet access permitted from Graham's compute nodes by policy?",
    "answer": "No, by policy, Graham's compute nodes cannot access the internet."
  },
  {
    "question": "What information is required to request an exception for internet access on Graham's compute nodes?",
    "answer": "To request an exception, you must contact technical support and provide the IP, Port/s, Protocol (TCP or UDP), Contact, and Removal Date."
  },
  {
    "question": "Is Crontab functionality available on Graham?",
    "answer": "No, Crontab is not offered on Graham."
  },
  {
    "question": "What is the minimum duration for a regular job on Graham?",
    "answer": "Each job on Graham should have a duration of at least one hour, or five minutes for test jobs."
  },
  {
    "question": "What is the maximum allowable duration for a job on Graham?",
    "answer": "A job on Graham can run for no more than 168 hours, which is equivalent to seven days."
  },
  {
    "question": "What is the maximum number of jobs a user can have running or queued on Graham at any moment?",
    "answer": "A user cannot have more than 1000 jobs, including both running and queued, at any given moment."
  },
  {
    "question": "How are array jobs counted against a user's job limit on Graham?",
    "answer": "An array job is counted as the total number of tasks in the array for the user's job limit."
  },
  {
    "question": "What is the total volume of Home space on Graham?",
    "answer": "The Home space on Graham has a total volume of 133TB."
  },
  {
    "question": "Does Home space on Graham include daily backups?",
    "answer": "Yes, Home space has daily backup."
  },
  {
    "question": "How is Home space allocated on Graham?",
    "answer": "Home space is not allocated via RAS or RAC; larger requests should go to Project space."
  },
  {
    "question": "What is the primary use case for Scratch space on Graham?",
    "answer": "Scratch space, located at `/scratch`, is used for active or temporary storage."
  },
  {
    "question": "What is the total volume of Scratch space on Graham?",
    "answer": "Scratch space has a total volume of 3.2PB."
  },
  {
    "question": "What happens to inactive data stored in Scratch space?",
    "answer": "Inactive data in Scratch space will be purged."
  },
  {
    "question": "What is the total volume of Project space on Graham?",
    "answer": "Project space on Graham has a total volume of 16PB."
  },
  {
    "question": "How is Project space allocated on Graham?",
    "answer": "Project space is allocated via Rapid Access Service (RAS) or Resource Allocation Competition (RAC)."
  },
  {
    "question": "Is Project space recommended for parallel I/O workloads?",
    "answer": "No, Project space is not designed for parallel I/O workloads; Scratch space should be used instead."
  },
  {
    "question": "What types of InfiniBand interconnects are utilized on Graham?",
    "answer": "Graham utilizes Mellanox FDR (56Gb/s) and EDR (100Gb/s) InfiniBand interconnects."
  },
  {
    "question": "Which InfiniBand interconnect type is used for GPU and cloud nodes on Graham?",
    "answer": "FDR (56Gb/s) InfiniBand is used for GPU and cloud nodes."
  },
  {
    "question": "What is the purpose of the central director switch in Graham's high-performance interconnect?",
    "answer": "A central 324-port director switch aggregates connections from islands of 1024 cores each for CPU and GPU nodes."
  },
  {
    "question": "What kind of network connects all nodes and scratch storage on Graham?",
    "answer": "A low-latency high-bandwidth Infiniband fabric connects all nodes and scratch storage."
  },
  {
    "question": "What is the design goal of Graham's interconnect for parallel jobs?",
    "answer": "The design of Graham's interconnect is to support multiple simultaneous parallel jobs of up to 1024 cores in a fully non-blocking manner."
  },
  {
    "question": "Where are Graham's dedicated visualization nodes accessible?",
    "answer": "Graham has dedicated visualization nodes available at gra-vdi.alliancecan.ca."
  },
  {
    "question": "What type of connection is permitted to Graham's visualization nodes?",
    "answer": "Only VNC connections are allowed to Graham's visualization nodes."
  },
  {
    "question": "When was Graham's capacity reduced, and for what reason?",
    "answer": "In early 2025, Graham's capacity was reduced to make space for the installation of the new Nibi cluster."
  },
  {
    "question": "Is Intel Turbo Boost enabled on Graham nodes?",
    "answer": "Yes, Intel Turbo Boost is enabled for all Graham nodes."
  },
  {
    "question": "How many nodes on Graham are configured with 8x NVIDIA V100 Volta GPUs?",
    "answer": "There are 2 nodes on Graham equipped with 8x NVIDIA V100 Volta GPUs."
  },
  {
    "question": "What is the recommended best practice for using local on-node storage during a job on Graham?",
    "answer": "The best practice for local on-node storage is to use the temporary directory generated by Slurm, which is designated by the environment variable `$SLURM_TMPDIR`."
  },
  {
    "question": "What happens to the contents of `$SLURM_TMPDIR` after a job completes?",
    "answer": "The `$SLURM_TMPDIR` directory and its contents will disappear upon job completion."
  },
  {
    "question": "Why is the available memory on Graham nodes often less than the stated hardware capacity?",
    "answer": "The available memory is less than the hardware's suggested 'round number' because some of it is permanently occupied by the kernel and operating system."
  },
  {
    "question": "What generations of Tesla GPUs are available on Graham?",
    "answer": "Graham contains Tesla GPUs from three different generations: V100 Volta, T4 Turing, and A100 Ampere."
  },
  {
    "question": "Which older generation of GPUs on Graham has been decommissioned?",
    "answer": "P100 GPUs have been decommissioned."
  },
  {
    "question": "How do V100 Volta GPUs perform compared to their predecessor, P100 GPUs?",
    "answer": "V100 Volta GPUs offer about double the performance for standard computation and approximately 8X performance for deep learning computations that utilize its tensor core computation units, compared to P100 GPUs."
  },
  {
    "question": "What are the characteristics of T4 Turing GPUs, particularly regarding deep learning and precision?",
    "answer": "T4 Turing GPUs are specifically targeted at deep learning workloads, providing good performance for single precision, featuring tensor cores, and supporting reduced precision integer calculations, but they do not support efficient double precision computations."
  },
  {
    "question": "How many Volta GPU nodes are there on Graham?",
    "answer": "Graham has a total of 2 Volta nodes."
  },
  {
    "question": "What interconnect technology do the Volta GPU nodes on Graham use?",
    "answer": "The Volta GPU nodes have high bandwidth NVLINK interconnect."
  },
  {
    "question": "What is the maximum job duration for users on Volta nodes?",
    "answer": "The maximum job duration on Volta nodes is seven days for all users."
  },
  {
    "question": "What is the recommended CPU to GPU ratio for jobs on 28-core Volta nodes?",
    "answer": "On 28-core Volta nodes, you should maintain a ratio of CPUs to GPUs at 3.5 or less."
  },
  {
    "question": "How many CPU cores should be requested for a job using 4 GPUs on a 28-core Volta node?",
    "answer": "For a job using 4 GPUs on a 28-core Volta node, you should request at most 14 CPU cores."
  },
  {
    "question": "How many CPU cores should be requested for a job using 1 GPU on a 28-core Volta node?",
    "answer": "For a job using 1 GPU on a 28-core Volta node, you should request at most 3 CPU cores."
  },
  {
    "question": "How should the CPU core per GPU ratio be adjusted for the newer 40-core Volta nodes?",
    "answer": "For the two newest 40-core Volta nodes, you can use 5 CPU cores per GPU."
  },
  {
    "question": "How can a user explicitly request an NVLINK Volta node for their job on Graham?",
    "answer": "Users can request an NVLINK Volta node by adding the `--constraint=cascade,v100` parameter to their job submission script."
  },
  {
    "question": "How would you specify requesting two T4 Turing GPUs per node in a job script?",
    "answer": "You would specify `--gres=gpu:t4:2` in your job script to request two T4 cards per node."
  },
  {
    "question": "How would you specify requesting two Ampere A100 GPUs per node in a job script?",
    "answer": "You would specify `--gres=gpu:a100:2` in your job script to request two A100 cards per node."
  },
  {
    "question": "How would you specify requesting two Ampere RTX A5000 GPUs per node in a job script?",
    "answer": "You would specify `--gres=gpu:a5000:2` in your job script to request two RTX A5000 cards per node."
  },
  {
    "question": "Starting when, and at what capacity, will the Graham cluster operate until Nibi comes online?",
    "answer": "Starting January 13, 2025, the Graham cluster will operate at approximately 25% capacity until the new Nibi system comes online."
  }
]