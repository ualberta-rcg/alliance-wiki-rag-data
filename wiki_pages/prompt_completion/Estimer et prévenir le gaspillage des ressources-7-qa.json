[
  {
    "question": "In what scenarios is Multi-Process Service (MPS) applicable for GPU tasks?",
    "answer": "MPS is well-suited for a multiprocessor (MPI) task where individual processes do not fully utilize a GPU, a multithreaded task where individual threads do not fully utilize a GPU, or several similar serial tasks where each individual job does not fully utilize a GPU."
  },
  {
    "question": "What is the benefit of grouping GPU tasks that only require one GPU?",
    "answer": "Grouping tasks that only require a single GPU can improve your priority in the queue."
  },
  {
    "question": "How can MPS be used in conjunction with MIG to optimize resource utilization?",
    "answer": "You can leverage MPS (Multi-Process Service) within a MIG (Multi-Instance GPU) to optimize resource utilization."
  },
  {
    "question": "To which computing clusters is the MPS approach applicable?",
    "answer": "This approach is applicable to all computing clusters equipped with GPUs."
  },
  {
    "question": "What is the first step to avoid wasting GPU resources?",
    "answer": "Verify if your program is compatible with the GPU and ensure your application is configured to take advantage of it."
  },
  {
    "question": "What type of initial tests should be performed for GPU tasks?",
    "answer": "Perform initial tests with an interactive task, requesting a MIG, to validate the proper functioning of your code on GPU."
  },
  {
    "question": "How can users analyze the efficiency of their GPU tasks?",
    "answer": "Analyze the efficiency of your task via the visualization portal by monitoring the real GPU usage (calculations, memory) to detect any potential waste."
  },
  {
    "question": "What should users understand regarding requesting a GPU with SBATCH?",
    "answer": "Users should understand the different ways to request a GPU with SBATCH, familiarizing themselves with options for requesting a GPU, a MIG, or activating MPS according to their needs."
  },
  {
    "question": "When should a Multi-Instance GPU (MIG) be used?",
    "answer": "Use a MIG if your task consumes less than 20 GiB of GPU memory, as it allows for efficient sharing of the GPU with other users."
  },
  {
    "question": "When should Multi-Process Service (MPS) be considered for GPU tasks?",
    "answer": "Consider MPS if you are executing several light tasks, whether in parallel or in series, as it allows for better exploitation of an underutilized GPU."
  },
  {
    "question": "What is the benefit of requesting shorter task durations?",
    "answer": "Shorter task durations reduce waiting times and improve your priority in the queue."
  },
  {
    "question": "Where can users find information about node-specific memory capacities?",
    "answer": "Information about node-specific memory capacities can be found on the main Wiki page, in the tabs dedicated to each available cluster."
  },
  {
    "question": "What is the first step to evaluate the necessary memory for a task?",
    "answer": "The first thing to do is to calculate the core-equivalent memory based on the node you intend to use."
  },
  {
    "question": "What is the approximate memory per core on B\u00e9luga/Narval clusters?",
    "answer": "On B\u00e9luga/Narval, you have approximately 4 GB of memory per core in core-equivalent terms."
  },
  {
    "question": "How can you save time when requesting memory?",
    "answer": "You can save time by requesting less memory if your task does not require the maximum available."
  },
  {
    "question": "What is an acceptable memory buffer to request to avoid 'Out of memory' errors?",
    "answer": "It is acceptable to request up to 20% more memory than what you expect to use to ensure you don't run out."
  },
  {
    "question": "How do resource requests apply to task arrays (vecteurs de t\u00e2ches)?",
    "answer": "The resources requested for a task array apply to a single task, not to the entire set of tasks, which is a common error to avoid."
  },
  {
    "question": "What happens if you request too many cores for each task in a task array?",
    "answer": "If you request multiple cores per task in a task array (e.g., `--cpus-per-task=12` for an array of 12 tasks), each individual task will receive all 12 cores, leading to an overestimation of resources if only one core is needed per task."
  },
  {
    "question": "What is the recommended configuration for a task array where each task needs one core and 9GB of memory?",
    "answer": "The recommended configuration would be to use `#SBATCH --cpus-per-task=1` and `#SBATCH --mem-per-cpus=9G`."
  },
  {
    "question": "What is the primary purpose of interactive tasks?",
    "answer": "Interactive tasks should remain short and be reserved for testing or debugging, not for complete development."
  },
  {
    "question": "What are the time and resource constraints for interactive tasks?",
    "answer": "Interactive tasks should last less than 6 hours and use the minimum possible resources."
  },
  {
    "question": "Where should full development be performed, as opposed to quick tests?",
    "answer": "Development should be performed on your local computer, while quick tests can be done in an interactive environment."
  },
  {
    "question": "What is the benefit of requesting minimal resources for interactive tasks?",
    "answer": "By requesting minimal resources, you reduce waiting times and preserve your priority in the execution queue."
  },
  {
    "question": "How can Jupyter notebooks be run as Python scripts?",
    "answer": "If you are working in a Jupyter notebook, you can convert them into scripts by consulting the JupyterHub documentation."
  },
  {
    "question": "What is the recommended `salloc` command for an interactive CPU task?",
    "answer": "A recommended `salloc` command for an interactive CPU task is: `$ salloc --time=1:0:0 --mem-per-cpu=4G --cpus-per-task=1 --account=def-someuser`."
  },
  {
    "question": "What is the recommended `salloc` command for an interactive GPU task?",
    "answer": "A recommended `salloc` command for an interactive GPU task is: `$ salloc --time=1:0:0 --mem-per-cpu=4G --cpus-per-task=1 --gres=gpu:a100_1g.5gb:1 --account=def-someuser`."
  },
  {
    "question": "How can a user request the total memory of a node in a submission script?",
    "answer": "To request the total memory of a node, you can configure your submission script by using `#SBATCH --mem=0`."
  }
]