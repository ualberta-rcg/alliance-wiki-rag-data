[
  {
    "question": "Qu'est-ce que PyTorch ?",
    "answer": "PyTorch est un paquet Python qui offre deux fonctionnalit\u00e9s de haut niveau : le calcul tensoriel (semblable \u00e0 celui effectu\u00e9 par NumPy) avec forte acc\u00e9l\u00e9ration de GPU, et des r\u00e9seaux de neurones d\u2019apprentissage profond dans un syst\u00e8me de gradients con\u00e7u sur le mod\u00e8le d\u2019un magn\u00e9tophone."
  },
  {
    "question": "Quelles sont les deux fonctionnalit\u00e9s principales offertes par PyTorch ?",
    "answer": "PyTorch offre le calcul tensoriel avec forte acc\u00e9l\u00e9ration de GPU, et des r\u00e9seaux de neurones d\u2019apprentissage profond dans un syst\u00e8me de gradients con\u00e7u sur le mod\u00e8le d\u2019un magn\u00e9tophone."
  },
  {
    "question": "Faut-il consid\u00e9rer PyTorch et Torch comme des projets similaires ?",
    "answer": "Bien qu'il y ait une certaine ressemblance, pour des raisons pratiques, PyTorch et Torch peuvent \u00eatre consid\u00e9r\u00e9s comme des projets diff\u00e9rents."
  },
  {
    "question": "\u00c0 quoi sert LibTorch ?",
    "answer": "LibTorch permet d'impl\u00e9menter des extensions \u00e0 PyTorch \u00e0 l'aide de C++ et d'impl\u00e9menter des applications d'apprentissage machine en C++ pur."
  },
  {
    "question": "Comment les mod\u00e8les Python \u00e9crits avec PyTorch peuvent-ils \u00eatre utilis\u00e9s en C++ ?",
    "answer": "Les mod\u00e8les Python \u00e9crits avec PyTorch peuvent \u00eatre convertis et utilis\u00e9s en C++ avec TorchScript."
  },
  {
    "question": "Comment trouver la derni\u00e8re version de PyTorch ?",
    "answer": "Pour conna\u00eetre la derni\u00e8re version de PyTorch, utilisez la commande `avail_wheels torch`."
  },
  {
    "question": "Quelle est la m\u00e9thode recommand\u00e9e pour installer PyTorch ?",
    "answer": "La meilleure option est d'installer PyTorch avec Python wheels."
  },
  {
    "question": "Quelles sont les \u00e9tapes pour installer PyTorch en utilisant Python wheels ?",
    "answer": "1. Chargez un module Python avec `module load python`. 2. Cr\u00e9ez et d\u00e9marrez un environnement virtuel. 3. Installez PyTorch dans l'environnement virtuel avec `pip install`."
  },
  {
    "question": "Comment installer PyTorch pour une utilisation avec GPU et CPU dans un environnement virtuel ?",
    "answer": "Dans l'environnement virtuel, utilisez la commande `pip install --no-index torch`."
  },
  {
    "question": "Quelle version de Torch est requise pour les GPU H100 ?",
    "answer": "Torch 2.3 et sup\u00e9rieur est requis pour les GPU H100."
  },
  {
    "question": "Quels paquets suppl\u00e9mentaires peuvent \u00eatre install\u00e9s avec `torch` ?",
    "answer": "En plus de `torch`, vous pouvez aussi installer `torchvision`, `torchtext` et `torchaudio`."
  },
  {
    "question": "Comment installer `torch`, `torchvision`, `torchtext` et `torchaudio` en une seule commande ?",
    "answer": "Utilisez la commande `pip install --no-index torch torchvision torchtext torchaudio` dans un environnement virtuel."
  },
  {
    "question": "Comment soumettre une t\u00e2che PyTorch sur un cluster avec un script SLURM ?",
    "answer": "Un exemple de script `pytorch-test.sh` configure un environnement virtuel, installe PyTorch et ex\u00e9cute un script Python. La t\u00e2che est soumise avec `sbatch pytorch-test.sh`."
  },
  {
    "question": "Quelles ressources sont demand\u00e9es dans le script SLURM d'exemple pour une t\u00e2che PyTorch ?",
    "answer": "Le script d'exemple `pytorch-test.sh` demande 1 GPU, 6 c\u0153urs CPU par t\u00e2che et 32000 Mo (32 Go) de m\u00e9moire."
  },
  {
    "question": "Qu'est-ce que le mode TensorFloat-32 (TF32) de Nvidia dans PyTorch ?",
    "answer": "Le mode TensorFloat-32 (TF32) de Nvidia est un mode de calcul qui a \u00e9t\u00e9 ajout\u00e9 \u00e0 PyTorch avec la version 1.7.0. Il est disponible pour les architectures GPU d'Ampere et de Nvidia, et peut acc\u00e9l\u00e9rer les op\u00e9rations tensorielles jusqu'\u00e0 20 fois par rapport au FP32, mais peut r\u00e9duire la pr\u00e9cision num\u00e9rique."
  },
  {
    "question": "Sur quelles architectures GPU le mode TF32 est-il disponible ?",
    "answer": "Le mode TF32 est seulement disponible pour les architectures GPU d'Ampere et de Nvidia."
  },
  {
    "question": "Comment le mode TF32 affecte-t-il la performance et la pr\u00e9cision ?",
    "answer": "Le mode TF32 peut acc\u00e9l\u00e9rer les op\u00e9rations tensorielles jusqu'\u00e0 20 fois, mais ce gain en performance peut entra\u00eener une baisse de la pr\u00e9cision du r\u00e9sultat des op\u00e9rations."
  },
  {
    "question": "Quel \u00e9tait le comportement par d\u00e9faut de TF32 dans PyTorch versions 1.7.x \u00e0 1.11.x ?",
    "answer": "Dans les versions 1.7.x \u00e0 1.11.x, le mode TF32 \u00e9tait offert par d\u00e9faut pour les op\u00e9rations tensorielles."
  },
  {
    "question": "Comment le comportement par d\u00e9faut de TF32 a-t-il chang\u00e9 \u00e0 partir de PyTorch 1.12.0 ?",
    "answer": "\u00c0 partir de la version 1.12.0, TF32 est d\u00e9sactiv\u00e9 par d\u00e9faut pour les multiplications matricielles et activ\u00e9 par d\u00e9faut pour les convolutions, suite aux commentaires de la communaut\u00e9."
  },
  {
    "question": "Pourquoi la d\u00e9sactivation par d\u00e9faut de TF32 a-t-elle \u00e9t\u00e9 appliqu\u00e9e aux multiplications matricielles ?",
    "answer": "La d\u00e9sactivation par d\u00e9faut a \u00e9t\u00e9 appliqu\u00e9e aux multiplications matricielles car le gain en performance peut engendrer une baisse dans la pr\u00e9cision du r\u00e9sultat, ce qui pose probl\u00e8me avec les mod\u00e8les d'apprentissage profond utilisant des matrices mal conditionn\u00e9es ou de longues s\u00e9quences d'op\u00e9rations tensorielles."
  },
  {
    "question": "Comment activer ou d\u00e9sactiver TF32 pour les multiplications matricielles avec PyTorch 1.12.0 et sup\u00e9rieur ?",
    "answer": "Pour activer ou d\u00e9sactiver TF32 pour les multiplications matricielles, utilisez `torch.backends.cuda.matmul.allow_tf32 = True` ou `False`."
  },
  {
    "question": "Comment activer ou d\u00e9sactiver TF32 pour les convolutions avec PyTorch 1.12.0 et sup\u00e9rieur ?",
    "answer": "Pour activer ou d\u00e9sactiver TF32 pour les convolutions, utilisez `torch.backends.cudnn.allow_tf32 = True` ou `False`."
  }
]