[
  {
    "question": "What is PyTorch?",
    "answer": "PyTorch is a Python package that provides two high-level functionalities: tensor computation (similar to NumPy) with strong GPU acceleration, and deep learning neural networks within a tape-based gradient system."
  },
  {
    "question": "What are the two main high-level features offered by PyTorch?",
    "answer": "PyTorch offers tensor computation with strong GPU acceleration and deep learning neural networks in a tape-based gradient system."
  },
  {
    "question": "Is PyTorch the same as Torch?",
    "answer": "While there is some resemblance between PyTorch and Torch, for practical purposes, they can be considered different projects."
  },
  {
    "question": "What is LibTorch and what can it be used for?",
    "answer": "LibTorch is offered by PyTorch developers and allows for implementing PyTorch extensions using C++ and creating pure C++ machine learning applications."
  },
  {
    "question": "How can Python models written with PyTorch be converted for use in C++?",
    "answer": "Python models written with PyTorch can be converted and used in C++ with TorchScript."
  },
  {
    "question": "How can one find the latest version of PyTorch available?",
    "answer": "To find the latest version of PyTorch, use the command `avail_wheels torch`."
  },
  {
    "question": "What is the recommended installation method for PyTorch on the clusters?",
    "answer": "The best option is to install PyTorch using Python wheels."
  },
  {
    "question": "What are the steps to install PyTorch using Python wheels?",
    "answer": "1. Load a Python module with `module load python`. 2. Create and start a virtual environment. 3. Install PyTorch in the virtual environment with `pip install`."
  },
  {
    "question": "How do you install PyTorch for GPU and CPU support in a virtual environment?",
    "answer": "You can install it with `pip install --no-index torch` within your virtual environment."
  },
  {
    "question": "What PyTorch version is recommended for H100 GPUs?",
    "answer": "Torch 2.3 and higher is required for H100 GPUs."
  },
  {
    "question": "Are there any known issues with PyTorch 1.10 on the clusters?",
    "answer": "PyTorch 1.10 causes known problems on the clusters (except Narval). Distributed training might produce errors or you might get a `c10::Error`."
  },
  {
    "question": "What should be done if PyTorch 1.10 causes a `c10::Error`?",
    "answer": "If PyTorch 1.10 causes a `c10::Error`, it is recommended to install PyTorch 1.9.1 with `pip install --no-index torch==1.9.1`."
  },
  {
    "question": "What additional packages can be installed alongside `torch`?",
    "answer": "In addition to `torch`, you can also install `torchvision`, `torchtext`, and `torchaudio`."
  },
  {
    "question": "How can I install `torchvision`, `torchtext`, and `torchaudio` along with `torch`?",
    "answer": "You can install them by running `pip install --no-index torch torchvision torchtext torchaudio`."
  },
  {
    "question": "How do you submit a PyTorch job on the clusters?",
    "answer": "You submit a PyTorch job by creating a shell script (e.g., `pytorch-test.sh`) to load Python, set up a virtual environment, install PyTorch, and run your Python script (e.g., `pytorch-test.py`), then submitting it with `sbatch pytorch-test.sh`."
  },
  {
    "question": "What is TensorFloat-32 (TF32) mode in PyTorch?",
    "answer": "TensorFloat-32 (TF32) mode is a feature introduced in PyTorch 1.7.0, available only for Nvidia Ampere GPU architectures, which can accelerate tensor operations by up to 20x compared to single-precision (FP32)."
  },
  {
    "question": "What is the default state of TF32 mode in PyTorch versions 1.7.x to 1.11.x?",
    "answer": "In PyTorch versions 1.7.x to 1.11.x, TF32 mode is offered by default for tensor operations."
  },
  {
    "question": "How does the default TF32 behavior change in PyTorch 1.12.0 and later versions?",
    "answer": "Starting with PyTorch 1.12.0, TF32 is disabled by default for matrix multiplications and activated by default for convolutions."
  },
  {
    "question": "What is a potential drawback of using TF32 mode for performance gains?",
    "answer": "While TF32 mode offers performance gains, it can lead to a decrease in the precision of operation results, which might be an issue for deep learning models that use ill-conditioned matrices or perform long sequences of tensor operations."
  },
  {
    "question": "Which cluster had Ampere GPUs as of October 2022?",
    "answer": "As of October 2022, Narval was the only cluster offering Ampere GPUs."
  },
  {
    "question": "How can TF32 be enabled or disabled for matrix multiplications in PyTorch versions 1.12.0 and above?",
    "answer": "To enable or disable TF32 for matrix multiplications in PyTorch versions 1.12.0 and above, set `torch.backends.cuda.matmul.allow_tf32 = True` or `False`."
  },
  {
    "question": "How can TF32 be enabled or disabled for convolutions in PyTorch versions 1.12.0 and above?",
    "answer": "To enable or disable TF32 for convolutions in PyTorch versions 1.12.0 and above, set `torch.backends.cudnn.allow_tf32 = True` or `False`."
  },
  {
    "question": "What are the two ways PyTorch allows parallelism with multiple CPUs by default?",
    "answer": "PyTorch allows intra-op parallelism (parallel implementation of common deep learning operators using OpenMP, MKL, or OneDNN) and inter-op parallelism (concurrent execution of different code parts, often using `torch.jit`)."
  },
  {
    "question": "Why is it often recommended to use multiple CPUs instead of a GPU for small models on shared clusters?",
    "answer": "For small models and datasets, the speed gain with a GPU might not be significant, leading to underutilization. On shared clusters, this blocks a resource for large-scale computations and impacts group allocations and job priority, making multiple CPUs a better choice."
  }
]