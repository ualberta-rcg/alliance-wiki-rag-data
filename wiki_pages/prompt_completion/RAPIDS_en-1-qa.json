[
  {
    "question": "What is RAPIDS?",
    "answer": "RAPIDS is a suite of open-source software libraries from NVIDIA, primarily designed for executing data science and analytics pipelines in Python on GPUs. It uses NVIDIA CUDA primitives for low-level compute optimization and offers Python APIs similar to Pandas or Scikit-learn."
  },
  {
    "question": "What are the main components of RAPIDS?",
    "answer": "The main components of RAPIDS include cuDF, cuML, cuGraph, Cyber Log Accelerators (CLX), cuxFilter, cuSpatial, cuSignal, cuCIM, and RAPIDS Memory Manager (RMM)."
  },
  {
    "question": "What is cuDF?",
    "answer": "cuDF is a Python GPU DataFrame library built on the Apache Arrow columnar memory format, used for loading, joining, aggregating, filtering, and manipulating data."
  },
  {
    "question": "What is cuML?",
    "answer": "cuML is a suite of libraries within RAPIDS that implements machine learning algorithms and mathematical primitive functions with compatible APIs."
  },
  {
    "question": "What is cuGraph?",
    "answer": "cuGraph is a GPU accelerated graph analytics library, providing functionality similar to NetworkX, and is seamlessly integrated into the RAPIDS data science platform."
  },
  {
    "question": "What are Cyber Log Accelerators (CLX)?",
    "answer": "Cyber Log Accelerators, also known as 'clicks' or CLX, are a collection of RAPIDS examples aimed at security analysts, data scientists, and engineers to quickly apply RAPIDS and GPU acceleration to cybersecurity use cases."
  },
  {
    "question": "What is cuxFilter used for?",
    "answer": "cuxFilter is a connector library that facilitates connections between different visualization libraries and a GPU dataframe, allowing the use of charts from various libraries in a single interactive dashboard."
  },
  {
    "question": "What is cuSpatial?",
    "answer": "cuSpatial is a GPU accelerated C++/Python library designed to accelerate GIS workflows, including tasks like point-in-polygon, spatial join, coordinate systems, shape primitives, distances, and trajectory analysis."
  },
  {
    "question": "What is cuSignal?",
    "answer": "cuSignal leverages CuPy, Numba, and the RAPIDS ecosystem for GPU accelerated signal processing. It can be a direct port of Scipy Signal to use GPU compute resources via CuPy and also contains Numba CUDA kernels for additional speedups."
  },
  {
    "question": "What is cuCIM?",
    "answer": "cuCIM is an extensible toolkit providing GPU accelerated I/O, computer vision, and image processing primitives for N-Dimensional images, with a focus on biomedical imaging."
  },
  {
    "question": "What is the purpose of RAPIDS Memory Manager (RMM)?",
    "answer": "RAPIDS Memory Manager (RMM) serves as a central place for all device memory allocations in cuDF (C++ and Python) and other RAPIDS libraries. It also functions as a replacement allocator for CUDA Device Memory and a pool allocator to make CUDA device memory allocation/deallocation faster and asynchronous."
  },
  {
    "question": "What is the first step to build an Apptainer image for RAPIDS?",
    "answer": "The first step to building an Apptainer image for RAPIDS is to find and select a Docker image provided by NVIDIA."
  },
  {
    "question": "What are the two types of RAPIDS Docker images available since v23.08?",
    "answer": "Starting with the RAPIDS v23.08 release, there are two types of RAPIDS Docker images: 'base' and 'notebooks'."
  },
  {
    "question": "When should you use a RAPIDS Base Docker image?",
    "answer": "You should use a RAPIDS Base image if you want to submit a job to the Slurm scheduler, as it contains a RAPIDS environment ready for use."
  },
  {
    "question": "When should you use a RAPIDS Notebooks Docker image?",
    "answer": "You should use a RAPIDS Notebooks image if you want to interactively work with RAPIDS through notebooks and examples, as it extends the base image by adding a Jupyter notebook server and example notebooks."
  },
  {
    "question": "How can you find the image tag of a selected RAPIDS Docker image?",
    "answer": "You can find the image tag of a selected Docker image under the 'Tags' tab on each respective NVIDIA container site."
  },
  {
    "question": "Provide an example command to build an Apptainer image from a RAPIDS Docker image.",
    "answer": "An example command to build an Apptainer image named 'rapids.sif' from a Docker image tag like 'nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.0-py3.12' is: `apptainer build rapids.sif docker://nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.0-py3.12`."
  },
  {
    "question": "How long does it typically take to complete the Apptainer image-building process for RAPIDS?",
    "answer": "It usually takes from thirty to sixty minutes to complete the image-building process for a RAPIDS Apptainer image."
  },
  {
    "question": "What resources are required on the server to build a RAPIDS Apptainer image?",
    "answer": "Due to the relatively large image size, you need to have enough memory and disk space on the server to build a RAPIDS Apptainer image."
  },
  {
    "question": "What can you do once a RAPIDS Apptainer image is ready in your account?",
    "answer": "Once a RAPIDS Apptainer image is ready, you can request an interactive session on a GPU node or submit a batch job to Slurm if your RAPIDS code is prepared."
  },
  {
    "question": "How can an Apptainer image built from a 'Notebooks' Docker image be used on a GPU node?",
    "answer": "If an Apptainer image was built based on a 'Notebooks' Docker image, it includes a Jupyter Notebook server and can be used to explore RAPIDS interactively on a compute node with a GPU."
  }
]