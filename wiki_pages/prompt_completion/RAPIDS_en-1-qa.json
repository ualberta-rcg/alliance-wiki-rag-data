[
  {
    "question": "What is RAPIDS?",
    "answer": "RAPIDS is a suite of open source software libraries from NVIDIA designed mainly for executing data science and analytics pipelines in Python on GPUs."
  },
  {
    "question": "What does RAPIDS use for low-level compute optimization?",
    "answer": "RAPIDS relies on NVIDIA CUDA primitives for low-level compute optimization."
  },
  {
    "question": "Which RAPIDS component is a Python GPU DataFrame library?",
    "answer": "cuDF is a Python GPU DataFrame library within RAPIDS."
  },
  {
    "question": "What is cuDF built upon?",
    "answer": "cuDF is built on the Apache Arrow columnar memory format."
  },
  {
    "question": "What is the function of cuML?",
    "answer": "cuML is a suite of libraries that implement machine learning algorithms and mathematical primitive functions with compatible APIs across RAPIDS projects."
  },
  {
    "question": "What is cuGraph?",
    "answer": "cuGraph is a GPU accelerated graph analytics library, providing functionality similar to NetworkX and seamlessly integrated into the RAPIDS data science platform."
  },
  {
    "question": "What does CLX stand for and what is its purpose?",
    "answer": "CLX, or Cyber Log Accelerators (sometimes called 'clicks'), is a collection of RAPIDS examples for security analysts, data scientists, and engineers to apply RAPIDS and GPU acceleration to cybersecurity use cases."
  },
  {
    "question": "What is cuxFilter used for?",
    "answer": "cuxFilter is a connector library that provides connections between different visualization libraries and a GPU dataframe, allowing the use of charts from various libraries in a single interactive dashboard."
  },
  {
    "question": "What kind of workflows does cuSpatial accelerate?",
    "answer": "cuSpatial accelerates GIS workflows, including point-in-polygon, spatial join, coordinate systems, shape primitives, distances, and trajectory analysis, using a GPU accelerated C++/Python library."
  },
  {
    "question": "Which RAPIDS component focuses on GPU accelerated signal processing?",
    "answer": "cuSignal leverages CuPy, Numba, and the RAPIDS ecosystem for GPU accelerated signal processing, often acting as a direct port of Scipy Signal to GPUs or using Numba CUDA kernels for additional speedups."
  },
  {
    "question": "What is cuCIM designed for?",
    "answer": "cuCIM is an extensible toolkit designed to provide GPU accelerated I/O, computer vision, and image processing primitives for N-Dimensional images, with a focus on biomedical imaging."
  },
  {
    "question": "What is the role of the RAPIDS Memory Manager (RMM)?",
    "answer": "RMM is a central place for all device memory allocations in cuDF (C++ and Python) and other RAPIDS libraries. It serves as a replacement allocator for CUDA Device Memory (and CUDA Managed Memory) and a pool allocator to make CUDA device memory allocation/deallocation faster and asynchronous."
  },
  {
    "question": "What is the first step when building an Apptainer image for RAPIDS?",
    "answer": "The first step to build an Apptainer image for RAPIDS is to find and select a Docker image provided by NVIDIA."
  },
  {
    "question": "What was Apptainer formerly known as?",
    "answer": "Apptainer was formerly called Singularity."
  },
  {
    "question": "What are the two types of RAPIDS Docker images available from release v23.08 onwards?",
    "answer": "Starting with the RAPIDS v23.08 release, there are two types of RAPIDS Docker images: 'base' and 'notebooks'."
  },
  {
    "question": "When should you use a 'RAPIDS Base' Docker image?",
    "answer": "You should use a 'RAPIDS Base' image if you want to submit a job to the Slurm scheduler, as it contains a RAPIDS environment ready for use."
  },
  {
    "question": "When should you use a 'RAPIDS Notebooks' Docker image?",
    "answer": "You should use a 'RAPIDS Notebooks' image if you want to interactively work with RAPIDS through notebooks and examples, as it extends the base image with a Jupyter notebook server and example notebooks."
  },
  {
    "question": "Where can one find the image tag for a selected RAPIDS Docker image?",
    "answer": "You can find the image tag of a selected image under the 'Tags' tab on each respective NVIDIA catalog site."
  },
  {
    "question": "How do you build an Apptainer image named 'rapids.sif' from a Docker image tag like 'nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.0-py3.12'?",
    "answer": "You can build the Apptainer image using the command: `apptainer build rapids.sif docker://nvcr.io/nvidia/rapidsai/notebooks:25.04-cuda12.0-py3.12`."
  },
  {
    "question": "How long does it typically take to build a RAPIDS Apptainer image?",
    "answer": "It usually takes from thirty to sixty minutes to complete the image-building process."
  },
  {
    "question": "What resources are required on the server to build a RAPIDS Apptainer image?",
    "answer": "Since the image size is relatively large, you need to have enough memory and disk space on the server to build such an image."
  },
  {
    "question": "What are the two main ways to work with a RAPIDS Apptainer image on clusters once it's ready?",
    "answer": "Once a RAPIDS Apptainer image is ready, you can request an interactive session on a GPU node or submit a batch job to the Slurm scheduler."
  },
  {
    "question": "What type of Apptainer image is suitable for interactive work with Jupyter Notebooks on a GPU node?",
    "answer": "An Apptainer image built based on a 'Notebooks' type of Docker image is suitable for interactive work with Jupyter Notebooks on a compute node with a GPU."
  },
  {
    "question": "What is an example command to request an interactive session on a compute node with a single GPU?",
    "answer": "An example command to request an interactive session on a compute node with a single GPU is: `salloc --ntasks=1 --cpus-per-task=2 --mem=10G --gpus-per-node=1 --time=1:0:0 --account=def-someuser`."
  }
]