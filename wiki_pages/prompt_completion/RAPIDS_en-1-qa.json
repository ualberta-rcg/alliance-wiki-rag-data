[
  {
    "question": "What is RAPIDS?",
    "answer": "RAPIDS is a suite of open source software libraries from NVIDIA mainly for executing data science and analytics pipelines in Python on GPUs."
  },
  {
    "question": "What do RAPIDS libraries rely on for low-level compute optimization?",
    "answer": "RAPIDS relies on NVIDIA CUDA primitives for low-level compute optimization."
  },
  {
    "question": "Which RAPIDS component is a Python GPU DataFrame library?",
    "answer": "cuDF is a Python GPU DataFrame library, built on the Apache Arrow columnar memory format, for loading, joining, aggregating, filtering, and otherwise manipulating data."
  },
  {
    "question": "What is the primary function of cuML?",
    "answer": "cuML is a suite of libraries that implement machine learning algorithms and mathematical primitive functions that share compatible APIs with other RAPIDS projects."
  },
  {
    "question": "What kind of library is cuGraph?",
    "answer": "cuGraph is a GPU accelerated graph analytics library, with functionality like NetworkX, which is seamlessly integrated into the RAPIDS data science platform."
  },
  {
    "question": "What does CLX stand for and what is its purpose?",
    "answer": "CLX stands for Cyber Log Accelerators, and it is a collection of RAPIDS examples for security analysts, data scientists, and engineers to quickly get started applying RAPIDS and GPU acceleration to real-world cybersecurity use cases."
  },
  {
    "question": "What functionality does cuxFilter provide?",
    "answer": "cuxFilter is a connector library that provides connections between different visualization libraries and a GPU dataframe without much hassle, allowing charts from different libraries in a single dashboard with interaction."
  },
  {
    "question": "Which RAPIDS library is designed for accelerating GIS workflows?",
    "answer": "cuSpatial is a GPU accelerated C++/Python library for accelerating GIS workflows including point-in-polygon, spatial join, coordinate systems, shape primitives, distances, and trajectory analysis."
  },
  {
    "question": "How does cuSignal achieve GPU accelerated signal processing?",
    "answer": "cuSignal leverages CuPy, Numba, and the RAPIDS ecosystem for GPU accelerated signal processing. It can be a direct port of Scipy Signal to leverage GPU compute resources via CuPy and also contains Numba CUDA kernels for additional speedups."
  },
  {
    "question": "What is the focus of cuCIM?",
    "answer": "cuCIM is an extensible toolkit designed to provide GPU accelerated I/O, computer vision & image processing primitives for N-Dimensional images with a focus on biomedical imaging."
  },
  {
    "question": "What is the role of the RAPIDS Memory Manager (RMM)?",
    "answer": "The RAPIDS Memory Manager (RMM) is a central place for all device memory allocations in cuDF (C++ and Python) and other RAPIDS libraries. It is also a replacement allocator for CUDA Device Memory and a pool allocator to make CUDA device memory allocation / deallocation faster and asynchronous."
  },
  {
    "question": "What is the initial step for building an Apptainer image for RAPIDS?",
    "answer": "The first thing to do is to find and select a Docker image provided by NVIDIA."
  },
  {
    "question": "What are the two types of RAPIDS Docker images available starting with the v23.08 release?",
    "answer": "Starting with the RAPIDS v23.08 release, there are two types of RAPIDS Docker images: 'base' and 'notebooks'."
  },
  {
    "question": "When should one use a 'RAPIDS Base' Docker image?",
    "answer": "Use the 'RAPIDS Base' type of image if you want to submit a job to the Slurm scheduler, as it contains a RAPIDS environment ready for use."
  },
  {
    "question": "When should one use a 'RAPIDS Notebooks' Docker image?",
    "answer": "Use the 'RAPIDS Notebooks' type of image if you want to interactively work with RAPIDS through notebooks and examples, as it extends the base image by adding a Jupyter notebook server and example notebooks."
  },
  {
    "question": "Where can the Docker `pull` command for a selected RAPIDS image be found?",
    "answer": "The Docker `pull` command for a selected image can be found under the 'Tags' tab on each site (NVIDIA catalog)."
  },
  {
    "question": "How do you build an Apptainer image from a Docker `pull` tag?",
    "answer": "You can build an Apptainer image (e.g., 'rapids.sif') using a command like: `apptainer build rapids.sif docker://nvcr.io/nvidia/rapidsai/rapidsai:cuda11.0-runtime-centos7`."
  },
  {
    "question": "Approximately how long does it take to build a RAPIDS Apptainer image?",
    "answer": "It usually takes from thirty to sixty minutes to complete the image-building process."
  },
  {
    "question": "What resources are necessary to build a RAPIDS Apptainer image?",
    "answer": "Since the image size is relatively large, you need to have enough memory and disk space on the server to build such an image."
  },
  {
    "question": "What are the two ways to use a RAPIDS Apptainer image on clusters?",
    "answer": "Once you have an Apptainer image for RAPIDS ready, you can request an interactive session on a GPU node or submit a batch job to Slurm."
  },
  {
    "question": "What type of Apptainer image is needed for interactive work with Jupyter Notebooks on a GPU node?",
    "answer": "If an Apptainer image was built based on a `Notebooks` type of Docker image, it includes a Jupyter Notebook server and can be used to explore RAPIDS interactively on a compute node with a GPU."
  },
  {
    "question": "What is the function of the `--nv` option when starting a RAPIDS shell with Apptainer?",
    "answer": "The `--nv` option binds the GPU driver on the host to the container, so the GPU device can be accessed from inside the Apptainer container."
  },
  {
    "question": "What is the purpose of the `-B` option when using `apptainer shell`?",
    "answer": "The `-B` option binds any filesystem that you would like to access from inside the container."
  },
  {
    "question": "How can you check if the GPU device is accessible within the Apptainer container?",
    "answer": "After the shell prompt changes to `Apptainer>`, you can check the GPU stats in the container by running `nvidia-smi`."
  },
  {
    "question": "How do you launch the Jupyter Notebook server from within the Apptainer shell?",
    "answer": "You can launch the Jupyter Notebook server in the RAPIDS environment with the command `jupyter-lab --ip $(hostname -f) --no-browser`."
  },
  {
    "question": "What is the default state of packages in the RAPIDS v23.08 container shell?",
    "answer": "Starting with the RAPIDS v23.08 release, all packages are included in the base conda environment which is activated by default in the container shell."
  }
]