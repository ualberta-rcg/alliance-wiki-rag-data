[
  {
    "question": "How do you use a Hugging Face pipeline in an environment without an internet connection?",
    "answer": "In an environment without internet connection, such as inside a job, you must explicitly specify the location of the model and its tokenizer when calling `pipeline`. For example, load them with `AutoModel.from_pretrained(\"/path/to/where/model/is/saved\", local_files_only=True)` and then pass them to `pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer)`."
  },
  {
    "question": "What happens if a Hugging Face pipeline attempts to download models in an offline job?",
    "answer": "If a pipeline attempts to download models from the internet in an offline job, it will result in a connection timeout error."
  },
  {
    "question": "What is the primary function of the Hugging Face Datasets package?",
    "answer": "Datasets is a Python package designed for easily accessing and sharing datasets for Audio, Computer Vision, and Natural Language Processing (NLP) tasks."
  },
  {
    "question": "What are the recommended steps to install the Hugging Face Datasets package?",
    "answer": "The recommended steps are: 1. Load a Python module (`module load python`). 2. Create and start a virtual environment. 3. Load the Arrow module (`module load gcc/9.3.0 arrow/11.0.0`). 4. Install Datasets in the virtual environment with `pip install --no-index datasets`."
  },
  {
    "question": "Why is it necessary to load the Arrow module when using the Datasets package?",
    "answer": "Loading the Arrow module makes the `pyarrow` package, which is a dependency of Datasets, available inside your virtual environment. It must be loaded every time you intend to import the Datasets package."
  },
  {
    "question": "Where should datasets from the Hugging Face hub be downloaded?",
    "answer": "Any download of a dataset from the Hugging Face hub must be performed on a login node."
  },
  {
    "question": "What is the default cache directory for downloaded Hugging Face datasets?",
    "answer": "The default cache directory for downloaded Hugging Face datasets is `$HOME/.cache/huggingface/datasets`."
  },
  {
    "question": "How can you change the default cache location for Hugging Face datasets?",
    "answer": "You can change the default cache location for Hugging Face datasets by setting the environment variable `HF_DATASETS_CACHE` before importing anything from the Datasets package in your Python script."
  },
  {
    "question": "How do you load a dataset in an offline job (without internet connection)?",
    "answer": "To load a dataset in an offline job, set the environment variable `HF_DATASETS_OFFLINE=1` and specify the local path to the dataset's cache directory when calling `load_dataset()`, for example: `os.environ['HF_DATASETS_OFFLINE'] = '1'; dataset = load_dataset(\"/path/to/loading_script/of/the/dataset\")`."
  },
  {
    "question": "What is the Hugging Face Evaluate library used for?",
    "answer": "Evaluate is a library for easily evaluating machine learning models and datasets, offering access to dozens of evaluation methods for various domains like NLP, Computer Vision, and Reinforcement Learning."
  },
  {
    "question": "What are the recommended steps to install the Hugging Face Evaluate package?",
    "answer": "The recommended steps are: 1. Load a Python module (`module load python`). 2. Create and start a virtual environment. 3. Load the Arrow module (`module load gcc arrow`). 4. Install Evaluate in the virtual environment with `pip install --no-index evaluate`."
  },
  {
    "question": "Is it necessary to load the Arrow module when importing the Evaluate package?",
    "answer": "Yes, you will need to load the Arrow module every time you intend to import the Evaluate package in your Python script because `pyarrow` is a dependency."
  },
  {
    "question": "Where must evaluators be downloaded before being used in a job?",
    "answer": "Any evaluators you wish to use in your code must first be downloaded on a login node before submitting a job."
  },
  {
    "question": "How do you download an evaluator using the Evaluate library, for instance, an accuracy evaluator?",
    "answer": "To download an evaluator, simply call the `evaluate.load()` method on a login node. For example, to download an accuracy evaluator, run: `import evaluate; evaluate.load(\"accuracy\")`."
  },
  {
    "question": "How do you prevent the Evaluate package from attempting to download evaluators in an offline job?",
    "answer": "Inside a job on compute nodes without internet connection, you must set the environment variable `HF_EVALUATE_OFFLINE=1` to prevent Evaluate from attempting to download evaluators from the web."
  },
  {
    "question": "What is the default storage location for downloaded evaluators?",
    "answer": "Evaluators are saved at the default location `$HOME/.cache/huggingface/evaluate`."
  },
  {
    "question": "How can you change the storage location for Hugging Face evaluators and other ecosystem libraries?",
    "answer": "You can change the storage location for evaluators and all Hugging Face ecosystem libraries (like Transformers and Datasets) by setting the environment variable `HF_HOME` to your desired storage location."
  }
]