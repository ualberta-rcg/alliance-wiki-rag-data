[
  {
    "question": "What are the key learning objectives for this document?",
    "answer": "The learning objectives are to understand the difference between a CPU and an accelerator, the difference between speed and throughput, and the steps to port an existing code to an accelerator."
  },
  {
    "question": "How did Central Processing Units (CPUs) historically develop in terms of task optimization?",
    "answer": "Historically, computing developed around Central Processing Units (CPUs) that were optimized for sequential tasks, completing only one compute operation during a given clock cycle."
  },
  {
    "question": "When did high-end CPU clock frequencies reach a plateau, and at what approximate speed?",
    "answer": "The top speed of high-end CPUs reached a plateau around 2005, at approximately 4 GHz."
  },
  {
    "question": "What technological shift did manufacturers make in CPUs after clock frequencies plateaued?",
    "answer": "Instead of increasing clock frequency, manufacturers started adding multiple computation cores within a single chipset, opening wide the era of parallel computing."
  },
  {
    "question": "Why do sequential tasks still run fastest on CPUs as of 2022?",
    "answer": "Sequential tasks still run fastest on CPUs because they have direct access to large main computer memory and can run a small number of tasks very quickly due to their very fast clock speed."
  },
  {
    "question": "What are some of the weaknesses of CPUs?",
    "answer": "CPUs have relatively low memory bandwidth, costly cache misses (despite cache mechanisms to mitigate low bandwidth), and are rather power-hungry compared to accelerators."
  },
  {
    "question": "What defines typical accelerators such as GPUs or coprocessors?",
    "answer": "Typical accelerators are highly parallel chipsets made out of hundreds or thousands of relatively simple and low-frequency compute cores, optimized for parallel computing."
  },
  {
    "question": "What advantages do high-end GPUs offer over high-end CPUs?",
    "answer": "High-end GPUs present significantly more compute resources than high-end CPUs, providing much higher throughput and much better performance per watt."
  },
  {
    "question": "What are the main drawbacks of accelerators?",
    "answer": "Accelerators embed a relatively low amount of memory and have a low per-thread performance."
  },
  {
    "question": "How is a 'high speed' device characterized?",
    "answer": "A high speed device will accomplish a single task within a very short amount of time."
  },
  {
    "question": "For what kind of computational task is a high speed device most suitable?",
    "answer": "A high speed device is most suitable for a single sequential computation, such as the resolution of a one-dimensional differential equation."
  },
  {
    "question": "What is the defining characteristic of a 'high throughput' device?",
    "answer": "A high throughput device will accomplish much more work, but in a longer amount of time."
  },
  {
    "question": "What types of problems are best solved using a high throughput device?",
    "answer": "A high throughput device is best for highly parallel problems, including matrix operations, Fourier transforms, and multidimensional differential equations."
  },
  {
    "question": "How is porting code to accelerators viewed in a broader context?",
    "answer": "Porting a code to accelerators can be seen as a phase of an optimization process."
  },
  {
    "question": "What are the typical steps in a general code optimization process?",
    "answer": "A typical optimization process involves profiling the code, identifying bottlenecks, optimizing the most significant bottleneck, validating the resulting code, and then restarting the process."
  },
  {
    "question": "What are the specific steps involved in porting a code to accelerators?",
    "answer": "The steps for porting code to accelerators are to profile the code, identify parallelism within the bottlenecks, port the code (by expressing parallelism to the compiler, expressing data movement, and optimizing loops), validate the resulting code, and then restart the process."
  },
  {
    "question": "How does OpenACC assist in expressing parallelism during code porting?",
    "answer": "OpenACC is a descriptive language that allows the programmer to tell the compiler which portions of the code can be parallelized by adding directives, letting the compiler figure out how to do it."
  },
  {
    "question": "What is the purpose of the 'express data movement' phase when porting code to accelerators?",
    "answer": "In the 'express data movement' phase, the programmer addresses unnecessary data movement that even the best compilers might miss, improving performance."
  },
  {
    "question": "Why is it important for a programmer to 'optimize loops' when porting code to accelerators?",
    "answer": "The programmer optimizes loops because they may possess information not available to the compiler, which allows them to achieve better performance by tuning those loops."
  }
]