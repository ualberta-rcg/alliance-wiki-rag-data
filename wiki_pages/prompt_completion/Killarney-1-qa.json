[
  {
    "question": "When will the Killarney cluster be available?",
    "answer": "Killarney will be available on June 9, 2025."
  },
  {
    "question": "What is the login node for Killarney?",
    "answer": "The login node for Killarney is killarney.alliancecan.ca."
  },
  {
    "question": "Is there a Globus collection available for Killarney?",
    "answer": "The Globus collection for Killarney is currently 'TBA' (To Be Announced)."
  },
  {
    "question": "Where can I find the System Status Page for Killarney?",
    "answer": "The System Status Page for Killarney is currently 'TBA' (To Be Announced)."
  },
  {
    "question": "What is the primary purpose of the Killarney cluster?",
    "answer": "Killarney is a cluster dedicated to the needs of the Canadian scientific Artificial Intelligence community."
  },
  {
    "question": "Where is the Killarney cluster physically located?",
    "answer": "The Killarney cluster is located at the University of Toronto."
  },
  {
    "question": "Who manages the Killarney cluster?",
    "answer": "Killarney is managed by the Vector Institute and SciNet."
  },
  {
    "question": "What is the origin of the Killarney cluster's name?",
    "answer": "Killarney is named after the Killarney Ontario Provincial Park, which is located near Georgian Bay."
  },
  {
    "question": "Is Killarney part of a larger computing environment?",
    "answer": "Yes, this cluster is part of the Pan-Canadian AI Compute Environment (PAICE)."
  },
  {
    "question": "Who is currently eligible to access Killarney?",
    "answer": "Killarney is currently open to Vector affiliated PIs with CCAI Chairs."
  },
  {
    "question": "How do researchers gain access to the Killarney cluster?",
    "answer": "To access Killarney, each researcher must request access in the CCDB."
  },
  {
    "question": "What type of Resource Allocation Project (RAP) do Principal Investigators need for Killarney?",
    "answer": "Principal Investigators must be granted an AIP-type RAP (with prefix `aip-`) by their AI Institution."
  },
  {
    "question": "How can a Principal Investigator sponsor other researchers in their AIP RAP for Killarney?",
    "answer": "The PI must go to the 'Resource Allocation Projects' table on the CCDB Home page, locate their AIP project's RAPI, click on it to reach the RAP management page, then click on 'Manage RAP memberships' at the bottom, and enter the CCRI of the user in the 'Add Members' section."
  },
  {
    "question": "What cybersecurity control does Vector enforce on Killarney access?",
    "answer": "Vector enforces geo-blocking on Killarney, restricting access to and from countries identified in the Government of Canada's Cyber Threat Assessment."
  },
  {
    "question": "How many Standard Compute nodes are in Killarney?",
    "answer": "Killarney has 168 Standard Compute nodes."
  },
  {
    "question": "What CPU model is used in Killarney's Standard Compute nodes?",
    "answer": "Killarney's Standard Compute nodes use 2 x Intel Xeon Gold 6338 CPUs."
  },
  {
    "question": "How much system memory does each Killarney Standard Compute node have?",
    "answer": "Each Killarney Standard Compute node has 512 GB of system memory."
  },
  {
    "question": "What type and quantity of GPUs are installed per Standard Compute node?",
    "answer": "Each Standard Compute node has 4 x NVIDIA L40S 48GB GPUs."
  },
  {
    "question": "What is the total number of GPUs in the Killarney Standard Compute tier?",
    "answer": "The total number of GPUs in the Standard Compute tier is 672."
  },
  {
    "question": "How many Performance Compute nodes does Killarney feature?",
    "answer": "Killarney has 10 Performance Compute nodes."
  },
  {
    "question": "What CPU is installed in Killarney's Performance Compute nodes?",
    "answer": "Killarney's Performance Compute nodes use 2 x Intel Xeon Gold 6442Y CPUs."
  },
  {
    "question": "How much system memory is available in each Killarney Performance Compute node?",
    "answer": "Each Killarney Performance Compute node has 2048 GB of system memory."
  },
  {
    "question": "What type and quantity of GPUs are installed per Performance Compute node?",
    "answer": "Each Performance Compute node has 8 x NVIDIA H100 SXM 80GB GPUs."
  },
  {
    "question": "What kind of storage system does Killarney use?",
    "answer": "Killarney's storage system is an all-NVME VastData platform."
  },
  {
    "question": "What is the total usable capacity of Killarney's storage system?",
    "answer": "The total usable capacity of Killarney's storage system is 1.7PB."
  },
  {
    "question": "What are the characteristics of the Killarney Home space?",
    "answer": "The Home space is the location of /home directories, has a small fixed quota, supports larger requests going to /project space, and has daily backup."
  },
  {
    "question": "How is inactive data managed in the Scratch space?",
    "answer": "Inactive data in the Scratch space will be purged."
  },
  {
    "question": "Does the Killarney Project space offer daily backup?",
    "answer": "Yes, the Project space has daily backup."
  },
  {
    "question": "What kind of network interconnects do the Standard Compute nodes use?",
    "answer": "Standard Compute nodes are interconnected with Infiniband HDR100 for 100Gbps throughput."
  },
  {
    "question": "What is the aggregate throughput for the Performance Compute nodes' network interconnects?",
    "answer": "Performance Compute nodes are connected with 2 x HDR 200 for 400Gbps aggregate throughput."
  },
  {
    "question": "Which scheduler does the Killarney cluster use?",
    "answer": "The Killarney cluster uses the Slurm scheduler to run user workloads."
  },
  {
    "question": "How is software organized on Killarney?",
    "answer": "Killarney uses a module-based software stack."
  },
  {
    "question": "What types of software are available on Killarney?",
    "answer": "Both the standard Alliance software stack as well as cluster-specific software are available."
  }
]