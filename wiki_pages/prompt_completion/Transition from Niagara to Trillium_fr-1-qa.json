[
  {
    "question": "How do I request access to Trillium?",
    "answer": "You must make a request for access on CCDB, specifically on the new page [https://ccdb.alliancecan.ca/me/access_systems](https://ccdb.alliancecan.ca/me/access_systems)."
  },
  {
    "question": "Who automatically gets access to Trillium?",
    "answer": "Users who obtained access to Niagara or Mist before August 5, 2025, automatically have access to Trillium."
  },
  {
    "question": "What types of sub-clusters are available on Trillium?",
    "answer": "On Trillium, you have access to both CPU and GPU sub-clusters."
  },
  {
    "question": "How do I request access to HPSS on Trillium?",
    "answer": "You need to request access to HPSS (the /nearline system) on Trillium through the CCDB page [https://ccdb.alliancecan.ca/me/access_systems](https://ccdb.alliancecan.ca/me/access_systems)."
  },
  {
    "question": "Is HPSS integrated with Trillium yet?",
    "answer": "HPSS is not yet integrated with Trillium. However, once integrated, files on HPSS will remain unchanged as it uses the same storage system."
  },
  {
    "question": "What is the SSH command to connect to the CPU sub-cluster on Trillium?",
    "answer": "To connect to the CPU sub-cluster via SSH, use `$ ssh USERNAME@trillium.alliancecan.ca`."
  },
  {
    "question": "What are the authentication requirements for SSH access to Trillium's CPU sub-cluster?",
    "answer": "You must have multi-factor authentication activated and use a registered SSH key for your account."
  },
  {
    "question": "What kind of tasks can the CPU login nodes (tri-login01-6) on Trillium process?",
    "answer": "These nodes do not have GPUs and can only process tasks on CPU nodes."
  },
  {
    "question": "How do I connect to the GPU sub-cluster on Trillium?",
    "answer": "To connect to the GPU sub-cluster, use the command `$ ssh USERNAME@trillium-gpu.alliancecan.ca`."
  },
  {
    "question": "What is the name of the GPU login node and what resources does it offer?",
    "answer": "The GPU login node is trig-login01, and it offers 4 NVIDIA H100 GPUs."
  },
  {
    "question": "What is the first recommended action upon your initial connection to Trillium?",
    "answer": "It is strongly recommended to run the command `$ trisetup` because your initialization files might not function correctly."
  },
  {
    "question": "What does the `trisetup` command do when run for the first time on Trillium?",
    "answer": "The `trisetup` command places .bashrc, .bash_profile, .chsrc, and .Xauthority files in your /home directory and creates .licenses, .local, .ssh, and links directories, while backing up original files with a timestamp."
  },
  {
    "question": "What is the current status of the SciNet OnDemand website regarding Trillium access?",
    "answer": "Currently, the SciNet OnDemand website remains connected to Niagara. It is planned to offer a way to connect to Trillium for web applications like Jupyper, with access to the Trillium filesystem."
  },
  {
    "question": "What are the core and memory specifications of a CPU compute node on Trillium?",
    "answer": "Each CPU compute node on Trillium has 192 cores and 755GB of memory."
  },
  {
    "question": "What type of CPUs are used in Trillium's CPU sub-cluster?",
    "answer": "Trillium's CPU sub-cluster uses AMD Zen 5 CPUs, also known as Turin."
  },
  {
    "question": "How many compute nodes and total cores are in Trillium's CPU sub-cluster?",
    "answer": "The CPU sub-cluster has 1224 compute nodes and a total of 235,008 cores."
  },
  {
    "question": "What is recommended for code that previously used Intel MKL for mathematical routines on Niagara?",
    "answer": "It is suggested to switch to Flexiblas or directly use AMD's AOCL libraries, which are available in the `aocl-blas` and `aocl-lapack` modules."
  },
  {
    "question": "What are the specifications of a GPU compute node on Trillium?",
    "answer": "Each GPU compute node on Trillium has 4 GPUs, 96 cores, and 755GB of available memory."
  },
  {
    "question": "What types of processors and GPUs are used in Trillium's GPU sub-cluster?",
    "answer": "The GPU sub-cluster uses AMD Zen 4 (Genoa) processors and NVIDIA H100 GPUs."
  },
  {
    "question": "How many GPU compute nodes and total GPUs are there in Trillium's GPU sub-cluster?",
    "answer": "There are 61 GPU compute nodes and a total of 244 GPUs."
  }
]