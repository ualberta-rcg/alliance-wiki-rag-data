[
  {
    "question": "What are the evaluation criteria used to rank different GPU models?",
    "answer": "The evaluation criteria are FP32 score (40% weight), FP16 score (40% weight), and GPU memory score (20% weight)."
  },
  {
    "question": "Which GPU model is used as the reference for assigning RGU values?",
    "answer": "The NVidia A100-40gb GPU is used as the reference model."
  },
  {
    "question": "What RGU value is assigned to the NVidia A100-40gb GPU?",
    "answer": "The NVidia A100-40gb GPU is assigned an RGU value of 4.0 for historical reasons."
  },
  {
    "question": "How are the FP16 performance, FP32 performance, and memory size of the A100-40gb defined for RGU calculations?",
    "answer": "Its FP16 performance, FP32 performance, and memory size are each defined as 1.0."
  },
  {
    "question": "What are the coefficients used for FP32, FP16, and Memory scores when calculating RGU values for other models?",
    "answer": "The coefficients are 1.6 for FP32 score, 1.6 for FP16 score, and 0.8 for Memory score."
  },
  {
    "question": "What is the combined RGU score for an H100-80gb GPU?",
    "answer": "The H100-80gb GPU has a combined RGU score of 12.2."
  },
  {
    "question": "What is the combined RGU score for an A100-80gb GPU?",
    "answer": "The A100-80gb GPU has a combined RGU score of 4.8."
  },
  {
    "question": "What is the combined RGU score for a V100-32gb GPU?",
    "answer": "The V100-32gb GPU has a combined RGU score of 2.6."
  },
  {
    "question": "What is the combined RGU score for a P100-12gb GPU?",
    "answer": "The P100-12gb GPU has a combined RGU score of 1.0."
  },
  {
    "question": "What new technology will allow scheduling a fraction of a GPU starting with the 2025 infrastructure renewal?",
    "answer": "Multi-Instance GPU (MIG) technology will allow scheduling a fraction of a GPU."
  },
  {
    "question": "What is a GPU instance, according to NVidia's terminology?",
    "answer": "A GPU instance, also sometimes called a MIG instance, is a fraction of a GPU allocated to a single job."
  },
  {
    "question": "What is the RGU value for an A100-1g.5gb GPU instance available for RAC 2026?",
    "answer": "An A100-1g.5gb GPU instance has an RGU value of 0.6."
  },
  {
    "question": "What is the RGU value for an H100-3g.40gb GPU instance available for RAC 2026?",
    "answer": "An H100-3g.40gb GPU instance has an RGU value of 6.1."
  },
  {
    "question": "Which GPU profiles are explicitly stated as not being available on the clusters?",
    "answer": "The 4g profiles are not available on the clusters to simplify things for users."
  },
  {
    "question": "How do A100-40gb and P100-12gb GPUs compare for FP32 operations in terms of speed and recorded usage?",
    "answer": "For FP32 operations, an A100-40gb GPU is expected to be twice as fast as a P100-12gb GPU, but its recorded usage will be 4 times the resources."
  },
  {
    "question": "How do A100-40gb and P100-12gb GPUs compare for FP16 operations in terms of calculation capability and resource evaluation?",
    "answer": "For FP16 operations, an A100-40gb will be evaluated as using 4x the resources of a P100-12gb but is capable of computing ~30x the calculations, allowing ~7.5x the computations for the same amount of time."
  },
  {
    "question": "What must a proposal requesting GPUs specify during the Resource Allocation Competition (RAC)?",
    "answer": "Any proposal asking for GPUs must specify the preferred GPU model for the project."
  },
  {
    "question": "How is the amount of Reference GPU Units (RGUs) calculated in the CCDB form during RAC?",
    "answer": "The amount of RGUs will automatically be calculated from the requested amount of gpu-years per year of project in the CCDB form."
  },
  {
    "question": "What happens if a GPU allocation must be moved to a different cluster?",
    "answer": "If an allocation must be moved to a different cluster, the committee will allocate gpu-years at that cluster so as to keep the amount of RGUs the same."
  },
  {
    "question": "What is the overarching principle for calculating job priority on national clusters?",
    "answer": "Compute-based jobs are considered in the calculation based on the resources that others are prevented from using, and not on the resources actually used."
  },
  {
    "question": "How does requesting more cores than an application uses affect job priority?",
    "answer": "If a submitted job requests multiple cores but uses fewer, the priority of future jobs will be affected by the number of cores requested, not the number actually used, because the unused cores were unavailable."
  },
  {
    "question": "How does requesting more memory than associated with the cores affect job priority?",
    "answer": "If a job requests memory beyond what is associated with the cores requested (e.g., 8GB for one core on a 4GB/core cluster), the job will be deemed to have used two cores, because other researchers were effectively prevented from using the second core."
  },
  {
    "question": "What constitutes a 'core equivalent'?",
    "answer": "A core equivalent is a bundle made up of a single core and some amount of associated memory, specifically a core plus the amount of memory considered to be associated with each core on a given system."
  },
  {
    "question": "What is the typical definition of a core-equivalent on most clusters?",
    "answer": "On most clusters, a core-equivalent is defined as a single core and 4GB of memory, which is the memory-to-core ratio in the most common node type."
  },
  {
    "question": "How are research groups charged for core-equivalent usage by the scheduler?",
    "answer": "Research groups are charged for the maximum number of core equivalents they take from the resources."
  }
]