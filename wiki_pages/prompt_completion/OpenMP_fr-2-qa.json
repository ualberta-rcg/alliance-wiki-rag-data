[
  {
    "question": "How does the 'static' scheduling mode work for OMP_SCHEDULE?",
    "answer": "In 'static' mode, the number of iterations is fixed, and they are distributed at the beginning of the parallel section."
  },
  {
    "question": "What is 'dynamic' scheduling mode in OMP_SCHEDULE?",
    "answer": "With 'dynamic' mode, the number of iterations is fixed, but they are distributed during execution based on the time each thread needs to complete its iterations."
  },
  {
    "question": "How does 'guided' scheduling work in OpenMP?",
    "answer": "In 'guided' mode, 'n' specifies the minimum number of iterations. The number of iterations initially chosen is large, then dynamically decreases as the remaining number of iterations diminishes."
  },
  {
    "question": "What happens in 'auto' scheduling mode for OMP_SCHEDULE?",
    "answer": "In 'auto' mode, the compiler and library are free to make their own choices regarding iteration distribution."
  },
  {
    "question": "What is an advantage of using 'dynamic', 'guided', or 'auto' scheduling modes?",
    "answer": "These modes theoretically allow for better load balancing among execution threads, as they adjust dynamically based on the time required by each thread."
  },
  {
    "question": "What is a disadvantage of 'dynamic', 'guided', or 'auto' scheduling modes?",
    "answer": "A disadvantage is that you do not know in advance which processor will execute which thread, or which memory it will access, making it impossible to predict memory/processor affinity, which can be problematic in a NUMA architecture."
  },
  {
    "question": "What is the purpose of the OMP_STACKSIZE environment variable?",
    "answer": "The OMP_STACKSIZE environment variable defines the stack size for each OpenMP thread created during execution, excluding the main OpenMP thread which gets its stack size from the shell."
  },
  {
    "question": "What is the default value for OMP_STACKSIZE if it is not defined?",
    "answer": "If OMP_STACKSIZE is not defined, its default value will be 4MB."
  },
  {
    "question": "What can happen if a program does not have enough memory for the stack?",
    "answer": "If a program does not have enough memory for the stack, it could terminate abnormally due to a segmentation fault."
  },
  {
    "question": "How can one identify environment variables specific to Intel compilers?",
    "answer": "Environment variables specific to Intel compilers typically begin with KMP_."
  },
  {
    "question": "How can one identify environment variables specific to GNU compilers?",
    "answer": "Environment variables specific to GNU compilers typically begin with GOMP_."
  },
  {
    "question": "Which environment variables should be set for optimal memory access performance in OpenMP programs?",
    "answer": "For optimal memory access performance, the variables OMP_PROC_BIND and affinity variables like KMP_AFFINITY for Intel and GOMP_CPU_AFFINITY for GNU should be set."
  },
  {
    "question": "Why is it important to fix OpenMP threads to specific processors for optimal performance?",
    "answer": "Fixing OpenMP threads to specific processors prevents them from moving between processors, which is particularly important in a NUMA (Non-Uniform Memory Access) architecture for optimal memory access."
  },
  {
    "question": "What is a simple C 'Hello World' example using OpenMP?",
    "answer": "A simple C 'Hello World' example uses '#include <stdio.h>', '#include <omp.h>', and '#pragma omp parallel' to print messages from multiple threads using 'omp_get_thread_num()' and 'omp_get_num_threads()'."
  },
  {
    "question": "How do you compile a C OpenMP program using GCC?",
    "answer": "You compile a C OpenMP program with GCC by using the command 'gcc -O3 -fopenmp ompHello.c -o ompHello'."
  },
  {
    "question": "How do you set the number of threads for an OpenMP program before execution?",
    "answer": "You can set the number of threads using the 'export OMP_NUM_THREADS=N' command, where N is the desired number of threads, before running the program."
  },
  {
    "question": "What is a simple Fortran 'Hello World' example using OpenMP?",
    "answer": "A simple Fortran 'Hello World' example uses '!$omp parallel' and '!$omp end parallel' directives to print messages from multiple threads using 'omp_get_thread_num()' and 'omp_get_num_threads()'."
  },
  {
    "question": "How do you compile a Fortran OpenMP program using GFortran?",
    "answer": "You compile a Fortran OpenMP program with GFortran by using the command 'gfortran -O3 -fopenmp ompHello.f90 -o fomphello'."
  },
  {
    "question": "Where can one find documentation and specifications for OpenMP?",
    "answer": "Documentation and specifications for OpenMP can be found at Lawrence Livermore National Laboratory and OpenMP.org, which provides specifications, C/C++ and Fortran cheat sheets, and examples."
  }
]