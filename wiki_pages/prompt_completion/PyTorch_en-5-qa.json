[
  {
    "question": "How is a PyTorch model typically prepared for distributed data parallelism on a GPU, according to the example?",
    "answer": "The model is first moved to CUDA (`net.cuda()`) and then wrapped with `torch.nn.parallel.DistributedDataParallel(net, device_ids=[current_device])`. The loss function (`criterion`) also needs to be moved to CUDA."
  },
  {
    "question": "Are there any known issues with PyTorch 1.10 when using DistributedDataParallel with multiple GPUs?",
    "answer": "Yes, there is a known issue with the PyTorch 1.10 wheel (`torch-1.10.0+computecanada`) where multi-GPU code using DistributedDataParallel may fail unpredictably if the backend is set to 'nccl' or 'gloo'."
  },
  {
    "question": "What is the recommended solution for the issues encountered with PyTorch 1.10 and DistributedDataParallel?",
    "answer": "It is recommended to use the latest PyTorch build instead of version 1.10 on all GP clusters."
  },
  {
    "question": "What is Data Parallelism in the context of training deep learning models with multiple GPUs?",
    "answer": "Data Parallelism refers to methods to perform training over multiple replicas of a model in parallel, where each replica receives a different chunk of training data at each iteration. Gradients are then aggregated, and parameters are updated synchronously or asynchronously."
  },
  {
    "question": "What is an important consideration for achieving equivalent training results when using Data Parallelism?",
    "answer": "To get a trained model that is equivalent to one trained without Data Parallelism, the user must scale either the learning rate or the desired batch size in function of the number of replicas."
  },
  {
    "question": "What is a prerequisite for a model to be suitable for Data Parallelism with multiple GPUs?",
    "answer": "The model must be small enough to fit inside the memory of a single GPU."
  },
  {
    "question": "What are the three main PyTorch methods for performing Data Parallelism mentioned in the document?",
    "answer": "The three main methods are using the DistributedDataParallel class, the PyTorch Lightning package, and the Horovod package."
  },
  {
    "question": "Which PyTorch class is recommended by PyTorch maintainers for using multiple GPUs, including those distributed across multiple nodes?",
    "answer": "The `DistributedDataParallel` class is recommended by PyTorch maintainers for using multiple GPUs, whether they are all on a single node, or distributed across multiple nodes."
  },
  {
    "question": "How many GPUs are requested in the example SLURM script for DistributedDataParallel (`pytorch-ddp-test.sh`)?",
    "answer": "The example SLURM script (`pytorch-ddp-test.sh`) requests 2 GPUs using `#SBATCH --gres=gpu:2`."
  },
  {
    "question": "How many tasks per node are requested in the example SLURM script for DistributedDataParallel (`pytorch-ddp-test.sh`)?",
    "answer": "The example SLURM script (`pytorch-ddp-test.sh`) requests 2 tasks per node using `#SBATCH --tasks-per-node=2`, indicating one process per GPU."
  }
]