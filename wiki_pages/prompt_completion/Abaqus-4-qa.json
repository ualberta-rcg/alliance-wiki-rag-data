[
  {
    "question": "How can I estimate the total SLURM node memory required for an Abaqus simulation?",
    "answer": "An estimate for the total SLURM node memory (`--mem=`) required for a simulation to run fully in RAM (without being virtualized to scratch disk) can be obtained by examining the Abaqus output `test.dat` file."
  },
  {
    "question": "What kind of memory estimates are provided in the Abaqus output .dat file for a single process simulation?",
    "answer": "The `MEMORY ESTIMATE` section in the Abaqus output `.dat` file provides 'FLOATING PT OPERATIONS PER ITERATION', 'MINIMUM MEMORY REQUIRED (MB)', and 'MEMORY TO MINIMIZE I/O (MB)' for a process."
  },
  {
    "question": "What is an alternative way to estimate memory for a single-node threaded Abaqus process?",
    "answer": "The total memory estimate for a single node threaded process can also be obtained by running the simulation interactively on a compute node and monitoring memory consumption using the `ps` or `top` commands."
  },
  {
    "question": "What are the steps to interactively monitor Abaqus memory consumption on a compute node?",
    "answer": "1) SSH into a cluster, obtain an allocation on a compute node using `salloc`, load `StdEnv/2020` and `abaqus/2021` modules, then start your simulation interactively. 2) SSH into the cluster again, then into the reserved compute node and run `top -u $USER`. 3) Watch the VIRT and RES columns until steady peak memory values are observed."
  },
  {
    "question": "What is the 'MEMORY TO OPERATIONS REQUIRED MINIMIZE I/O' (MRMIO) and how does it relate to Abaqus memory usage?",
    "answer": "MRMIO is a recommended value for memory usage. To completely satisfy it, at least the same amount of non-swapped physical memory (RES) must be available to Abaqus. If the memory upper limit is greater than MRMIO, actual memory usage will be close to MRMIO, and scratch disk usage will be near zero."
  },
  {
    "question": "Why is it necessary to over-allocate the requested Slurm node memory (`--mem=`) for Abaqus simulations?",
    "answer": "It is necessary to slightly over-allocate the requested Slurm node memory because the Resident Set Size (RES) will generally be less than the Virtual Memory (VIRT) by a relatively constant amount for a given simulation."
  },
  {
    "question": "What is the hardcoded memory over-allocation in the sample Slurm scripts?",
    "answer": "The hardcoded memory over-allocation in the sample Slurm scripts is a conservative value of 3072MB."
  },
  {
    "question": "What happens if the RES memory available to Abaqus falls below the MINIMUM MEMORY REQUIRED (MMR)?",
    "answer": "If the RES memory dips below the MINIMUM MEMORY REQUIRED (MMR), Abaqus will exit due to an Out of Memory (OOM) error."
  },
  {
    "question": "How can I test the performance impact of reducing RES memory below MRMIO to avoid long queue wait times?",
    "answer": "You can investigate this by lowering the `#SBATCH --mem=` value in your Slurm script, which will set an artificially low `memory=` value in the Abaqus command. Try running a series of short test jobs with different `--mem=` values (e.g., 8G, 16G, 32G, 64G)."
  },
  {
    "question": "How do you determine the required Slurm memory (`mem-per-cpu`) for multi-node Abaqus scripts?",
    "answer": "Memory estimates (per compute process) required to minimize I/O are found in the output `.dat` file of completed jobs. If `mp_host_split` is not specified or is 1, `mem-per-cpu` is roughly calculated by multiplying the largest memory estimate by the number of nodes and dividing by `ntasks`."
  },
  {
    "question": "How does `mp_host_split` influence the `mem-per-cpu` calculation for multi-node Abaqus jobs?",
    "answer": "If `mp_host_split` is specified and greater than 1, the `mem-per-cpu` value is roughly determined from the largest memory estimate multiplied by the number of nodes, multiplied by the `mp_host_split` value, and then divided by the number of tasks (`ntasks`)."
  },
  {
    "question": "What condition must `mp_host_split` satisfy to prevent Abaqus termination in multi-node jobs?",
    "answer": "`mp_host_split` must be less than or equal to the number of cores per node assigned by Slurm at runtime; otherwise, Abaqus will terminate."
  }
]