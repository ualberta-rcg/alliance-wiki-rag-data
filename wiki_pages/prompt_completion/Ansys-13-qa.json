[
  {
    "question": "How can DPM coupled calculations be enabled in Ansys Fluent via a journal file?",
    "answer": "You can enable DPM coupled calculations by adding the command `/define/models/dpm/interaction/coupled-calculations yes` to your journal file."
  },
  {
    "question": "How do you delete an existing DPM injection named 'injection-0:1' using a journal command?",
    "answer": "To delete an injection, use the command `/define/models/dpm/injections/delete-injection injection-0:1` in your journal file."
  },
  {
    "question": "How do you create a DPM injection named 'injection-0:1' from a file named 'zinjection01.inj' using a journal command?",
    "answer": "The command `/define/models/dpm/injections/create injection-0:1 no yes file no zinjection01.inj no no no no` can be used to create the injection from the specified file."
  },
  {
    "question": "How can you list the particles for a DPM injection 'injection-0:1' in Ansys Fluent?",
    "answer": "Use the journal command `/define/models/dpm/injections/list-particles injection-0:1`."
  },
  {
    "question": "How do you list the properties for a DPM injection 'injection-0:1' in Ansys Fluent?",
    "answer": "The command `/define/models/dpm/injections/list-injection-properties injection-0:1` can be added to your journal file."
  },
  {
    "question": "What is the typical format for a basic manually created steady DPM injection file?",
    "answer": "A basic steady injection file `zinjection01.inj` includes coordinate ranges (e.g., `(z=4 12)`) followed by a header and then particle properties in a specific format, for example: `( x y z u v w diameter t mass-flow mass frequency time name ) (( 2.90e-02 5.00e-03 0.0 -1.00e-03 0.0 0.0 1.00e-04 2.93e+02 1.00e-06 0.0 0.0 0.0 ) injection-0:1 )`."
  },
  {
    "question": "Where can one find detailed information on the steady file format for DPM injections?",
    "answer": "Detailed information is described in `Part III: Solution Mode | Chapter 24: Modeling Discrete Phase | 24.3. Setting Initial Conditions for the Discrete Phase | 24.3.13 Point Properties for File Injections | 24.3.13.1 Steady File Format` of the `2024R2 Fluent Customization Manual`."
  },
  {
    "question": "How can you view a summary of command-line options for Ansys CFX-Solver?",
    "answer": "You can print a summary of command-line options by running `cfx5solve -help` after loading the appropriate Ansys CFX module."
  },
  {
    "question": "What is the default precision for cfx5solve and how can it be changed to double precision?",
    "answer": "By default, `cfx5solve` runs in single precision. To run in double precision, you need to add the `-double` option to the command line."
  },
  {
    "question": "What are the default mesh element limits for cfx5solve and how can they be extended for larger meshes?",
    "answer": "By default, `cfx5solve` supports meshes up to 80 million structured elements or 200 million unstructured elements. For larger meshes, up to 2 billion elements, you can add the `-large` option."
  },
  {
    "question": "What are the typical maximum core limits per node for Ansys CFX single node jobs on Graham, Cedar, Beluga, and Narval clusters?",
    "answer": "The maximum cores per node are typically Graham 44, Cedar 32 or 48, Beluga 40, and Narval 64."
  },
  {
    "question": "Which MPI implementation is typically used for Ansys CFX single-node parallel jobs on Narval?",
    "answer": "On Narval, the `Open MPI Local Parallel` method is used for single-node jobs."
  },
  {
    "question": "Which MPI implementation is typically used for Ansys CFX single-node parallel jobs on clusters other than Narval?",
    "answer": "On clusters other than Narval, the `Intel MPI Local Parallel` method is typically used for single-node jobs."
  },
  {
    "question": "How does a multinode Ansys CFX job specify the number of compute nodes for parallel execution?",
    "answer": "In the Slurm script, the `#SBATCH --nodes` directive is used to specify the number of compute nodes (e.g., `#SBATCH --nodes=2` for two or more nodes)."
  },
  {
    "question": "Which MPI implementation is typically used for Ansys CFX multinode parallel jobs on Narval?",
    "answer": "On Narval, the `Open MPI Distributed Parallel` method is used for multinode jobs."
  },
  {
    "question": "Which MPI implementation is typically used for Ansys CFX multinode parallel jobs on clusters other than Narval?",
    "answer": "On clusters other than Narval, the `Intel MPI Distributed Parallel` method is used for multinode jobs, and `export I_MPI_HYDRA_BOOTSTRAP=ssh` is also set."
  },
  {
    "question": "What Slurm setting allocates all memory per compute node for an Ansys CFX multinode job?",
    "answer": "The setting `#SBATCH --mem=0` allocates all memory per compute node."
  },
  {
    "question": "What is the recommended module load for Ansys CFX version 2023R2 on StdEnv/2023?",
    "answer": "The recommended module load is `module load StdEnv/2023 ansys/2023R2`."
  }
]