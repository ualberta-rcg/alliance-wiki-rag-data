[
  {
    "question": "How are arguments accessed within an R script?",
    "answer": "Arguments are accessed using `args = commandArgs(trailingOnly=TRUE)`."
  },
  {
    "question": "How do you read the first argument as a string in an R script?",
    "answer": "Use `name <- args[1]` to read the first argument as a string."
  },
  {
    "question": "How do you read the second argument as an integer in an R script?",
    "answer": "Use `number <- as.integer( args[2] )` to read the second argument as an integer."
  },
  {
    "question": "What happens if an R script expecting two arguments receives fewer?",
    "answer": "The script will return an error message, for example: \"At least two arguments must be supplied ('name' (text) and 'numer' (integer) )\"."
  },
  {
    "question": "How can you execute an R script named `arguments_test.R` with arguments 'Hello' and '42'?",
    "answer": "Run `Rscript arguments_test.R Hello 42`."
  },
  {
    "question": "What is the expected output when running `Rscript arguments_test.R Hello 42`?",
    "answer": "The expected output is `[1] \"Processing with name:'Hello' and number:'42'\"`."
  },
  {
    "question": "What makes supercomputers beneficial for R code?",
    "answer": "Supercomputers provide access to thousands of CPU cores with a high-performance network, which is beneficial for running R code in parallel."
  },
  {
    "question": "What should be done before parallelizing R code for efficiency?",
    "answer": "Before parallelizing R code, ensure that its serial implementation is as efficient as possible."
  },
  {
    "question": "What is a significant performance bottleneck in R, especially for interpreted languages?",
    "answer": "The use of loops, particularly nested loops, constitutes a significant performance bottleneck in R."
  },
  {
    "question": "How can R code performance be improved without parallelization?",
    "answer": "Performance can be improved by using vectorized forms of R functions and more functional elements like the `apply` family of functions and `ifelse`."
  },
  {
    "question": "Where can one find information on R packages for parallel computing?",
    "answer": "The CRAN Task View on High-Performance and Parallel Computing with R describes a collection of interrelated R packages for parallel computing."
  },
  {
    "question": "In the context of most documentation, what does the term 'node' refer to?",
    "answer": "In most documentation, 'node' refers to an individual machine, also called a 'host'."
  },
  {
    "question": "In the context of R documentation (e.g., `snow` package), what does the term 'node' refer to?",
    "answer": "In R documentation, 'node' often refers to a worker process."
  },
  {
    "question": "What is `foreach` considered in R parallel computing?",
    "answer": "`foreach` is considered a unified interface for various backends like `doMC`, `doMPI`, `doParallel`, and `doRedis`."
  },
  {
    "question": "What is the function of `doParallel`?",
    "answer": "`doParallel` acts as an interface between `foreach` and the `parallel` package."
  },
  {
    "question": "Are there any known efficiency issues with `foreach`?",
    "answer": "Yes, there are known efficiency issues when using `foreach` to run a very large number of very small tasks."
  },
  {
    "question": "What must be done to enable parallel execution with `foreach`?",
    "answer": "The backend must be registered by feeding it the number of available cores."
  },
  {
    "question": "What happens if the `foreach` backend is not registered?",
    "answer": "`foreach` will assume the number of cores is 1 and execute iterations serially."
  },
  {
    "question": "What are the general steps to use `foreach` for parallel processing?",
    "answer": "The general method involves loading both `foreach` and the backend package, registering the backend, and calling `foreach()` on the same line as the `%do%` (serial) or `%dopar%` operator."
  },
  {
    "question": "How is the number of cores determined in the `test_foreach.R` script example for SLURM systems?",
    "answer": "The number of cores is determined by the `SLURM_CPUS_PER_TASK` environment variable using `ncores = Sys.getenv(\"SLURM_CPUS_PER_TASK\")`."
  },
  {
    "question": "How do you register the `doParallel` backend with a specific number of cores?",
    "answer": "You register it using `registerDoParallel(cores=ncores)`, where `ncores` is the desired number of cores."
  },
  {
    "question": "What is a crucial syntax requirement for `foreach()` and `%dopar%`?",
    "answer": "`foreach()` and `%dopar%` must be on the same line in the script."
  },
  {
    "question": "What SBATCH directive specifies that only one node should be used for a job?",
    "answer": "The `#SBATCH --nodes=1` directive specifies that the number of nodes must be 1."
  },
  {
    "question": "How is an R script executed non-interactively using `R CMD BATCH` in `job_foreach.sh`?",
    "answer": "It is executed using `R CMD BATCH --no-save --no-restore test_foreach.R`."
  },
  {
    "question": "How do you submit a job script named `job_foreach.sh`?",
    "answer": "You submit it using the command `sbatch job_foreach.sh`."
  },
  {
    "question": "When using `doParallel` and `makeCluster` with a `PSOCK` cluster type, how are commands run?",
    "answer": "Commands are run through SSH connections into the nodes when using a `PSOCK` cluster type."
  },
  {
    "question": "How is the `NODESLIST` environment variable typically populated in a `makeCluster` job script?",
    "answer": "It is populated by running `export NODESLIST=$(echo $(srun hostname | cut -f 1 -d '.'))` to get the node names."
  },
  {
    "question": "What R function is used to create a cluster for `doParallel` with `makeCluster`?",
    "answer": "The `makeCluster(nodeslist, type = \"PSOCK\")` function is used, where `nodeslist` contains the names of the nodes."
  },
  {
    "question": "How do you ensure resources are released after using `makeCluster` for parallel computations?",
    "answer": "You must call `stopCluster(cl)` to release the resources."
  },
  {
    "question": "How can you explicitly request that processes be placed on different nodes when using `makeCluster` with SLURM?",
    "answer": "Add the SBATCH directive `#SBATCH --ntasks-per-node=2` to the job script (assuming 2 tasks per node are desired)."
  }
]