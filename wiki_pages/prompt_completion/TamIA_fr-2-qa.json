[
  {
    "question": "What is the purpose of the PROJECT storage space on tamIA?",
    "answer": "The PROJECT space is designed for data sharing among group members and for storing large amounts of data."
  },
  {
    "question": "Are quotas for the PROJECT storage space fixed or adjustable?",
    "answer": "The PROJECT storage space has large quotas that are adjustable per project."
  },
  {
    "question": "How often is the PROJECT storage space backed up?",
    "answer": "There is an automatic backup once per day for the PROJECT storage space."
  },
  {
    "question": "Which address should be used for data transfers via Globus?",
    "answer": "For data transfers by Globus, you should use the 'Point de chute Globus' (Globus Drop-off Point)."
  },
  {
    "question": "What address should be used for data transfers using tools like rsync and scp?",
    "answer": "For tools like rsync and scp, you should use the 'N\u0153ud de copie' (Copy Node) address."
  },
  {
    "question": "What type of high-performance network connects all nodes in the tamIA cluster?",
    "answer": "All nodes in the tamIA cluster are connected by an InfiniBand NDR network from Nvidia."
  },
  {
    "question": "How are the H100 GPUs connected to the InfiniBand network?",
    "answer": "Each H100 GPU is connected to a NDR200 port via a Nvidia ConnectX-7 card."
  },
  {
    "question": "How many NDR200 ports per server are connected to the InfiniBand fabric?",
    "answer": "Each server has 4 NDR200 ports connected to the InfiniBand fabric."
  },
  {
    "question": "What is the topology of the InfiniBand network?",
    "answer": "The InfiniBand network is non-blocking for compute servers and is composed of 2 stages of switches arranged in a 'fat-tree' topology."
  },
  {
    "question": "How are the storage and management nodes connected to the InfiniBand network?",
    "answer": "The storage and management nodes are connected via 4 connections at 400Gb/s to the core of the network."
  },
  {
    "question": "What are the specifications of the 42 compute nodes in terms of CPU, memory, storage, and GPU?",
    "answer": "The 42 compute nodes each have 48 cores, 512GB of available memory, 2 x Intel Xeon Gold 6442Y 2.6 GHz (24C) CPUs, 1 x 7.68TB SSD storage, and 4 x NVIDIA HGX H100 SXM 80GB HBM3 700W GPUs connected via NVLink."
  },
  {
    "question": "What are the specifications of the 4 non-GPU nodes in terms of CPU, memory, and storage?",
    "answer": "The 4 non-GPU nodes each have 64 cores, 512GB of available memory, 2 x Intel Xeon Gold 6438M 2.2G (32C/64T) CPUs, and 1 x 7.68TB SSD storage."
  },
  {
    "question": "Do all nodes in the tamIA cluster have GPUs?",
    "answer": "No, 4 nodes have no GPUs, while 42 nodes each have 4 NVIDIA HGX H100 GPUs."
  },
  {
    "question": "What is the default software environment on tamIA?",
    "answer": "The default software environment on tamIA is 'StdEnv/2023'."
  },
  {
    "question": "Where can users monitor their computing tasks on tamIA?",
    "answer": "Users can monitor their computing tasks (GPU and CPU) in real-time or past tasks via the tamIA portal (https://portail.tamia.ecpia.ca/)."
  },
  {
    "question": "What metrics can be visualized for a task on the tamIA portal?",
    "answer": "For a task, users can visualize the utilization of computing cores, used memory, and GPU usage."
  },
  {
    "question": "Why is it important to adjust resource requests for tasks?",
    "answer": "It is important to adjust resource requests to maximize resource utilization and reduce waiting times, especially if allocated resources are underutilized (e.g., asking for four CPU cores but only using one)."
  }
]