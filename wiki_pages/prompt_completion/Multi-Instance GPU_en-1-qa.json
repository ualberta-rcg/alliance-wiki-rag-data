[
  {
    "question": "What problem does Multi-Instance GPU (MIG) technology aim to solve?",
    "answer": "Many programs are unable to fully use modern GPUs such as NVidia A100s and H100s."
  },
  {
    "question": "What is Multi-Instance GPU (MIG) technology?",
    "answer": "Multi-Instance GPU (MIG) is a technology that allows partitioning a single GPU into multiple instances, making each one a completely independent virtual GPU."
  },
  {
    "question": "How do GPU instances manage their resources and memory from other instances?",
    "answer": "Each of the GPU instances gets a portion of the original GPU's computational resources and memory, all detached from the other instances by on-chip protections."
  },
  {
    "question": "What are the benefits of using GPU instances regarding resource allocation and job execution?",
    "answer": "Using GPU instances is less wasteful, usage is billed accordingly, jobs use less of your allocated priority, allowing you to execute more jobs and have shorter wait times."
  },
  {
    "question": "Under what conditions should a job be considered for running on a GPU instance?",
    "answer": "Jobs that use less than half of the computing power of a full GPU and less than half of the available memory should be evaluated and tested on an instance."
  },
  {
    "question": "Does MIG technology support CUDA Inter-Process Communication (IPC)?",
    "answer": "No, the MIG technology does not support CUDA Inter-Process Communication (IPC)."
  },
  {
    "question": "What is the implication of MIG not supporting CUDA Inter-Process Communication (IPC)?",
    "answer": "This limitation reduces communication efficiency between instances, and consequently, launching an executable on more than one instance at a time does not improve performance and should be avoided."
  },
  {
    "question": "Are graphic APIs like OpenGL and Vulkan supported by MIG technology?",
    "answer": "No, graphic APIs are not supported (for example, OpenGL, Vulkan, etc.)."
  },
  {
    "question": "What factors influence the maximum number of CPU cores that can be assigned to a GPU instance?",
    "answer": "The maximum number of CPU cores per instance depends on the number of cores per full GPU and on the configured MIG profiles, both of which vary between clusters and GPU nodes."
  },
  {
    "question": "Which NVIDIA GPUs are supported for MIG instances on the Narval and Rorqual clusters?",
    "answer": "Narval supports NVIDIA A100-40gb GPUs, and Rorqual supports NVIDIA H100-80gb GPUs."
  },
  {
    "question": "How does the profile name of a MIG instance describe its characteristics?",
    "answer": "The profile name describes the size of the instance, for example, a `3g.20gb` instance has 20 GB of GPU memory and offers 3/8th of the computing performance of a full GPU."
  },
  {
    "question": "How can you list all available MIG flavors and full GPU names on a cluster?",
    "answer": "One can run the command `sinfo -o \"%G\"|grep gpu|sed 's/gpu://g'|sed 's/,/\n/g'|cut -d: -f1|sort|uniq` to list all the flavours of MIGs (plus the full size GPU names) available on a given cluster."
  },
  {
    "question": "Where can users find the recommended maximum number of CPU cores and system memory for an instance?",
    "answer": "The recommended maximum number of CPU cores and amount of system memory per instance are listed in the table of ratios in bundles."
  },
  {
    "question": "What command requests an A100 3g.20gb GPU instance with 2 CPU cores and 40GB memory for a 1-hour interactive job?",
    "answer": "The command is `salloc --account=def-someuser --gpus=a100_3g.20gb:1 --cpus-per-task=2 --mem=40gb --time=1:0:0`."
  },
  {
    "question": "What metrics are good indicators for determining if a job should use a GPU instance?",
    "answer": "Power consumption, GPU functionality utilization, maximum GPU memory, and the average number of CPU cores required are good indicators."
  },
  {
    "question": "Based on the example, what power consumption pattern would suggest a job is suitable for a GPU instance?",
    "answer": "If a job requested a full A100 GPU with a maximum TDP of 400W but only used 100W on average, which is only 50W more than the idle electric consumption, it suggests suitability for an instance."
  },
  {
    "question": "How can you monitor a running job's GPU metrics in real-time?",
    "answer": "You can monitor the usage of a running job by attaching to the node where the job is currently running and then by using `nvidia-smi` to read the GPU metrics in real time."
  },
  {
    "question": "Is it supported to use multiple MIG instances on the same physical GPU?",
    "answer": "No, while possible in principle, the document states that this is not supported."
  },
  {
    "question": "What is the recommended alternative if you want to run multiple independent tasks on a GPU instead of multiple MIG instances on the same GPU?",
    "answer": "If you want to run multiple independent tasks on a GPU, you should use MPS rather than MIG."
  }
]