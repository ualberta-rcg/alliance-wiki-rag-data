[
  {
    "question": "What is the purpose of the `pytorch-ddp-test-pl.sh` script?",
    "answer": "It is a SLURM batch script example for running a PyTorch Lightning application with multi-GPU data parallelism."
  },
  {
    "question": "How many GPUs are requested in the `pytorch-ddp-test-pl.sh` script?",
    "answer": "The script requests 2 GPUs using `#SBATCH --gres=gpu:2`."
  },
  {
    "question": "How many tasks per node are requested in the `pytorch-ddp-test-pl.sh` script?",
    "answer": "The script requests 2 tasks per node using `#SBATCH --tasks-per-node=2`, which means 1 process per GPU."
  },
  {
    "question": "What Python packages are installed in the virtual environment for the PyTorch Lightning multi-GPU example?",
    "answer": "`torchvision` and `pytorch-lightning` are installed."
  },
  {
    "question": "What environment variable is exported in `pytorch-ddp-test-pl.sh` to handle NCCL asynchronously?",
    "answer": "The `TORCH_NCCL_ASYNC_HANDLING=1` environment variable is exported."
  },
  {
    "question": "What does PyTorch Lightning expect regarding task allocation when running inside a SLURM batch job for multi-GPU training?",
    "answer": "PyTorch Lightning expects the user to have requested one task per GPU."
  },
  {
    "question": "How is the `pl.Trainer` initialized for multi-GPU data parallelism in `pytorch-ddp-test-pl.py`?",
    "answer": "It is initialized with `accelerator=\"gpu\"`, `devices=2`, `num_nodes=1`, `strategy='ddp'`, `max_epochs`, and `enable_progress_bar=False`."
  },
  {
    "question": "Why is `enable_progress_bar=False` set in the `pl.Trainer` initialization for PyTorch Lightning scripts?",
    "answer": "It is set to avoid writing a progress bar to the logs, which can cause issues due to updating logs too frequently."
  },
  {
    "question": "When is it generally not recommended to use a GPU for model training?",
    "answer": "It is not advisable when a model is fairly small, does not take up a large portion of GPU memory, and cannot use a reasonable amount of its compute capacity."
  },
  {
    "question": "Under what conditions can Data Parallelism on a single GPU be a viable option for a small model?",
    "answer": "It can be a viable option if you have a very large dataset and wish to perform training with a small batch size, allowing multiple model replicas to be fit on a single GPU."
  },
  {
    "question": "What Nvidia service is used with MPI for single GPU data parallelism to place multiple model replicas?",
    "answer": "Nvidia's Multi-Process Service (MPS) is used."
  },
  {
    "question": "How is Nvidia MPS activated in the `pytorch-gpu-mps.sh` script?",
    "answer": "It is activated by exporting `CUDA_MPS_PIPE_DIRECTORY` and `CUDA_MPS_LOG_DIRECTORY`, then running `nvidia-cuda-mps-control -d`."
  },
  {
    "question": "Which backend for `dist.init_process_group` should be used for single GPU data parallelism, and why is NCCL not suitable?",
    "answer": "The `backend=\"mpi\"` or \"gloo\" should be used. NCCL does not work on a single GPU due to a hard-coded multi-GPU topology check."
  },
  {
    "question": "How is the model wrapped for data parallelism in the `cifar10-gpu-mps.py` script?",
    "answer": "The model is wrapped with `torch.nn.parallel.DistributedDataParallel(net, device_ids=[current_device])`."
  }
]