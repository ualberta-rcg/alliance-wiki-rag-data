[
  {
    "question": "What Python package simplifies common PyTorch tasks, including multi-GPU training?",
    "answer": "PyTorch Lightning is a Python package that provides interfaces to PyTorch to make many common, but otherwise code-heavy tasks, more straightforward, including training on multiple GPUs."
  },
  {
    "question": "How many GPUs are requested in the `pytorch-ddp-test-pl.sh` script for PyTorch Lightning distributed training?",
    "answer": "The `pytorch-ddp-test-pl.sh` script requests 2 GPUs using `#SBATCH --gres=gpu:2`."
  },
  {
    "question": "What is the recommended SLURM task configuration when using PyTorch Lightning with GPUs in a batch job?",
    "answer": "PyTorch Lightning expects the user to have requested one task per GPU when running inside a SLURM batch job. If this is not done, and the script is not run with `srun`, the job will fail."
  },
  {
    "question": "What environment variable is exported in `pytorch-ddp-test-pl.sh` to handle asynchronous NCCL operations?",
    "answer": "The environment variable `TORCH_NCCL_ASYNC_HANDLING=1` is exported in `pytorch-ddp-test-pl.sh`."
  },
  {
    "question": "How is the PyTorch Lightning `Trainer` configured for multi-GPU training in `pytorch-ddp-test-pl.py`?",
    "answer": "The `Trainer` is initialized with `pl.Trainer(accelerator=\"gpu\", devices=2, num_nodes=1, strategy='ddp', max_epochs = args.max_epochs, enable_progress_bar=False)`."
  },
  {
    "question": "What is the purpose of setting `enable_progress_bar=False` in the PyTorch Lightning `Trainer`?",
    "answer": "Setting `enable_progress_bar=False` is done to avoid writing a progress bar to the logs, which can cause issues due to updating logs too frequently."
  },
  {
    "question": "What is the default `batch_size` argument passed to the `pytorch-ddp-test-pl.py` script in the example?",
    "answer": "The `srun` command in `pytorch-ddp-test-pl.sh` passes `--batch_size 256` to the Python script."
  },
  {
    "question": "What is the maximum number of training epochs configured in the `pytorch-ddp-test-pl.py` script?",
    "answer": "The `max_epochs` argument defaults to 4 in the `pytorch-ddp-test-pl.py` script."
  },
  {
    "question": "Which dataset is used for training in the `pytorch-ddp-test-pl.py` example?",
    "answer": "The CIFAR10 dataset is used for training in the `pytorch-ddp-test-pl.py` example."
  },
  {
    "question": "What optimizer is configured for the `Net` model in `pytorch-ddp-test-pl.py`?",
    "answer": "The `Net` model in `pytorch-ddp-test-pl.py` uses `torch.optim.Adam` as its optimizer."
  },
  {
    "question": "What specific PyTorch Lightning method is implemented in the `Net` class for the training loop in `pytorch-ddp-test-pl.py`?",
    "answer": "The `training_step` method is implemented in the `Net` class for the training loop."
  },
  {
    "question": "When is it generally not recommended to use a GPU for model training?",
    "answer": "It is not advisable to use a GPU when a model is fairly small, such that it does not take up a large portion of GPU memory and cannot use a reasonable amount of its compute capacity."
  },
  {
    "question": "Under what conditions can Data Parallelism on a single GPU be a viable strategy for small models with large datasets?",
    "answer": "Data Parallelism on a single GPU becomes a viable option for small models if you have a very large dataset and wish to perform training with a small batch size, allowing multiple model replicas to be fit on a single GPU to increase resource usage and gain speed-up."
  },
  {
    "question": "What two Nvidia/MPI technologies are used to place multiple model replicas on one GPU for single GPU Data Parallelism?",
    "answer": "Nvidia's Multi-Process Service (MPS) and MPI are used to efficiently place multiple model replicas on one GPU for single GPU Data Parallelism."
  },
  {
    "question": "How is Nvidia's Multi-Process Service (MPS) activated in the `pytorch-gpu-mps.sh` script?",
    "answer": "Nvidia MPS is activated by exporting `CUDA_MPS_PIPE_DIRECTORY` and `CUDA_MPS_LOG_DIRECTORY` environment variables, then running `nvidia-cuda-mps-control -d`."
  },
  {
    "question": "What SLURM parameter in `pytorch-gpu-mps.sh` determines the number of model replicas to be placed on the GPU?",
    "answer": "The `tasks-per-node` SLURM parameter (`#SBATCH --tasks-per-node=8`) determines the number of model replicas to be placed on the GPU."
  },
  {
    "question": "What is the requested GPU count for the `pytorch-gpu-mps.sh` SLURM job?",
    "answer": "The `pytorch-gpu-mps.sh` SLURM job requests 1 GPU using `#SBATCH --gres=gpu:1`."
  },
  {
    "question": "Which backend is used for `dist.init_process_group` in `cifar10-gpu-mps.py` and why is NCCL not used?",
    "answer": "The `backend=\"mpi\"` (or `\"gloo\"`) is used for `dist.init_process_group` in `cifar10-gpu-mps.py` because NCCL does not work on a single GPU due to a hard-coded multi-GPU topology check."
  },
  {
    "question": "What is the default `batch_size` argument used when running `cifar10-gpu-mps.py` in the example script?",
    "answer": "The `srun` command in `pytorch-gpu-mps.sh` passes `--batch_size=512` to the `cifar10-gpu-mps.py` script."
  },
  {
    "question": "How is the current CUDA device set in `cifar10-gpu-mps.py` for single GPU parallelism?",
    "answer": "`torch.cuda.set_device(current_device)` is called, where `current_device` is initialized to 0."
  }
]