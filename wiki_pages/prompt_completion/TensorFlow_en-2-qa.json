[
  {
    "question": "What high-level API does TensorFlow offer for using multiple GPUs?",
    "answer": "TensorFlow offers the high-level API `tf.distribute` to make use of multiple GPUs."
  },
  {
    "question": "Where can users find more detailed information about TensorFlow's multi-GPU strategies?",
    "answer": "For more details, users should refer to the official TensorFlow documentation on `tf.distribute`."
  },
  {
    "question": "How is the Mirrored strategy implemented for multi-GPU training on a single node in TensorFlow?",
    "answer": "The Mirrored strategy for a single node is implemented using `tf.distribute.MirroredStrategy()` within a `strategy.scope()` in the Python script."
  },
  {
    "question": "What is the purpose of the `NCCL_BLOCKING_WAIT` environment variable in a single-node Mirrored strategy SLURM script?",
    "answer": "Setting `export NCCL_BLOCKING_WAIT=1` is done if you wish to use the NCCL backend for inter-GPU communication."
  },
  {
    "question": "What SLURM resource requests are included in the `tensorflow-singleworker.sh` script for a single-node Mirrored strategy?",
    "answer": "The `tensorflow-singleworker.sh` script requests 1 node (`#SBATCH --nodes 1`), 4 GPUs (`#SBATCH --gres=gpu:4`), 8GB of memory (`#SBATCH --mem=8G`), and a time limit of 30 minutes (`#SBATCH --time=0-00:30`)."
  },
  {
    "question": "How is TensorFlow installed within the `tensorflow-singleworker.sh` SLURM script?",
    "answer": "TensorFlow is installed in a virtual environment created in `$SLURM_TMPDIR/env` using `pip install --no-index tensorflow` after loading the `python/3` module and activating the virtual environment."
  },
  {
    "question": "What type of Keras model is defined in the `tensorflow-singleworker.py` script?",
    "answer": "The `tensorflow-singleworker.py` script defines a `tf.keras.Sequential()` model for CIFAR10 classification, consisting of convolutional, activation, MaxPooling, Dropout, Flatten, and Dense layers."
  },
  {
    "question": "How does the `tensorflow-singleworker.py` script handle the CIFAR10 dataset?",
    "answer": "The script attempts to download the CIFAR10 dataset from the internet if it's not already stored in `~/.keras/datasets`, or it can be manually downloaded and placed there. It then uses `tf.data.Dataset.from_tensor_slices` to create a batched dataset."
  },
  {
    "question": "What is the main difference in syntax when using the Mirrored strategy across multiple nodes compared to a single node?",
    "answer": "The most notable difference is the use of `MultiWorkerMirroredStrategy()` for multiple nodes instead of `MirroredStrategy()`."
  },
  {
    "question": "How does TensorFlow obtain necessary job information from SLURM for a multi-node Mirrored strategy?",
    "answer": "TensorFlow uses `SlurmClusterResolver()` to acquire all the necessary job information from SLURM, avoiding manual assignment of master and worker nodes."
  },
  {
    "question": "How is Nvidia's NCCL backend explicitly specified for inter-GPU communications in a multi-node Mirrored strategy?",
    "answer": "`CommunicationImplementation.NCCL` must be explicitly added to the distribution strategy using `tf.distribute.experimental.CommunicationOptions(implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)`."
  },
  {
    "question": "Why is explicit specification of `CommunicationImplementation.NCCL` necessary for multi-node but not single-node Mirrored strategy?",
    "answer": "NCCL is the default backend with `MirroredStrategy()` (single-node), but it needs to be explicitly specified for `MultiWorkerMirroredStrategy()` (multi-node)."
  },
  {
    "question": "What SLURM resource requests are made in the `tensorflow-multiworker.sh` script for a multi-node Mirrored strategy?",
    "answer": "The script requests 2 nodes (`#SBATCH --nodes 2`), 2 GPUs per node (`#SBATCH --gres=gpu:2`), 2 tasks per node (`#SBATCH --ntasks-per-node=2`), 8GB of memory (`#SBATCH --mem=8G`), and a time limit of 30 minutes (`#SBATCH --time=0-00:30`)."
  },
  {
    "question": "What environment variables are set in the `tensorflow-multiworker.sh` script for multi-node GPU training?",
    "answer": "The `tensorflow-multiworker.sh` script sets `export NCCL_BLOCKING_WAIT=1` for the NCCL backend and `export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CUDA_HOME`."
  },
  {
    "question": "What is the role of the `config_env.sh` script in the multi-node TensorFlow setup?",
    "answer": "The `config_env.sh` script is responsible for loading the python module, creating a virtual environment in `$SLURM_TMPDIR/ENV`, upgrading pip, and installing tensorflow using `pip install --no-index tensorflow`."
  },
  {
    "question": "What does the `launch_training.sh` script do in the multi-node TensorFlow setup?",
    "answer": "The `launch_training.sh` script activates the virtual environment located in `$SLURM_TMPDIR/ENV` and then executes the main Python training script, `tensorflow-multiworker.py`."
  }
]