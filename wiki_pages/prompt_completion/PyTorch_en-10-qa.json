[
  {
    "question": "What does PyTorch offer as high-level features?",
    "answer": "PyTorch provides Tensor computation (like NumPy) with strong GPU acceleration and deep neural networks built on a tape-based autograd system."
  },
  {
    "question": "What is the relationship between PyTorch and Torch?",
    "answer": "PyTorch has a distant connection with Torch, but for all practical purposes, they can be treated as separate projects."
  },
  {
    "question": "What is LibTorch?",
    "answer": "LibTorch allows one to implement extensions to PyTorch using C++ and to implement pure C++ machine learning applications. It includes all headers, libraries, and CMake configuration files required to depend on PyTorch."
  },
  {
    "question": "How can models written in Python using PyTorch be used in pure C++?",
    "answer": "Models written in Python using PyTorch can be converted and used in pure C++ through TorchScript."
  },
  {
    "question": "How can I see the latest available version of PyTorch wheels?",
    "answer": "Run the command `avail_wheels torch`."
  },
  {
    "question": "What are the preferred steps to install a PyTorch wheel?",
    "answer": "1. Load a Python module using `module load python`. 2. Create and start a virtual environment. 3. Install PyTorch in the virtual environment with `pip install --no-index torch`."
  },
  {
    "question": "Which PyTorch version is required for H100 GPUs?",
    "answer": "Torch 2.3 and higher is required for H100 GPUs."
  },
  {
    "question": "How do you install additional PyTorch packages like torchvision, torchtext, and torchaudio?",
    "answer": "Run `pip install --no-index torch torchvision torchtext torchaudio` within your virtual environment."
  },
  {
    "question": "What does a 'CUDA error: no kernel image is available for execution on the device' mean?",
    "answer": "This exception means that the current torch installation does not support the compute architecture or the GPU device being used."
  },
  {
    "question": "How can you resolve a 'CUDA error: no kernel image is available for execution on the device'?",
    "answer": "You should either update `torch` to a more recent version or request a different GPU compatible with the current version used."
  },
  {
    "question": "What modules are required to set up the LibTorch environment using StdEnv/2023?",
    "answer": "For StdEnv/2023, you need to load `StdEnv/2023 gcc cuda/12.2 cmake protobuf cudnn python/3.11 abseil cusparselt opencv/4.8.1`."
  },
  {
    "question": "How do you create and activate a Python virtual environment for LibTorch installation?",
    "answer": "Run `virtualenv --no-download --clear ~/ENV && source ~/ENV/bin/activate`."
  },
  {
    "question": "How do you install PyTorch and NumPy in the LibTorch virtual environment?",
    "answer": "After activating the virtual environment, run `pip install --no-index torch numpy`."
  },
  {
    "question": "How can you determine the versions of modules like abseil, cusparselt, and opencv used to compile the PyTorch wheel?",
    "answer": "You can use the command `ldd $VIRTUAL_ENV/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so | sed -n 's&^.*/\\(\\(opencv\\|abseil\\|cusparselt\\)/[^/]*\\).*&\\1&p' | sort -u` (adjusting python version as needed)."
  },
  {
    "question": "What are the specific versions for abseil, cusparselt, and opencv shown in the StdEnv/2023 example output?",
    "answer": "The example output shows `abseil/20230125.3`, `cusparselt/0.5.0.1`, and `opencv/4.8.1`."
  },
  {
    "question": "What modules are required to set up the LibTorch environment using StdEnv/2020?",
    "answer": "For StdEnv/2020, you need to load `gcc cuda/11.4 cmake protobuf cudnn python/3.10`."
  },
  {
    "question": "What is a minimal C++ example for LibTorch to check CUDA availability and create a tensor?",
    "answer": "The `example.cpp` code includes `torch/torch.h` and checks `torch::cuda::is_available()` to set the device, then creates and prints a random tensor `torch::rand({2, 3}).to(device)`."
  },
  {
    "question": "What does the `CMakeLists.txt` file for a minimal LibTorch example contain?",
    "answer": "It specifies `cmake_minimum_required(VERSION 3.0 FATAL_ERROR)`, `project(example)`, `find_package(Torch REQUIRED)`, `add_executable(example example.cpp)`, `target_link_libraries(example \"${TORCH_LIBRARIES}\")`, and `set_property(TARGET example PROPERTY CXX_STANDARD 14)`."
  },
  {
    "question": "How do you configure a LibTorch project for compilation in StdEnv/2023?",
    "answer": "You configure with `cmake -B build -S . -DCMAKE_PREFIX_PATH=$VIRTUAL_ENV/lib/python3.11/site-packages -DCMAKE_EXE_LINKER_FLAGS=-Wl,-rpath=$VIRTUAL_ENV/lib/python3.11/site-packages/torch/lib,-L$EBROOTCUDA/extras/CUPTI/lib64 -DCMAKE_SKIP_RPATH=ON -DTORCH_CUDA_ARCH_LIST=\"6.0;7.0;7.5;8.0;9.0\"`."
  },
  {
    "question": "How do you compile a LibTorch program after configuring it?",
    "answer": "After configuration, compile using `cmake --build build`."
  },
  {
    "question": "How do you run a compiled LibTorch example program?",
    "answer": "Run the program using `build/example`."
  },
  {
    "question": "What is required to test a LibTorch application with CUDA?",
    "answer": "To test a LibTorch application with CUDA, you need to request an interactive job with a GPU."
  },
  {
    "question": "Where can I find additional resources for LibTorch?",
    "answer": "You can refer to the official documentation at `https://pytorch.org/cppdocs/`."
  }
]