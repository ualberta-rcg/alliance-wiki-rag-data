[
  {
    "question": "What is the primary purpose of a journal file in Ansys Fluent simulations?",
    "answer": "A journal file is used to load the case file (and optionally the data file), run the solver, and finally write the results of an Ansys Fluent simulation. Users should adjust filenames and desired iterations within it."
  },
  {
    "question": "How can users address frequent job failures in Fluent due to license shortages?",
    "answer": "Users can modify their Slurm script to requeue the job (up to 4 times) when jobs frequently fail to start due to license shortages. This option is available under the 'by node + requeue' tab."
  },
  {
    "question": "What is the recommended practice when using job requeueing to handle license-related Fluent job failures?",
    "answer": "It is strongly recommended to monitor and inspect each Slurm output file to confirm that each requeue attempt is license-related. If a job is requeued due to a simulation issue (like divergence), the job progression should be immediately killed manually using `scancel jobid` and the problem corrected to avoid wasted compute time."
  },
  {
    "question": "After a Fluent job has been run on a cluster, how can the data file be imported back into Fluent?",
    "answer": "After running the job, the data file can be downloaded and imported back into Fluent using 'File > Import > Data\u2026'."
  },
  {
    "question": "For most Fluent jobs, which type of Slurm script is recommended for optimal performance and minimal solution latency?",
    "answer": "Most Fluent jobs should use a 'by node' script to minimize solution latency and maximize performance over as few nodes as possible."
  },
  {
    "question": "When might a 'by core' script be preferable for Fluent jobs, despite potential downsides?",
    "answer": "Very large Fluent jobs might wait less in the queue if they use a 'by core' script."
  },
  {
    "question": "What are the potential drawbacks of running large Fluent jobs over an unspecified number of many nodes?",
    "answer": "Running large jobs over many nodes can lead to significantly longer startup times and makes them far more vulnerable to crashing if any compute nodes fail during the simulation."
  },
  {
    "question": "How do the general purpose Fluent Slurm scripts manage memory communication for single-node versus multi-node runs?",
    "answer": "The scripts ensure Fluent uses shared memory for communication when run on a single node and distributed memory (utilizing MPI and HPC interconnect) when run over multiple nodes."
  },
  {
    "question": "What is a suggested approach if Fluent crashes during the initial auto mesh partitioning phase on Narval using standard Intel-based scripts?",
    "answer": "If Fluent crashes, a more robust alternative is to use the two Narval tabs for scripts, or manually perform mesh partitioning in the Fluent GUI and then rerun the job on the cluster with Intel scripts. This allows inspection of partition statistics and selection of an optimal partitioning method."
  },
  {
    "question": "What are the guidelines for the number of mesh partitions and cells per core for optimal efficiency in Fluent?",
    "answer": "The number of mesh partitions should be an integral multiple of the number of cores, and for optimal efficiency, there should be at least 10,000 cells per core."
  },
  {
    "question": "What is the name of the example script provided for multinode Fluent jobs utilizing the 'by node' strategy with Intel MPI?",
    "answer": "The example script is named `script-flu-bynode-intel.sh`."
  },
  {
    "question": "In the `script-flu-bynode-intel.sh` example, how is the Slurm account specified?",
    "answer": "The Slurm account is specified using `#SBATCH --account=def-group`."
  },
  {
    "question": "How is the time limit for a job set in the `script-flu-bynode-intel.sh` example?",
    "answer": "The time limit is set using `#SBATCH --time=00-03:00` (dd-hh:mm format) in the `script-flu-bynode-intel.sh` example."
  },
  {
    "question": "What is the default number of compute nodes requested in `script-flu-bynode-intel.sh`, and what is the maximum for Narval?",
    "answer": "The default number of compute nodes requested is 1, and for Narval, 1 node is the maximum."
  },
  {
    "question": "How many cores per node are specified in the `script-flu-bynode-intel.sh` example?",
    "answer": "The `script-flu-bynode-intel.sh` example specifies 32 cores per node (`#SBATCH --ntasks-per-node=32`)."
  },
  {
    "question": "What value should be used for the `--mem` parameter in `script-flu-bynode-intel.sh` to allocate all memory available on a compute node?",
    "answer": "The `--mem` parameter should be set to `0` to allocate all memory per compute node."
  },
  {
    "question": "Which Ansys and Standard Environment modules are loaded in the `script-flu-bynode-intel.sh` example?",
    "answer": "The `StdEnv/2023` and `ansys/2023R2` (or newer versions) modules are loaded in the `script-flu-bynode-intel.sh` example."
  },
  {
    "question": "Which variables in `script-flu-bynode-intel.sh` need customization for the Fluent journal file and version?",
    "answer": "The `MYJOURNALFILE` variable (e.g., `sample.jou`) and `MYVERSION` variable (e.g., `3d` for 2d, 2ddp, 3d, or 3ddp) need to be customized."
  },
  {
    "question": "How does the `script-flu-bynode-intel.sh` script execute Fluent when only one compute node is requested?",
    "answer": "If `SLURM_NNODES` is 1, Fluent is executed with `fluent -g $MYVERSION -t $NCORES -affinity=0 -mpi=intel -pshmem -i $MYJOURNALFILE`."
  },
  {
    "question": "How does the `script-flu-bynode-intel.sh` script execute Fluent on multiple nodes, differentiating between Nibi and other clusters?",
    "answer": "On multiple nodes, if the cluster is Nibi, Fluent is run with `-peth`. For other clusters, it's run with `-pib`. Both use Intel MPI with a machinefile: `fluent -g $MYVERSION -t $NCORES -affinity=0 -mpi=intel -peth/-pib -cnf=/tmp/machinefile-$SLURM_JOB_ID -i $MYJOURNALFILE`."
  }
]