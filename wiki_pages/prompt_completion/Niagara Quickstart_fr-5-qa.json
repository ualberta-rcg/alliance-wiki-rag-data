[
  {
    "question": "What is a recommended format for writing data out to disk on Niagara?",
    "answer": "It is recommended to write data out in a binary format because it is faster and takes less space."
  },
  {
    "question": "What is the Burst Buffer used for on Niagara?",
    "answer": "The Burst Buffer is better for I/O heavy jobs and to speed up checkpoints."
  },
  {
    "question": "What does `#!/bin/bash` signify at the beginning of a Slurm submission script?",
    "answer": "The line `#!/bin/bash` indicates that the script is a bash script."
  },
  {
    "question": "How do you specify the number of nodes for an MPI job in the example Slurm script?",
    "answer": "The number of nodes is specified using `#SBATCH --nodes=2`."
  },
  {
    "question": "How many tasks are requested for the MPI job in the example Slurm script?",
    "answer": "A total of 80 tasks are requested using `#SBATCH --ntasks=80`."
  },
  {
    "question": "What is the requested walltime for the MPI job in the example Slurm script?",
    "answer": "The requested walltime is 1 hour, specified by `#SBATCH --time=1:00:00`."
  },
  {
    "question": "What is the job name specified in the example MPI submission script?",
    "answer": "The job name is specified as `mpi_job` using `#SBATCH --job-name mpi_job`."
  },
  {
    "question": "Which modules are loaded in the example MPI submission script?",
    "answer": "The `intel/2018.2` and `openmpi/3.1.0` modules are loaded."
  },
  {
    "question": "How is the MPI application executed within the example submission script?",
    "answer": "The MPI application is executed using `mpirun ./mpi_example` or `srun ./mpi_example`."
  },
  {
    "question": "How do you submit the MPI job script (named mpi_ex.sh) to the Slurm scheduler?",
    "answer": "The script is submitted with the command `sbatch mpi_ex.sh`."
  },
  {
    "question": "How can hyperthreading be enabled for an OpenMPI application when submitting a job?",
    "answer": "To use hyperthreading with OpenMPI, change `--ntasks=80` to `--ntasks=160` and add `--bind-to none` to the `mpirun` command."
  },
  {
    "question": "How many nodes and CPUs per task are requested for the OpenMP job in the example Slurm script?",
    "answer": "One node (`--nodes=1`) and 40 CPUs per task (`--cpus-per-task=40`) are requested."
  },
  {
    "question": "How is the `OMP_NUM_THREADS` environment variable set in the example OpenMP submission script?",
    "answer": "The `OMP_NUM_THREADS` environment variable is set to the number of CPUs per task using `export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK`."
  },
  {
    "question": "How can hyperthreading be enabled for an OpenMP application in a Slurm job script?",
    "answer": "To enable hyperthreading for OpenMP, replace `--cpus-per-task=40` with `--cpus-per-task=80`."
  },
  {
    "question": "What happens after Slurm finds a node for an MPI job and runs the script?",
    "answer": "The script changes to the submission directory, loads modules, and runs the `mpi_example` application."
  }
]