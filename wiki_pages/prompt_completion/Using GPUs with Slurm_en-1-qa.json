[
  {
    "question": "What is the recommended form to request one or more GPUs for a Slurm job?",
    "answer": "Use the form `--gpus-per-node=[type:]number`."
  },
  {
    "question": "What does the `[type:]number` notation mean in the `--gpus-per-node` directive?",
    "answer": "You must specify the number of GPUs, and you may optionally specify the GPU type."
  },
  {
    "question": "Where can I find valid GPU types for the `--gpus-per-node` directive?",
    "answer": "Valid types are listed in the 'Available GPUs' table, in the column headed 'Slurm type specifier'."
  },
  {
    "question": "How do I request two GPUs per node of any type available on the cluster?",
    "answer": "Use `--gpus-per-node=2`."
  },
  {
    "question": "How do I request one V100 GPU per node?",
    "answer": "Use `--gpus-per-node=v100:1`."
  },
  {
    "question": "What is an older form for requesting GPU resources?",
    "answer": "The form `--gres=gpu[[:type]:number]` can also be used."
  },
  {
    "question": "Is the `--gres=gpu` form recommended for requesting GPUs?",
    "answer": "No, it is older and may no longer be supported in future Slurm releases; the `--gpus-per-node` form is recommended instead."
  },
  {
    "question": "What other directives can be used to request GPU resources?",
    "answer": "Other directives include `--gpus`, `--gpus-per-socket`, `--gpus-per-task`, `--mem-per-gpu`, and `--ntasks-per-gpu`."
  },
  {
    "question": "Where can I find more information about advanced GPU resource directives?",
    "answer": "Please see the Slurm documentation for sbatch."
  },
  {
    "question": "What should I do if I don't get the expected result when requesting GPU resources?",
    "answer": "Contact technical support."
  },
  {
    "question": "What GPU model is available on the Fir cluster?",
    "answer": "H100-80gb."
  },
  {
    "question": "What is the Compute Capability of the H100-80gb GPUs on the Fir cluster?",
    "answer": "90."
  },
  {
    "question": "What are the characteristics of the GPUs on the Fir cluster?",
    "answer": "There are two GPUs per CPU socket, and all GPUs are connected via NVLink."
  },
  {
    "question": "What GPU model is available on the Narval cluster?",
    "answer": "A100-40gb."
  },
  {
    "question": "What is the Compute Capability of the A100-40gb GPUs on the Narval cluster?",
    "answer": "80."
  },
  {
    "question": "What are the characteristics of the GPUs on the Narval cluster?",
    "answer": "There are two GPUs per CPU socket, and all GPUs are connected via NVLink."
  },
  {
    "question": "What GPU models are available on the Nibi cluster?",
    "answer": "H100-80gb and MI300A-128gb."
  },
  {
    "question": "What is the Compute Capability of the H100-80gb GPUs on the Nibi cluster?",
    "answer": "90."
  },
  {
    "question": "What are the characteristics of the H100-80gb GPUs on the Nibi cluster?",
    "answer": "There are two GPUs per CPU socket, and all GPUs are connected via NVLink."
  },
  {
    "question": "What is the Compute Capability of the MI300A-128gb GPUs on the Nibi cluster?",
    "answer": "N.A."
  },
  {
    "question": "What are the characteristics of the MI300A-128gb GPUs on the Nibi cluster?",
    "answer": "They feature unified memory between the CPU and GPU."
  },
  {
    "question": "What GPU model is available on the Rorqual cluster?",
    "answer": "H100-80gb."
  },
  {
    "question": "What is the Compute Capability of the H100-80gb GPUs on the Rorqual cluster?",
    "answer": "90."
  },
  {
    "question": "What GPU model is available on the Trillium cluster?",
    "answer": "H100-80gb."
  },
  {
    "question": "What is the Compute Capability of the H100-80gb GPUs on the Trillium cluster?",
    "answer": "90."
  },
  {
    "question": "Are cloud resources like Arbutus schedulable via Slurm?",
    "answer": "No, cloud resources are not schedulable via Slurm."
  },
  {
    "question": "What is 'Compute Capability'?",
    "answer": "Compute Capability is a technical term created by NVIDIA to describe what hardware functions are available on some GPU models, not a measure of performance."
  },
  {
    "question": "When is Compute Capability relevant?",
    "answer": "It is relevant only if you are compiling your own GPU programs."
  },
  {
    "question": "What is MIG (Multi-Instance GPU)?",
    "answer": "MIG is a technology that allows partitioning a GPU into multiple instances."
  },
  {
    "question": "What happens if I do not specify a GPU type for my Slurm job?",
    "answer": "Slurm may send your job to a node equipped with any type of GPU available."
  },
  {
    "question": "When is it important to include a GPU type specifier?",
    "answer": "It is important when specific GPU performance characteristics are needed for a workflow, such as high double-precision performance for molecular dynamics code."
  },
  {
    "question": "What is the default number of CPU cores associated with each GPU instance requested?",
    "answer": "The default number of CPU cores is 1."
  },
  {
    "question": "Where can I find recommendations for the maximum number of CPU cores and system memory per GPU instance?",
    "answer": "The recommended maximums are listed in the 'table of bundle characteristics' on the 'Allocations_and_compute_scheduling' page."
  }
]