[
  {
    "question": "What is the primary command-line argument used to request GPUs for a Slurm job?",
    "answer": "The primary argument is `--gpus-per-node=[type:]number`."
  },
  {
    "question": "When requesting GPUs using `--gpus-per-node=[type:]number`, which part is mandatory and which is optional?",
    "answer": "The 'number' of GPUs must be specified, while the 'type' of GPU is optional."
  },
  {
    "question": "Where can users find a list of valid GPU types for the Slurm type specifier?",
    "answer": "Valid types are listed in the 'Available GPUs' table, in the column headed 'Slurm type specifier'."
  },
  {
    "question": "What does the Slurm command `--gpus-per-node=2` request?",
    "answer": "It requests two GPUs per node, of any type available on the cluster."
  },
  {
    "question": "How do you request one V100 type GPU per node using the recommended Slurm argument?",
    "answer": "Use `--gpus-per-node=v100:1`."
  },
  {
    "question": "Which older Slurm form can also be used to request GPUs, but is not recommended?",
    "answer": "The form `--gres=gpu[[:type]:number]` can be used, but it is older and not recommended."
  },
  {
    "question": "What is the recommended replacement for the `--gres` form in Slurm scripts?",
    "answer": "It is recommended to replace `--gres` with the `--gpus-per-node` form."
  },
  {
    "question": "Are there other directives available for requesting GPU resources besides `--gpus-per-node` and `--gres`?",
    "answer": "Yes, other directives include `--gpus`, `--gpus-per-socket`, `--gpus-per-task`, `--mem-per-gpu`, and `--ntasks-per-gpu`."
  },
  {
    "question": "Where can a user find more information about advanced GPU resource directives like `--gpus-per-socket`?",
    "answer": "Users should see the Slurm documentation for `sbatch`."
  },
  {
    "question": "What should a user do if they don't get the expected results when requesting GPU resources?",
    "answer": "If results are unexpected, users should contact technical support."
  },
  {
    "question": "How many nodes are on the B\u00e9luga cluster?",
    "answer": "B\u00e9luga has 172 nodes."
  },
  {
    "question": "What is the Slurm type specifier for GPUs on the B\u00e9luga cluster?",
    "answer": "The Slurm type specifier for B\u00e9luga is `v100`."
  },
  {
    "question": "How many GPUs are available per node on B\u00e9luga?",
    "answer": "There are 4 GPUs per node on B\u00e9luga."
  },
  {
    "question": "What is the GPU model on the B\u00e9luga cluster?",
    "answer": "The GPU model on B\u00e9luga is V100-16gb."
  },
  {
    "question": "What is the GPU memory (GiB) for the P100-12gb GPUs on Cedar?",
    "answer": "The P100-12gb GPUs on Cedar have 12 GiB of memory."
  },
  {
    "question": "What is the Slurm type specifier for the P100-16gb GPUs on Cedar?",
    "answer": "The Slurm type specifier for P100-16gb GPUs on Cedar is `p100l`."
  },
  {
    "question": "How many CPU cores are available per node for the V100-32gb GPUs on Cedar (v100l type)?",
    "answer": "There are 32 CPU cores per node for the V100-32gb GPUs (v100l type) on Cedar."
  },
  {
    "question": "How many GPUs are available per node for the P100-12gb GPUs on Graham?",
    "answer": "There are 2 GPUs per node for the P100-12gb GPUs on Graham."
  },
  {
    "question": "What is the Compute Capability of the T4-16gb GPUs on Graham?",
    "answer": "The Compute Capability of the T4-16gb GPUs on Graham is 75."
  },
  {
    "question": "What GPU model is available on the Mist cluster?",
    "answer": "The Mist cluster has V100-32gb GPUs."
  },
  {
    "question": "What is the Slurm type specifier for GPUs on the Narval cluster?",
    "answer": "The Slurm type specifier for GPUs on Narval is `a100`."
  },
  {
    "question": "How much GPU memory (GiB) does the A100-40gb model on Narval have?",
    "answer": "The A100-40gb GPU model on Narval has 40 GiB of memory."
  },
  {
    "question": "Are cloud resources like Arbutus schedulable via Slurm?",
    "answer": "No, cloud resources are not schedulable via Slurm."
  },
  {
    "question": "What does 'Compute Capability' describe, according to NVIDIA?",
    "answer": "Compute Capability is a technical term by NVIDIA that describes the hardware functions available on certain GPU models."
  },
  {
    "question": "Is NVIDIA's 'Compute Capability' a measure of GPU performance?",
    "answer": "No, it is not a measure of performance."
  },
  {
    "question": "When is 'Compute Capability' relevant for users?",
    "answer": "It is relevant only if you are compiling your own GPU programs."
  },
  {
    "question": "How do you access the 16GB flavor of V100 GPUs on Graham?",
    "answer": "Use the arguments `--constraint=skylake,v100` in your sbatch/salloc command."
  },
  {
    "question": "What arguments are needed to access the 32GB flavor of V100 GPUs on Graham?",
    "answer": "Use the arguments `--constraint=cascade,v100`."
  },
  {
    "question": "Do all clusters have only one GPU type available?",
    "answer": "No, clusters like Cedar and Graham have more than one GPU type available."
  },
  {
    "question": "What happens if a user does not specify a GPU type when submitting a Slurm job?",
    "answer": "If no type specifier is supplied, Slurm may send the job to a node equipped with any type of GPU."
  },
  {
    "question": "Why might it be undesirable to not specify a GPU type for certain workflows, such as molecular dynamics?",
    "answer": "For workflows like molecular dynamics that require high double-precision performance, not specifying a GPU type could be undesirable because GPUs like T4 are not appropriate for such tasks."
  }
]