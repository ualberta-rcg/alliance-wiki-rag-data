[
  {
    "question": "How do you submit single-node LS-DYNA jobs?",
    "answer": "Jobs may be submitted to the queue with: 'sbatch script-smp.sh'."
  },
  {
    "question": "What are the common SBATCH directives for a single-node LS-DYNA job script?",
    "answer": "The common SBATCH directives are '--account', '--time', '--cpus-per-task', '--mem', and '--nodes'."
  },
  {
    "question": "Which modules are typically loaded for LS-DYNA version 12.2.1 in a single-node script?",
    "answer": "The modules loaded are 'StdEnv/2023', 'intel/2023.2.1', and 'ls-dyna/12.2.1'."
  },
  {
    "question": "How do you execute the double precision SMP solver in a single-node LS-DYNA job script?",
    "answer": "Execute 'ls-dyna_d ncpu=$SLURM_CPUS_ON_NODE i=airbag.deploy.k memory=1500M'."
  },
  {
    "question": "What is the difference between 'ls-dyna_s' and 'ls-dyna_d' in the context of single-node jobs?",
    "answer": "'ls-dyna_s' is the single precision smp solver, and 'ls-dyna_d' is the double precision smp solver."
  },
  {
    "question": "What is the purpose of 'LSTC_MEMORY=AUTO' for single-node LS-DYNA jobs?",
    "answer": "It is an optional setting for explicit analysis only."
  },
  {
    "question": "How is the total memory setting for Slurm determined for implicit LS-DYNA analysis?",
    "answer": "Once an estimate for the total solver memory (in GB) is determined, the total memory setting for Slurm can be determined by multiplying it by 25%."
  },
  {
    "question": "How do you calculate the memory parameter value in mega words for a double precision implicit LS-DYNA solution?",
    "answer": "It is calculated as (0.75 * memGB / 8Bytes/w) * 1000M."
  },
  {
    "question": "How do you calculate the memory parameter value in mega words for a single precision implicit LS-DYNA solution?",
    "answer": "It is calculated as (0.75 * memGB / 4Bytes/w) * 1000M."
  },
  {
    "question": "What is the MPP version of LS-DYNA used for?",
    "answer": "The MPP version of LS-DYNA is used for running jobs across multiple compute nodes using MPI."
  },
  {
    "question": "How can you list the available modules for the MPP version of LS-DYNA?",
    "answer": "You can list them by running 'module spider ls-dyna-mpi'."
  },
  {
    "question": "What are the two methods for submitting MPP LS-DYNA jobs?",
    "answer": "MPP jobs can be submitted by specifying a number of whole nodes or a specified total number of cores."
  },
  {
    "question": "What does 'memory1' refer to in the context of MPP LS-DYNA jobs?",
    "answer": "'memory1' refers to the sufficiently large amount of memory required for the first core (processor 0) on the master node to decompose and simulate the model."
  },
  {
    "question": "What does 'memory2' refer to in the context of MPP LS-DYNA jobs?",
    "answer": "'memory2' refers to the memory required per core for simulation."
  },
  {
    "question": "What is the memory recommendation for MPP jobs to achieve best results?",
    "answer": "For best results, keep the sum of all expected memory per node within 75% of the reserved RAM on a node."
  },
  {
    "question": "How can LS-DYNA jobs be submitted to a specified number of whole compute nodes?",
    "answer": "Jobs can be submitted to a specified number of whole compute nodes using 'sbatch script-mpp-bynode.sh'."
  },
  {
    "question": "What are the key SBATCH directives for an MPP job script that specifies node count?",
    "answer": "The key directives are '--account', '--time', '--ntasks-per-node', '--nodes', and '--mem=0'."
  },
  {
    "question": "Which modules are loaded for LS-DYNA-MPI version 12.2.1 in a multi-node script by node count?",
    "answer": "The modules loaded are 'StdEnv/2023', 'intel/2023.2.1', and 'ls-dyna-mpi/12.2.1'."
  },
  {
    "question": "What do 'ls-dyna_s' and 'ls-dyna_d' signify for MPP solvers?",
    "answer": "'ls-dyna_s' signifies the single precision mpp solver, and 'ls-dyna_d' signifies the double precision mpp solver."
  },
  {
    "question": "What is the advantage of specifying the core count when submitting MPP LS-DYNA jobs?",
    "answer": "This approach allows the scheduler to determine the optimal number of compute nodes to minimize job wait time in the queue."
  },
  {
    "question": "What important memory setting must be specified for MPP jobs submitted by core count?",
    "answer": "A sufficiently large value of 'mem-per-cpu' must be specified so the master processor can successfully decompose and handle its computations."
  },
  {
    "question": "What are the main SBATCH directives for an MPP job script that specifies core count?",
    "answer": "The main directives are '--account', '--time', '--ntasks', and '--mem-per-cpu'."
  },
  {
    "question": "Why should standard scaling tests be performed before running full LS-DYNA simulations?",
    "answer": "Standard scaling tests should be run to determine the optimal number of cores that can be used before simulation slowdown occurs."
  },
  {
    "question": "Which command can be used to assess the efficiency of completed LS-DYNA test jobs?",
    "answer": "The 'seff jobnumber' command can be used to determine the Job Wall-clock time, CPU Efficiency, and Memory Efficiency."
  },
  {
    "question": "What did recent testing with airbag jobs on different clusters reveal about performance?",
    "answer": "Recent testing found significantly better performance on Cedar and Narval than on Graham."
  },
  {
    "question": "What is recommended before running full LS-DYNA simulations regarding performance?",
    "answer": "It is recommended to (A) conduct standard scaling tests on a given cluster and (B) run identical test cases on each cluster to settle on an optimal job size, module version, and cluster configuration."
  },
  {
    "question": "What is LS-PrePost used for?",
    "answer": "LS-PrePost is used for pre- and post-processing of LS-DYNA models."
  },
  {
    "question": "Is a license required to use LS-PrePost?",
    "answer": "No, LS-PrePost does not require a license."
  },
  {
    "question": "Where can LS-PrePost be utilized?",
    "answer": "It can be used on any cluster node or on the Graham VDI nodes."
  },
  {
    "question": "How do you load and launch LS-PrePost version 4.9 on cluster nodes?",
    "answer": "Connect via TigerVNC, open a terminal, then run 'module load StdEnv/2020', 'module load ls-prepost/4.9', and then 'lsprepost' or 'lspp49'."
  },
  {
    "question": "How do you load and launch LS-PrePost version 4.8 on VDI nodes?",
    "answer": "Connect to gra-vdi with TigerVNC, open a new terminal, then run 'module load CcEnv StdEnv/2020', 'module load ls-prepost/4.8', and then 'lsprepost'."
  }
]