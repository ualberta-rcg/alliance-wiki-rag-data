[
  {
    "question": "How do clusters differ from local machines for machine learning applications?",
    "answer": "Clusters use a distributed filesystem, linking many storage devices, which leads to different performance implications for IO operations compared to a local machine."
  },
  {
    "question": "Why is it important to choose wisely where to put your data on a cluster?",
    "answer": "Accessing a file on a distributed filesystem, like `/project`, has very different performance implications than accessing one from a current node, requiring careful data placement for optimal performance."
  },
  {
    "question": "Is there a self-paced course available on machine learning for clusters?",
    "answer": "Yes, SHARCNET offers a self-paced course titled 'Introduction to Machine Learning'."
  },
  {
    "question": "Where can users find a tutorial for porting their machine learning programs to one of the clusters?",
    "answer": "Users can refer to 'our tutorial' for guidance on porting their programs for use on the clusters."
  },
  {
    "question": "Is there a user-made tutorial for setting up deep learning environments in Python?",
    "answer": "Yes, a user-made tutorial detailing the steps for setting up local and Alliance environments for deep learning in Python is available."
  },
  {
    "question": "Where can users find important information about Python usage on clusters for machine learning?",
    "answer": "Users should refer to the documentation about Python for information on Python versions, virtual environments on login or compute nodes, `multiprocessing`, Anaconda, Jupyter, and more."
  },
  {
    "question": "Should users use Anaconda for Python environments on the clusters?",
    "answer": "No, users are asked to avoid using Anaconda and use virtualenv instead."
  },
  {
    "question": "How easy is it to switch from Anaconda to virtualenv?",
    "answer": "Switching to virtualenv is easy in most cases; users just need to install the same packages, excluding CUDA, CuDNN, and other low-level libraries that are already installed on the clusters."
  },
  {
    "question": "Where can users find useful information about specific machine learning software packages?",
    "answer": "Users should refer to the dedicated page for their machine learning package of choice for installation information and common pitfalls."
  },
  {
    "question": "What are some of the machine learning packages for which specific information pages are available?",
    "answer": "Information pages are available for TensorFlow, PyTorch, Keras, Torch, SpaCy, XGBoost, Scikit-Learn, and SnapML."
  },
  {
    "question": "What types of storage options are available on the clusters for machine learning datasets?",
    "answer": "The clusters offer a wide range of storage options, including high-speed temporary local storage and different kinds of long-term storage, to suit diverse user needs."
  },
  {
    "question": "Where can users find more documentation about storage and file management on the clusters?",
    "answer": "Users should refer to the documentation on 'Storage and file management'."
  },
  {
    "question": "What is the recommendation for storing datasets that are around 10 GB or less?",
    "answer": "If a dataset is around 10 GB or less, it can probably fit in memory, and users should avoid reading data from disk during machine learning tasks."
  },
  {
    "question": "What is the recommended storage strategy for datasets around 100 GB or less?",
    "answer": "Datasets around 100 GB or less should be transferred to the local storage of the compute node at the beginning of the job, as this storage is significantly faster and more reliable than shared storage."
  },
  {
    "question": "What is the purpose of `$SLURM_TMPDIR`?",
    "answer": "`$SLURM_TMPDIR` is a temporary directory available for each job on the local storage of the compute node."
  },
  {
    "question": "What is a potential issue when using local node storage for datasets?",
    "answer": "A potential issue is that a job from another user might fully utilize the local node storage, leaving no space for your job."
  },
  {
    "question": "Where should datasets larger than 100 GB be stored?",
    "answer": "If a dataset is larger than 100 GB, it may need to be stored in shared storage, such as project space for permanent storage or scratch space for faster, non-permanent storage."
  },
  {
    "question": "What is the recommended frequency for reading and storing data on shared storage (home, project, scratch)?",
    "answer": "All shared storage is designed for storing and reading at low frequencies, such as one large chunk every 10 seconds, rather than many small chunks every second."
  },
  {
    "question": "What problems can arise when managing datasets with many small files (e.g., image datasets) on clusters?",
    "answer": "Problems include filesystem quotas limiting the number of filesystem objects and significant slowdowns in software when streaming many small files from `/project` or `/scratch`."
  },
  {
    "question": "How should datasets containing lots of small files be stored on a distributed filesystem?",
    "answer": "On a distributed filesystem, data with many small files should be stored in large single-file archives to mitigate performance and quota issues."
  }
]