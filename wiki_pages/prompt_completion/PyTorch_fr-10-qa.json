[
  {
    "question": "When is it recommended to combine model parallelism and data parallelism with multiple GPUs in PyTorch?",
    "answer": "Combining model and data parallelism is recommended when a model is too large to fit on a single GPU and requires training with a very large dataset."
  },
  {
    "question": "How does combining model and data parallelism work with multiple GPUs?",
    "answer": "The model is divided into portions, each assigned to a distinct GPU. Pipeline parallelism is then applied to the results, and copies of this process are made, training these model copies in parallel with different subsets of the training data. Gradients are calculated independently, aggregated, and parameters are updated synchronously or asynchronously across all copies."
  },
  {
    "question": "What is a limitation of Torch RPC when combining model and data parallelism across multiple GPUs?",
    "answer": "Currently, Torch RPC only supports dividing a model within a single node. For models that exceed the memory capacity of all GPUs in a compute node, DeepSpeed is recommended."
  },
  {
    "question": "What environment variables are set for Torch RPC and DDP combination in the `pytorch-model-data-par.sh` script?",
    "answer": "The `MASTER_ADDR` is set to the hostname of the main node, and the `MASTER_PORT` is set to `34567` for the main node, with subsequent replicas using `34567 + local_rank` to ensure unique RPC server ports for each model replica."
  },
  {
    "question": "How are model parts distributed across GPUs when combining Torch RPC and DDP?",
    "answer": "The first part of the model (ConvPart) is loaded onto `cuda(local_rank)`, and the second part (MLPPart) is loaded onto `cuda(local_rank + 1)` for each process."
  },
  {
    "question": "What is DeepSpeed?",
    "answer": "DeepSpeed is a library designed to optimize the training of deep learning models, particularly those with billions of parameters, by implementing new distributed training methods that efficiently use memory, notably through the Zero Redundancy Optimizer (ZeRO) concept."
  },
  {
    "question": "How does DeepSpeed's ZeRO (Zero Redundancy Optimizer) work?",
    "answer": "ZeRO distributes the storage and processing of various training elements, such as optimizer states, model weights, gradients, and activations, across multiple devices like GPUs, CPUs, local hard drives, or combinations thereof. This pooling of resources allows for efficient training of large models on multiple nodes."
  },
  {
    "question": "What is the primary benefit of using DeepSpeed?",
    "answer": "DeepSpeed enables the efficient training of models with enormous numbers of parameters across multiple nodes without requiring explicit code for model, pipeline, or data parallelism."
  },
  {
    "question": "How is ZeRO Stage 3 used with GPUs for model training?",
    "answer": "ZeRO Stage 3 distributes the optimizer states, model parameters, and model gradients across all participating GPUs. This approach is more memory-efficient than pure data parallelism, where a complete copy of the model is loaded onto each GPU."
  },
  {
    "question": "Which DeepSpeed optimizer is recommended for ZeRO Stage 3 with GPUs?",
    "answer": "The `FusedAdam` optimizer from DeepSpeed is recommended for ZeRO Stage 3 with GPUs, offering performance comparable to pure data parallelism. It requires loading a `cuda/<version>` module that matches the PyTorch package's build version."
  },
  {
    "question": "What are the advantages of using ZeRO Stage 3 with CPU offloading?",
    "answer": "Offloading optimizer states and model parameters to CPU memory makes the compute node's memory available for tensors not currently required by the GPU. This can be seen as adding significant additional memory (e.g., 32GB) to the GPU's capacity, allowing for larger batch sizes or models. Optimizer steps are also computed on the CPU."
  },
  {
    "question": "Which DeepSpeed optimizer is used for ZeRO Stage 3 with CPU offloading?",
    "answer": "The `DeepSpeedCPUAdam` optimizer from DeepSpeed is used for ZeRO Stage 3 with CPU offloading, and it requires loading a `cuda/<version>` module that matches the PyTorch package's build version."
  },
  {
    "question": "When is ZeRO Stage 3 with NVMe disk offloading used, and what are its characteristics?",
    "answer": "ZeRO Stage 3 with NVMe disk offloading is used when optimizer states and model parameters are moved to local storage (NVMe disks) instead of CPU memory. This further expands available storage for tensors, enabling even larger batches or models. However, it results in a significant performance loss compared to CPU/GPU offloading. It's best utilized with faster NVMe disks to minimize this performance impact."
  },
  {
    "question": "What is the role of `torch.distributed.rpc.init_rpc` when combining Torch RPC and DDP?",
    "answer": "`torch.distributed.rpc.init_rpc` is used to initialize an RPC server for pipeline parallelism within each model replica, rather than for communication between different replicas, which is handled by DistributedDataParallel."
  },
  {
    "question": "How are inputs and targets sent to the GPUs in the model and data parallel example?",
    "answer": "Inputs are sent to `inputs.cuda(model_rank)` and targets are sent to `targets.cuda(model_rank + 1)`, distributing them across the GPUs assigned to different parts of the model within each replica."
  }
]