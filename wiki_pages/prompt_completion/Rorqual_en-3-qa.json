[
  {
    "question": "How do I request multiple H100-80gb GPUs per node?",
    "answer": "To request 2, 3, or 4 H100-80gb GPUs per node, use the Slurm options: `--gpus-per-node=h100:2`, `--gpus-per-node=h100:3`, or `--gpus-per-node=h100:4` respectively."
  },
  {
    "question": "What is the Slurm option for requesting multiple full H100 GPUs that can be spread across any available nodes?",
    "answer": "To request multiple full H100 GPUs spread anywhere, use `--gpus=h100:n`, replacing `n` with the number of GPUs you want."
  },
  {
    "question": "Which GPU nodes are configured with Multi-Instance GPU (MIG) technology?",
    "answer": "Approximately half of the GPU nodes are configured with MIG technology."
  },
  {
    "question": "What are the available GPU instance sizes for MIG technology?",
    "answer": "The available MIG instance sizes are H100-1g.10gb (1/8th computing power, 10GB GPU memory), H100-2g.20gb (2/8th computing power, 20GB GPU memory), and H100-3g.40gb (3/8th computing power, 40GB GPU memory)."
  },
  {
    "question": "How do I request a single H100-1g.10gb GPU instance for a compute job?",
    "answer": "To request one H100-1g.10gb GPU instance, use the Slurm option `--gpus=h100_1g.10gb:1`."
  },
  {
    "question": "What Slurm option is used to request a single H100-2g.20gb GPU instance?",
    "answer": "To request one H100-2g.20gb GPU instance, use the Slurm option `--gpus=h100_2g.20gb:1`."
  },
  {
    "question": "What is the command to request a single H100-3g.40gb GPU instance for my job?",
    "answer": "To request one H100-3g.40gb GPU instance, use the Slurm option `--gpus=h100_3g.40gb:1`."
  }
]