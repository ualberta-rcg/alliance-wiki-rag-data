[
  {
    "question": "What topics does this tutorial cover regarding data handling in HPC?",
    "answer": "This self-study tutorial will discuss issues in handling large amounts of data in HPC, various parallel I/O strategies for large-scale Input/Output (I/O) with parallel jobs, with a particular focus on MPI-IO, and will introduce parallel I/O libraries like NetCDF, HDF5, and ADIOS."
  },
  {
    "question": "What are the three primary I/O activities in computationally expensive HPC jobs?",
    "answer": "The three primary I/O activities are reading initial datasets or conditions, storing numerical data from calculations for follow-up runs or post-processing, and writing the application state into a file for restarting the application in case of system failure."
  },
  {
    "question": "How does Amdahl's law relate to I/O performance in parallel HPC programs?",
    "answer": "Amdahl's law states that a parallel program's speedup is limited by its sequential fraction. If the I/O part of an HPC application works sequentially, it can create a bottleneck, severely limiting the code's scalability and overall performance."
  },
  {
    "question": "Is achieving efficient I/O straightforward in HPC systems?",
    "answer": "No, efficient I/O without stressing out the HPC system is challenging."
  },
  {
    "question": "Why are load/store operations a critical factor in HPC performance?",
    "answer": "Load/store operations from memory or hard-disk take much more time than multiply operations in the CPU, making efficient I/O handling a key factor to achieve best overall performance in HPC."
  },
  {
    "question": "What are the components that make up the total execution time in high-performance computing?",
    "answer": "The total execution time in high-performance computing consists of computation time in the CPU, communication time in the inter-connection or network, and I/O time."
  },
  {
    "question": "How does the improvement in supercomputer speed compare to disk access rates over time?",
    "answer": "From 1960 to 2014, top supercomputer speed increased by 11 orders of magnitude, while single hard disk drive capacity grew by 6 orders, and the average internal drive access rate grew by only 3-4 orders of magnitude. This significant discrepancy means systems produce far more data than can be stored proportionally."
  },
  {
    "question": "What is IOPs in the context of I/O performance?",
    "answer": "IOPs stands for I/O operations per second, which includes read/write operations, and is essentially the inverse of latency."
  },
  {
    "question": "How is I/O Bandwidth defined?",
    "answer": "I/O Bandwidth is defined as the quantity of data that you read or write."
  },
  {
    "question": "Are parallel filesystems designed to provide 'supercomputing' performance for I/O?",
    "answer": "No, parallel (distributed) filesystems are optimized for efficient I/O by multiple users on multiple machines/nodes, but they do not result in 'supercomputing' performance."
  },
  {
    "question": "Are high-end SSDs suitable for supercomputing systems with hundreds of terabytes of data?",
    "answer": "While top-of-the-line SSDs on a PCI Express can achieve up to 1GB IOPs, they are still very expensive and not a suitable fit for several hundreds terabyte supercomputing systems."
  }
]