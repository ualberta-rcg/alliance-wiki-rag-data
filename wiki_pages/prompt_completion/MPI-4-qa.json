[
  {
    "question": "What information can each process output after incorporating `MPI_Comm_rank` and `MPI_Comm_size` functions?",
    "answer": "Each process can output its unique rank and the total number of processes running in the job."
  },
  {
    "question": "When using `MPI_Comm_rank` and `MPI_Comm_size` for basic output, what is notable about the code structure?",
    "answer": "Since all processes perform identical operations, no conditional blocks are required in the code."
  },
  {
    "question": "What is the purpose of the `MPI_Comm_rank` function?",
    "answer": "`MPI_Comm_rank` reports the rank of the calling process."
  },
  {
    "question": "What is the purpose of the `MPI_Comm_size` function?",
    "answer": "`MPI_Comm_size` reports the total number of processes running as part of the job."
  },
  {
    "question": "How do you compile a C MPI program, such as `phello1.c`?",
    "answer": "You compile it using `mpicc -Wall phello1.c -o phello1`."
  },
  {
    "question": "How do you run a compiled MPI program, for example `phello1`, with 4 processes?",
    "answer": "You run it using `mpirun -np 4 ./phello1`."
  },
  {
    "question": "When running an MPI program, what assumptions should you make about the order of output from different processes?",
    "answer": "You should make no assumptions about the order of output from different processes, as the stdout of all running processes is simply concatenated together."
  },
  {
    "question": "How do you compile a Boost C++ MPI program?",
    "answer": "A Boost C++ MPI program is compiled using `mpic++ --std=c++11 phello1.cpp -lboost_mpi-mt -lboost_serialization-mt -o phello1`."
  },
  {
    "question": "How do you run a Python MPI program using `mpi4py` with multiple processes?",
    "answer": "You run it using `mpirun -np 4 python phello1.py`."
  },
  {
    "question": "What is the next step to make a parallel \"Hello, World!\" program more engaging after simply having processes output their rank and size?",
    "answer": "The next step is to introduce communication between the processes by having them send messages to one another."
  },
  {
    "question": "Describe a common communication pattern used to make processes send messages in a ring.",
    "answer": "Process `i` sends its message to process `i+1`, and the last process `N-1` sends its message back to process `0`. This can be expressed as `process i sends to process (i+1)%N`."
  },
  {
    "question": "What are the simplest MPI functions for sending and receiving data between two processes?",
    "answer": "The simplest functions are `MPI_Send` for sending and `MPI_Recv` for receiving data."
  },
  {
    "question": "What kind of data can be sent or received using `MPI_Send` and `MPI_Recv`?",
    "answer": "These functions send and receive a sequence of one or more instances of an atomic data type."
  },
  {
    "question": "What are the arguments for the `MPI_Send` function?",
    "answer": "The arguments are `message` (reference to data), `count` (number of items), `datatype` (type of item), `dest` (rank of receiver), `tag` (programmer-specified identifier), and `comm` (communicator)."
  },
  {
    "question": "What is the `tag` argument in `MPI_Send` used for?",
    "answer": "The `tag` is a programmer-specified identifier associated with the message, which can be used to organize communication streams, for example, to distinguish different interleaved data streams."
  },
  {
    "question": "Which communicator value is typically used in basic MPI tutorials?",
    "answer": "`MPI_COMM_WORLD` is typically used, representing all MPI processes started with the job."
  },
  {
    "question": "Why is the `datatype` argument a variable in `MPI_Send` and `MPI_Recv`?",
    "answer": "It provides a layer of compatibility between processes running on architectures for which the native format for these types differs."
  },
  {
    "question": "Name some predefined MPI data types for the C language.",
    "answer": "Some predefined MPI data types for C include `MPI_CHAR`, `MPI_FLOAT`, `MPI_SHORT`, and `MPI_INT`."
  },
  {
    "question": "Name some predefined MPI data types for the Fortran language.",
    "answer": "Some predefined MPI data types for Fortran include `MPI_CHARACTER`, `MPI_INTEGER`, and `MPI_REAL`."
  },
  {
    "question": "What additional argument does `MPI_Recv` have compared to `MPI_Send`?",
    "answer": "`MPI_Recv` takes an additional `status` argument."
  },
  {
    "question": "What is the `status` argument in `MPI_Recv` used for in C?",
    "answer": "In C, `status` should be a reference to an allocated `MPI_Status` structure that stores information about the received message upon return."
  },
  {
    "question": "How do you calculate the rank of the process to send to in a communication ring where process `i` sends to `i+1`?",
    "answer": "The process to send to is calculated as `(rank + 1) % size`, where `size` is the total number of processes."
  },
  {
    "question": "How do you calculate the rank of the process to receive from in a communication ring where messages rotate one rank to the right?",
    "answer": "The process to receive from is calculated as `(rank + size - 1) % size`."
  }
]