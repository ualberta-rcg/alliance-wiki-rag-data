[
  {
    "question": "What is CUDA?",
    "answer": "CUDA\u00ae is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs)."
  },
  {
    "question": "How can CUDA be understood or thought of?",
    "answer": "CUDA can be thought of as a set of libraries and associated C, C++, and Fortran compilers that enable you to write code for GPUs."
  },
  {
    "question": "What is the name of the CUDA C/C++ language compiler?",
    "answer": "The CUDA C/C++ language compiler is called `nvcc`."
  },
  {
    "question": "What is the first step when starting to use CUDA?",
    "answer": "First, load a CUDA module."
  },
  {
    "question": "How do you load a CUDA module?",
    "answer": "You can load a CUDA module by running the commands: `$ module purge` and then `$ module load cuda`."
  },
  {
    "question": "What file extension is important for CUDA C/C++ programs?",
    "answer": "The `cu` file extension is important for CUDA C/C++ programs."
  },
  {
    "question": "How do you compile a CUDA program like `add.cu`?",
    "answer": "Compile the program with `nvcc` using the command: `$ nvcc add.cu -o add`."
  },
  {
    "question": "How do you run a compiled CUDA program, such as 'add'?",
    "answer": "To run the program, you create a Slurm job script (e.g., `gpu_job.sh`) and submit it with `$ sbatch gpu_job.sh`."
  },
  {
    "question": "What specific detail needs to be replaced in the example Slurm job script?",
    "answer": "You need to replace `def-someuser` with your specific account in the Slurm job script."
  },
  {
    "question": "What might be the output if a CUDA program is run without a GPU present?",
    "answer": "If a CUDA program is run without a GPU present, you might see output like `2+7=0`."
  },
  {
    "question": "How do you compile a CUDA program that needs to link external libraries like cuBLAS?",
    "answer": "Compile with the flags `nvcc -lcublas -Xlinker=-rpath,$CUDA_PATH/lib64`."
  },
  {
    "question": "What is 'compute capability' as defined by NVIDIA?",
    "answer": "The compute capability of a device is a version number, also called its 'SM version', that identifies features supported by the GPU hardware and determines which hardware features and/or instructions are available to applications at runtime."
  },
  {
    "question": "What are common error messages related to compute capability?",
    "answer": "Common error messages related to compute capability include: `nvcc fatal : Unsupported gpu architecture 'compute_XX'` and `no kernel image is available for execution on the device (209)`."
  },
  {
    "question": "How can you fix 'Unsupported gpu architecture' errors when compiling with `nvcc`?",
    "answer": "You can fix this by adding the flag `-gencode arch=compute_XX,code=[sm_XX,compute_XX]` to the `nvcc` call, where 'XX' is the compute capability."
  },
  {
    "question": "How do you specify the compute capability when using `cmake`?",
    "answer": "When using `cmake`, you provide the flag `cmake .. -DCMAKE_CUDA_ARCHITECTURES=XX`, where 'XX' is the compute capability."
  },
  {
    "question": "What does 'XX' represent in the compute capability flags?",
    "answer": "'XX' represents the compute capability of the Nvidia GPU that you expect to run the application on."
  },
  {
    "question": "What is the compute capability of a Narval A100 node?",
    "answer": "The compute capability of a Narval A100 node is 80."
  },
  {
    "question": "What `nvcc` flag should be used for a Narval A100 node's compute capability?",
    "answer": "For a Narval A100 node, the `nvcc` flag to use is `-gencode arch=compute_80,code=[sm_80,compute_80]`."
  },
  {
    "question": "What `cmake` flag should be supplied for a Narval A100 node's compute capability?",
    "answer": "For a Narval A100 node, the `cmake` flag to supply is `cmake .. -DCMAKE_CUDA_ARCHITECTURES=80`."
  }
]