<languages /> 
__TOC__

<span id="Overview"></span>
=Aperçu=

La grappe Trillium est conçue pour prendre en charge des tâches massivement parallèles. Construite par Lenovo Canada, elle est hébergée par SciNet à l'Université de Toronto. Ses trois composantes principales sont&nbsp;:

1. Sous-grappe de CPU

* 235&nbsp;008 cœurs dans 1&nbsp;224 nœuds de calcul CPU
* Chaque nœud de calcul CPU a 192&nbsp;cœurs provenant de deux processeurs AMD EPYC 9655 de 96&nbsp;cœurs chacun (Zen 5, ou Turin) cadencés à 2,6GHz (fréquence de base).
* Chaque nœud de calcul CPU a 755GiB / 810GB de mémoire disponible.
* Les nœuds ont une connexion InfiniBand NDR non bloquante (1:1) à 400Gb/s.
* Cette sous-grappe est conçue pour les tâches massivement parallèles. 

2. Sous-grappe de GPU

* 244GPU fournis par 61&nbsp;nœuds de calcul GPU. 
* Chaque nœud de calcul GPU est équipé de 4&nbsp;GPU NVIDIA H100 (SXM) avec 80GB de VRAM dédiée.
* Chaque nœud de calcul GPU a 96&nbsp;cœurs provenant d'un processeur AMD EPYC 9654 à 96&nbsp;cœurs (Zen 4, ou Genoa) cadencé à 2,4GHz (fréquence de base).
* Les nœuds ont une connexion InfiniBand NDR non bloquante (1:1) de 800Gb/s, soit 200Gb/s par GPU.
* Dispose d'un nœud de connexion dédié (trig-login01) avec 4&nbsp;GPU NVIDIA H100 (SXM).
* Cette sous-grappe est optimisée pour l'IA, l'apprentissage machine  et les charges de travail scientifiques accélérées. 

3. Système de stockage

* Stockage NVMe VAST unifié de 29PB pour toutes les charges de travail
* Utilise uniquement de la mémoire flash pour des performances constantes
* Accessible en tant que système de fichiers parallèle partagé standard

<span id="Getting_started_on_Trillium"></span>
= Avant de commencer =

Vous devez posséder un compte [https://ccdb.alliancecan.ca CCDB] actif auprès de l'Alliance de recherche numérique du Canada. Vous pourrez ensuite demander l'accès à Trillium en sélectionnant ''Ressources-->Accès aux systèmes-->onglet HPC''. Cliquez sur ''Trillium'' et sur ''Je demande l'accès''. Il faut environ une heure pour que votre compte soit créé et que vous puissiez utiliser Trillium.

Prenez bien connaissance de la présente page. La page [[Frequently Asked Questions/fr|Foire aux questions]] est aussi une ressource utile. Si vous avez besoin d'aide ou si vous avez des questions, n'hésitez pas à nous écrire à [mailto:trillium@tech.alliancecan.ca trillium@tech.alliancecan.ca].

<span id="Logging_in"></span>
==Se connecter==

Comme pour tous les systèmes de SciNet et de l'Alliance, l'accès s'effectue via [[SSH/fr|SSH]]. De plus, pour Trillium en particulier, l'authentification est uniquement autorisée via des clés SSH téléversées dans [https://ccdb.alliancecan.ca CCDB]. Pour savoir comment générer votre paire de clés SSH, téléverser et utiliser vos clés SSH, voir [[SSH Keys/fr| Clés SSH]].

Trillium utilise Rocky Linux 9.6, un système d'exploitation de type Linux. Vous devez connaître l'interpréteur Linux pour travailler sur Trillium. Si ce n'est pas le cas, nous vous conseillons de lire [[Linux introduction/fr|Introduction à Linux]], de vous inscrire à une [https://explora.alliancecan.ca/events?include_expired=true&keywords=Shell formation sur l'interpréteur Linux] ou de suivre un [[Self-paced courses/fr| tutoriel de formation autonome]].

Vous pouvez utiliser [[SSH/fr|SSH]] en ouvrant une fenêtre de terminal (par exemple, en vous [[Connecting with PuTTY/fr| connectant avec PuTTY]] sous Windows, ou avec [[Connecting with MobaXTerm/fr|MobaXTerm]]), puis en vous connectant via SSH aux nœuds de connexion Trillium avec vos identifiants CCDB.

* Pour vous connecter à l'un des nœuds de connexion de la sous-grappe de CPU, utilisez la commande
<pre>
$ ssh -i /PATH/TO/SSH_PRIVATE_KEY  MYALLIANCEUSERNAME@trillium.scinet.utoronto.ca
</pre>

* Pour vous connecter à l'un des nœuds de connexion de la sous-grappe de GPU, utilisez la commande
<pre>
$ ssh -i /PATH/TO/SSH_PRIVATE_KEY  MYALLIANCEUSERNAME@trillium-gpu.scinet.utoronto.ca
</pre>

où <code>/PATH/TO/SSH_PRIVATE_KEY</code> est le chemin de votre clé SSH privée et <code>MYALLIANCEUSERNAME</code> est votre nom d'utilisateur CCDB.

'''Remarques'''
* Les nœuds de connexion de Trillium vous permettent de développer, de modifier, de compiler, de préparer et de soumettre des tâches.
* Les nœuds de connexion CPU et GPU ne font pas partie des nœuds de calcul, mais ils ont la même architecture, le même système d'exploitation et la même pile logicielle que les nœuds de calcul CPU et GPU.
* Vous pouvez vous connecter via SSH d'un nœud de connexion à un autre en utilisant leurs noms d'hôte internes <code>tri-login01, ..., tri-login06</code> et <code>trig-login01</code> (ce dernier étant le nœud de connexion GPU).
* L'option <code>-Y</code> active la redirection X11, ce qui permet aux programmes graphiques sur Trillium d'ouvrir des fenêtres sur votre ordinateur local. 
* Pour exécuter des tâches sur les nœuds de calcul, vous devez soumettre une tâche en lot.

'''Sur les nœuds de connexion, vous ne pouvez pas'''

* exécuter des tâches à forte consommation de mémoire;
* exécuter des entraînements parallèles ou des processus hautement multifils;
* exécuter des calculs de longue durée (ne dépassez pas quelques minutes);
* exécuter des tâches intensives, comme des opérations avec plusieurs I/O ou des simulations.

Si vous ne parvenez pas à vous connecter,
* vérifiez d'abord [https://status.alliancecan.ca l'état du système],
* assurez-vous que votre compte [https://ccdb.alliancecan.ca CCDB] est actif,
* assurez-vous que votre clé publique a été téléversée (au format openssh) dans CCDB
* vérifiez que vous avez demandé l'accès sur la page [https://ccdb.alliancecan.ca/me/access_systems Accès aux systèmes].

L'accès à Trillium via Open OnDemand est prévu pour bientôt. En attendant, vous pouvez toujours accéder à notre déploiement Open OnDemand existant en suivant les directives de notre guide [https://docs.scinet.utoronto.ca/index.php/Open_OnDemand_Quickstart Open OnDemand Quickstart].

<span id="Storage"></span>
==Stockage==

Trillium dispose d'un système de stockage unifié de haute performance basé sur la plateforme VAST, avec les répertoires suivants&nbsp;:

* <code>/home</code> – pour les configurations et fichiers personnels
* <code>/scratch</code> – espace de stockage personnel temporaire haute vitesse pour les données des tâches 
* <code>/project</code> – espace partagé pour les projets d'équipe et la collaboration

Pour plus de commodité, l'emplacement du niveau supérieur de vos répertoires /home et /scratch est disponible dans les variables d'environnement $HOME et $SCRATCH, tandis que la variable $PROJECT pointe vers votre répertoire dans /project.  

Dans le cas où vous participez à plusieurs projets, $PROJECT pointe vers votre dernier projet dans l'ordre alphabétique (souvent celui associé à une allocation). Vous trouverez cependant tous les répertoires de niveau supérieur des projets auxquels vous avez accès dans <code>$HOME/links/projects</code>, à côté d'un lien <code>$HOME/links/scratch</code> pointant vers <code>$SCRATCH</code>. Si vous ne voyez pas le répertoire <code>$HOME/links</code> dans votre compte, vous pouvez le créer avec la commande
<pre>
$ trisetup
</pre>
Le contenu de <code>$HOME/links/projects</code> sera automatiquement mis à jour lorsque vous quitterez ou joindrez des projets.

Sur [[Using nearline storage/fr|HPSS]] (le système /nearline qui sera attaché à Trillium), une variable d'environnement appelée <code>$ARCHIVE</code> pointera vers l'emplacement de votre répertoire de niveau supérieur, le cas échéant.

Le tableau ci-dessous indique l'espace disponible et les politiques pour chaque emplacement.

{| class="wikitable"
! emplacement
! quota
! délai d'expiration
! sauvegarde
! sur les nœuds de connexion
! sur les nœuds de calcul
|-
| $HOME
| 100GB par utilisateur
| aucun
| oui
| oui
| lecture seule
|-
| $SCRATCH
| 25TB par utilisateur<sup>*</sup>
| à déterminer<sup>*</sup>
| non
| oui
| oui
|-
| $PROJECT
| par allocation de groupe
| aucun
| oui
| oui
| lecture seule
|-
| $ARCHIVE
| par allocation de groupe
| aucun
| double copie
| non
| non
|}
<small><sup>*</sup>Les politiques pour SCRATCH ne sont pas définitives.</small>

<span id="Software"></span>
== Logiciels ==

Trillium utilise des [[Using modules|modules d'environnement]] pour gérer les compilateurs, les bibliothèques et autres progiciels. Les modules modifient dynamiquement votre environnement (par exemple, code>PATH</code>, <code>LD_LIBRARY_PATH</code>) afin que vous puissiez accéder sans problème à différentes versions des logiciels.

Commandes fréquemment utilisées&nbsp;:

* <code>module load <module-name></code>, charge la version par défaut d'un paquet logiciel
* <code>module load <nom-module>/<version-module></code>, charge une version spécifique
* <code>module purge</code>, retire tous les modules actuellement chargés
* <code>module avail</code>, liste les modules disponibles pouvant être chargés
* <code>module list</code>, affiche les modules actuellement chargés
* <code>module spider</code> ou <code>module spider <nom-module></code>, recherche des modules et leurs versions

Abréviations utiles&nbsp;:

* <code>ml</code>, équivaut à <code>module list</code>
* <code>ml <module-name></code>, équivaut à  <code>module load <module-name></code>

Au  moment où vous vous connectez, seuls les modules <code>CCconfig</code>, <code>gentoo/2023</code> et <code>mii</code> sont chargés, offrant les fonctionnalités de base du système d'exploitation. Pour obtenir un ensemble standard de compilateurs et de bibliothèques, comme sur nos autres grappes de calcul, chargez <code>StdEnv/2023</code>.

<span id="Tips_for_loading_software"></span>
== Conseils pour le chargement de logiciels ==

Une bonne gestion de votre environnement logiciel est essentielle pour éviter les conflits et garantir la reproductibilité. Voici quelques bonnes pratiques&nbsp;:

* Évitez de charger des modules dans votre fichier <code>.bashrc</code>, car cela peut entraîner des comportements inattendus, notamment dans les environnements non interactifs comme les tâches en lot ou les interpréteurs distants. 

* Chargez plutôt les modules manuellement, à partir d'un script distinct ou à l'aide de collections de modules. Cette approche offre un meilleur contrôle et contribue à préserver la propreté des environnements.

* Chargez les modules requis dans votre script de tâche, ce qui garantit que votre tâche s'exécute dans l'environnement logiciel attendu, quels que soient les paramètres de votre interpréteur interactif.

* Soyez explicite quant aux versions des modules. Des noms courts comme <code>gcc</code> chargeront le module par défaut (par exemple <code>gcc/12.3</code>) qui pourrait éventuellement changer. Spécifiez les versions complètes (par exemple <code>gcc/13.3</code>) pour une reproductibilité à long terme.

* Résolvez les dépendances avec <code>module spider</code>. Certains modules dépendent d'autres modules. Utilisez <code>module spider <module-name></code> pour savoir lesquels sont requis et comment les charger dans le bon ordre. Pour en savoir plus, voir [[Using_modules/fr#Sous_-_commande_spider |Sous-commande spider]].

<span id="Using_commercial_software"></span>
==  Applications commerciales ==

Certains aspects sont à considérer si vous voulez utiliser des logiciels commerciaux sur Trillium.

* Vous pouvez utiliser des logiciels commerciaux sur Trillium si vous possédez une licence valide. Si le logiciel nécessite un serveur de licences, vous pouvez vous y connecter en toute sécurité via [[SSH tunnelling/fr|un tunnel SSH]].

* Nous ne fournissons pas de licence spécifique à chaque utilisateur. En raison du nombre et de la diversité de nos utilisateurs, nous ne pouvons pas offrir des licences pour des paquets individuels ou spécialisés.

* Certains outils du commerce très utiles sont disponibles, tels que des compilateurs (Intel), bibliothèques mathématiques (MKL) et débogueurs (DDT).

* Nous pouvons vous aider. Si vous possédez une licence valide et avez besoin d'aide pour installer un logiciel, n'hésitez pas à nous contacter.

<span id="Testing_and_debugging"></span>
= Tests et débogage =

Avant de soumettre votre tâche, il est important de tester votre code pour vous assurer de son exactitude et des ressources nécessaires.

* '''Les tests légers''' peuvent être exécutés directement sur les nœuds de connexion. En règle générale, ils doivent&nbsp;:
** s'exécuter en quelques minutes
** utiliser au plus 1 à 2GB de mémoire
** utiliser entre 1 et 4 CPU
** utiliser au plus 1 GPU 

* Vous pouvez également exécuter le débogueur parallèle [[ARM_software/fr|ARM DDT]] sur les nœuds de connexion après l'avoir chargé avec <code>module load ddt-cpu</code> ou <code>module load ddt-gpu</code>.

* Pour les tests dépassant les limites du nœud de connexion ou nécessitant des ressources dédiées, demandez une tâche de débogage interactive à l'aide de la commande <code>debugjob</code> sur un nœud de connexion.
<pre>
$ debugjob
</pre>
Exécutée depuis un nœud de connexion CPU, cette commande vous permet d'utiliser un interpréteur interactif dans une session de calcul CPU pendant une heure. La commande <code>debugjob</code> exécutée depuis un nœud de connexion GPU ouvre une session interactive avec un GPU sur un nœud de calcul GPU (partagé) pendant deux heures. Le tableau suivant montre quelques variantes de cette commande permettant de demander davantage de ressources pour une session interactive. Notez que plus vous demandez de ressources, plus le temps d'exécution alloué est court, ce qui permet de garantir que la session interactive démarre presque toujours immédiatement.
{| class="wikitable"
!Commande
!Sous-grappe
!Nombre de cœurs
!Nombre de cœurs CPU
!Nombre de GPU
!Mémoire
!Temps d'exécution maximum
|-
|debugjob   ||CPU|| 1 ||192||0||  755GiB|| 60 minutes
|-
|debugjob 2 ||CPU|| 2 ||384||0||2x755GiB|| 30 minutes
|-
|debugjob<br />debugjob -g 1  ||GPU||1/4|| 24||1||  188GiB||120 minutes
|-
|debugjob 1<br />debugjob -g 4||GPU|| 1 || 96||4||  755GiB|| 30 minutes
|-
|debugjob 2<br />debugjob -g 8||GPU|| 2 ||192||8||2x755GiB|| 15 minutes
|}
L'environnement de l'interpréteur pour une tâche de débogage est similaire à celui que vous obtenez lorsque vous venez de vous connecter&nbsp;: seuls les modules standards sont chargés, aucun accès Internet, aucun accès en écriture aux systèmes de fichiers /home et /projet, et aucune soumission de tâche. Sachez que si vous souhaitez que la session hérite des modules chargés avant d'exécuter la commande de débogage, vous pouvez ajouter <code>--export=ALL</code> comme première option à debugjob.

* Si votre tâche de test nécessite plus de temps que ce qui est autorisé par debugjob, vous pouvez demander une session interactive depuis la file d'attente standard avec <code>salloc</code>. Pour les tâches de test CPU, la commande serait 
<pre>
$ salloc --export=NONE --nodes=N --time=M:00:00 [--ngpus-per-node=G] [--x11]
</pre>
où
* <code>N</code> est le nombre de nœuds  
* <code>M</code> est le nombre d'heures d'exécution de la tâche
* <code>G</code> est le nombre de GPU par nœud (le cas échéant) 
* <code>--x11</code> est requis uniquement pour les applications graphiques (par exemple [[ARM_software/fr|ARM DDT]]).

'''Remarque''' : Les tâches soumises avec <code>salloc</code> peuvent prendre plus de temps à démarrer qu'avec debugjob et sont comptabilisées dans votre allocation.

<span id="Submitting_jobs_to_the_scheduler"></span>
= Soumettez des tâches à l'ordonnanceur =

Une fois que votre code ou votre flux de travail est compilé et testé sur les nœuds de connexion de Trillium et que son bon fonctionnement est confirmé, vous pouvez soumettre des tâches sur la grappe. Ces tâches s'exécuteront sur les nœuds de calcul de Trillium et leur exécution sera gérée par l'ordonnanceur.

Trillium utilise SLURM comme ordonnanceur de tâches. Pour plus d'information sur l'interaction avec l'ordonnanceur, voyez [[Running jobs/fr|la page Slurm]].  

Pour soumettre une tâche, utilisez la commande <code>sbatch</code> sur un nœud de connexion.
<pre>
$ sbatch jobscript.sh
</pre>
Les tâches avec CPU doivent être soumises depuis les nœuds de connexion CPU, tandis que les tâches avec GPU doivent être soumises depuis le nœud de connexion GPU. Dans les deux cas, la commande est identique, mais les options du script sont différentes (voir ci-dessous).

La commande <code>sbatch</code> place votre tâche dans la file d'attente. Le script doit contenir des lignes commençant par <code>#SBATCH</code> spécifiant les ressources nécessaires (les options les plus courantes sont présentées ci-dessous). L'ordonnanceur exécutera ce script sur les nœuds de calcul lorsque votre tâche aura passé au début de la file d'attente et que les ressources seront disponibles. 

La priorité d'une tâche dans la file d'attente dépend des ressources demandées, du temps déjà passé dans la file d'attente, de l'utilisation récente, ainsi que du compte SLURM avec lequel la tâche a été soumise. Les comptes SLURM correspondent aux [[Frequently_Asked_Questions_about_the_CCDB/fr#RAP_(resource_allocation_project)| RAP (Resource Allocation Project)]]&nbsp;:
* Chaque chercheuse principale ou chercheur principal dispose d'au moins un RAP, le RAP par défaut du service d'accès rapide. Les membres parrainés ont accès au compte SLURM correspondant dont le nom commence par <code>def-</code>.
* Une chercheuse principale ou un chercheur principal disposant d'une allocation via concours dispose d'un RAP supplémentaire, auquel des utilisateurs peuvent être ajoutés. Le nom des comptes SLURM correspondants commence généralement par <code>rrg-</code> ou <code>rpp-</code>. Notez que les RAC sont liés à un système; par exemple, un RAC pour Nibi ne peut pas être utilisé sur Trillium.

<span id="Trillium_specific_restrictions"></span>
== Restrictions particulières à Trillium ==

Trillium étant conçue pour les tâches massivement parallèles, elle présente certaines différences par rapport aux grappes à usage général ([[Fir/fr|Fir]], [[Nibi/fr|Nibi]], [[Narval]], [[Rorqual]]), que nous allons maintenant aborder.

<span id="Job_output_must_be_written_to_the_scratch_file_system"></span>
=== Les données de sortie doivent être écrites dans /scratch ===

/scratch est un système de fichiers parallèle rapide que vous devriez utiliser pour écrire les données pendant l'exécution des tâches. Ceci est nécessaire parce que /home et /project sont en lecture seulement sur les nœuds de calcul.

En plus de vous assurer que votre application écrit dans le répertoire /scratch, vous devez généralement soumettre vos tâches depuis votre répertoire <code>$SCRATCH</code> (et non $HOME ou $PROJECT). L'emplacement par défaut des fichiers de sortie de l'ordonnanceur se trouve dans le répertoire à partir duquel vous soumettez vos tâches. Par conséquent, si ce répertoire n'est pas dans /scratch, les fichiers de sortie ne seront pas écrits.

<span id="Default_scheduler_account"></span>
=== Compte par défaut pour l'ordonnanceur ===

Les tâches s'exécuteront avec l'allocation attribuée à votre groupe ou, à défaut, avec une allocation du service d'accès rapide. Vous pouvez contrôler ceci explicitement en spécifiant le compte avec l'option <code>--account=ACCOUNT_NAME</code> dans votre script de tâche ou votre commande de soumission. Si vous disposez de plusieurs allocations, il est fortement recommandé de spécifier le nom du compte.

<span id="No_job_submission_from_jobs"></span>
=== Tâche soumise par une autre tâche ===

Les tâches ne peuvent pas être soumises depuis les nœuds de calcul (ni depuis les nœuds de copie). Ceci évite de générer accidentellement de nombreuses tâches et de surcharger l'ordonnanceur et le processus de sauvegarde.

<span id="Whole_node_or_whole_gpu_scheduling"></span>
=== Ordonnancement pour nœud entier ou GPU entier ===

Il n'est pas possible de demander un nombre particulier de cœurs sur Trillium. Sur la sous-grappe de CPU, toutes les tâches doivent utiliser des nœuds entiers. Ceci signifie que la taille minimale d'une tâche CPU est de 192&nbsp;cœurs, que vous devez utiliser efficacement. Si vous exécutez des tâches séquentielles ou à faible nombre de cœurs, vous devez tout de même utiliser les 192&nbsp;cœurs du nœud en regroupant plusieurs tâches indépendantes dans un seul script. Pour des exemples, consultez [[GNU Parallel/fr|GNU Parallel]] et [[META-Farm: Advanced features and troubleshooting/fr#Mode_WHOLE_NODE|cette section de la page META-Farm (fonctions avancées)]].

Si votre tâche sous-utilise les cœurs, notre équipe peut vous aider à optimiser votre flux de travail, ou vous pouvez [mailto:trillium@tech.alliancecan.ca nous contacter] pour obtenir de l'aide.

Sur la sous-grappe de GPU, chaque nœud contient 4&nbsp;GPU. L'ordonnanceur vous permet de demander soit un nombre entier de nœuds, soit un seul GPU. Ce dernier équivaut à un quart de nœud, avec 24&nbsp;cœurs et environ 188&nbsp;GiB de RAM. Il est important d'utiliser le GPU efficacement. Trillium ne prend pas en charge MIG comme sur les autres grappes (MIG permet de planifier une fraction de GPU), mais vous pouvez utiliser [[Hyper-Q / MPS/fr|HyperQ / MPS]] dans vos tâches.

<span id="Memory_requests_are_ignored"></span>
=== Quantité de mémoire allouée ===

N'indiquez pas la quantité de mémoire requise. Les tâches CPU reçoivent toujours  <code>N × 768GB </code> de RAM, où <code>N</code> est le nombre de nœuds et 768GB est la quantité de mémoire pour chaque nœud. Les tâches sur un nœud GPU entier obtiennent la même quantité de mémoire alors que celles sur un GPU unique obtiennent 1/4 de la mémoire, soit 188GiB.

<span id="Common_options_for_job_script"></span>
== Options fréquemment utilisées dans les scripts de tâches ==

Les options suivantes sont fréquemment utilisées&nbsp;:

{| class="wikitable"
!option
!short option
!résultat
!remarques
|-
|<code>--nodes</code>||<code>-N</code>||nombre de nœuds||il est recommandé de toujours inclure cette option
|-
|<code>--ntasks-per-node</code>|| ||nombre de tâches à lancer par srun/mpirun, par nœud||préférez cette option à <code>--ntasks</code>
|-
|<code>--ntasks</code>||<code>-n</code>||nombre de tâches à lancer par srun/mpirun||
|-
|<code>--cpus-per-task</code>||<code>-c</code>||nombre de cœurs par tâche|| habituellement pour les fils (OpenMP)
|-
|<code>--time</code>||<code>-t</code>||durée de la tâche||
|-
|<code>--job-name</code>||<code>-J</code>||nom de la tâche||
|-
|<code>--output</code>||<code>-o</code>||fichier de sortie||peut être répété (par exemple avec %j pour l'identifiant de la tâche)
|-
|<code>--mail-type|| ||quand envoyer un courriel (par exemple BEGIN, END, FAIL, ALL)
|-
|<code>--gpus-per-node|| || nombre de GPU à utiliser sur chaque nœud || les valeurs pour la sous-grappe de GPU sont 1&nbsp;et&nbsp;4
|-
|<code>--partition</code>||<code>-p</code>||partition à laquelle soumettre la tâche||(voir les partitions disponibles ci-dessous)
|-
|<code>--account</code>||<code>-A</code>||compte slurm à utiliser||dans plusieurs cas, ceci est automatique sur Trillium
|-
|<code>--mem<code>|| || quantité de mémoire||ne s'applique pas (vous obtenez toute la mémoire)
|}

Ces options doivent être dans des lignes de commentaire distinctes en haut du script de tâche (mais après <code>#!/bin/bash</code>), préfixées par <code>#SBATCH</code>.  Elles peuvent également être utilisées comme options de ligne de commande pour salloc. Vous trouverez ci-dessous quelques exemples de scripts de tâches.

Pour plus d'information, voyez [[Running jobs/fr|Exécuter des tâches]] et [https://slurm.schedmd.com/sbatch.html la documentation sur SLURM].

<span id="Submitting_jobs_on_the_CPU_subcluster"></span>
== Soumettre des tâches sur la sous-grappe de CPU ==

<span id="Partitions_and_limits"></span>
=== Partitions et limites ===

La taille et la durée de vos tâches, leur nombre d'exécutions et leur nombre de mises en file d'attente sont limités. L'appartenance ou non d'un utilisateur à un groupe disposant d'une allocation via concours (pour un groupe de recherche ou pour une plateforme ou un portail) est importante. La partition d'exécution de la tâche est également importante. Dans le langage de l'ordonnanceur Slurm, le terme ''partition'' est utilisé pour décrire les cas d'utilisation. Vous spécifiez la partition avec le paramètre <code>-p</code> de <code>sbatch</code> ou <code>salloc</code>, mais si vous n'en spécifiez pas, votre tâche s'exécutera dans la partition <code>compute</code>, ce qui est le cas le plus courant.

{| class="wikitable"
!Utilisation
!Partition
!Limite pour les tâches en cours
!Limite pour les tâches soumises et en cours
!Plus petite taille des tâches
!Plus grande taille des tâches
!Plus court temps d'exécution
!Plus long temps d'exécution
|-
|tâches de calcul ||compute|| 150 || 500 || 1&nbsp;nœud (192&nbsp;cœurs) || par défaut, &nbsp;10&nbsp;nœud&nbsp;(1920&nbsp;cœurs) <br> avec&nbsp;une&nbsp;allocation,&nbsp;128&nbsp;nœuds &nbsp;(24576&nbsp;cœurs)<sup>*</sup>|| 15 minutes || 24 heures
|-
|Tests ou débogage || debug || 1 || 1 || 1 nœud (192&nbsp;cœurs) || 2&nbsp;nœuds&nbsp;(384&nbsp;cœurs)|| s.o. || 1 heure
|}
<small><sup>*</sup> Maximum recommandé; si vous avez des tâches plus exigeantes, contactez-nous.</small>

Même si vous respectez ces limites, vos tâches devront passer par la file d'attente. Le temps d'attente dépend de nombreux facteurs, tels que la taille de l'allocation pour votre groupe, la quantité de ressources utilisées récemment, le nombre de nœuds et le temps d’exécution demandés, ainsi que le nombre total de tâches en attente.

<span id="Example:_MPI_job"></span>
=== Exemple d'une tâche MPI ===

<source lang="bash">
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=192
#SBATCH --time=01:00:00
#SBATCH --job-name=mpi_job
#SBATCH --output=mpi_output_%j.txt
#SBATCH --mail-type=FAIL

cd $SLURM_SUBMIT_DIR

module load StdEnv/2023
module load gcc/12.3
module load openmpi/4.1.5

source /scinet/vast/etc/vastpreload-openmpi.bash # important if doing MPI-IO

mpirun ./mpi_example
</source>

Depuis un nœud de connexion, à partir de votre répertoire <code>$SCRATCH</code>, soumettez ce script avec la commande
<pre>
$ sbatch mpi_job.sh
</pre>

<ul>
<li>La première ligne indique qu'il s'agit d'un script bash.</li>
<li>Les lignes commençant par <code>#SBATCH</code> sont dirigées vers l'ordonnanceur.</li>
<li><code>sbatch</code> lit ces lignes comme étant une requête de tâche qu'elle nomme <code>mpi_job</code>.</li>
<li>Ici, l'ordonnanceur recherche deux&nbsp;nœuds pour exécuter chacun 192&nbsp;tâches pendant une&nbsp;heure.</li>
<li>Une fois ces nœuds alloués, Slurm exécute le script  qui effectue les opérations suivantes&nbsp;:
<ul>
<li>accéder au répertoire de soumission,</li>
<li>charger les modules,</li>
<li>précharger une bibliothèque optimisant MPI-IO pour le système de fichiers VAST; si vous utilisez intelmpi au lieu d'openmpi, utilisez plutôt <code>source /scinet/vast/etc/vastpreload-intelmpi.bash</code>,</li>
<li>exécuter l'application <code>mpi_example</code> (l'ordonnanceur indiquera à <code>mpirun</code> ou <code>srun</code> le nombre de processus à exécuter).</li>
</ul>
</li>
</ul>

<span id="Example:_OpenMP_job"></span>
=== Exemple d'une tâche OpenMP ===

<source lang="bash">
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=192
#SBATCH --time=01:00:00
#SBATCH --job-name=openmp_job
#SBATCH --output=openmp_output_%j.txt
#SBATCH --mail-type=FAIL

cd $SLURM_SUBMIT_DIR

module load StdEnv/2023
module load gcc/12.3

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

./openmp_example
# or "srun ./openmp_example"
</source>

À partir de votre répertoire <code>$SCRATCH</code>, soumettez ce script depuis un nœud de connexion CPU avec la commande
<pre>
$ sbatch openmp_job.sh
</pre>

<ul>
<li>La première ligne indique qu'il s'agit d'un script bash.</li>
<li>Les lignes commençant par <code>#SBATCH</code> sont des directives pour l'ordonnanceur.</li>
<li><code>sbatch</code> lit ces lignes comme étant une requête de tâche qu'elle nomme <code>openmp_job</code>.</li>
<li>Ici, l'ordonnanceur recherche un nœud avec192&nbsp;CPU pour exécuter une tâche pendant une&nbsp;heure.</li>
<li>Une fois le nœud alloué, Slurm exécute le script  qui effectue les opérations suivantes&nbsp;:
  <ul>
    <li>changer le répertoire de soumission,</li>
    <li>charger les modules,</li>
    <li>configurer <code>OMP_NUM_THREADS</code> pour le nombre de CPU demandés,</li>
    <li>exécuter l'application <code>openmp_example</code>.</li>
  </ul>
</li>
</ul>

<span id="Example:_hybrid_MPI/OpenMP_job"></span>
=== Exemple d'une tâche hybride MPI/OpenMP ===

<source lang="bash">
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=48
#SBATCH --cpus-per-task=4
#SBATCH --time=01:00:00
#SBATCH --job-name=hybrid_job
#SBATCH --output=hybrid_output_%j.txt
#SBATCH --mail-type=FAIL

cd $SLURM_SUBMIT_DIR

module load StdEnv/2023
module load gcc/12.3
module load openmpi/4.1.5

export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export OMP_PLACES=cores
export OMP_PROC_BIND=true

export CORES_PER_L3CACHE=8
export RANKS_PER_L3CACHE=$(( $CORES_PER_L3CACHE / $OMP_NUM_THREADS ))  # this works up to 8 threads 

source /scinet/vast/etc/vastpreload-openmpi.bash # important if doing MPI-IO

mpirun --bind-to core --map-by ppr:$RANKS_PER_L3CACHE:l3cache:pe=$OMP_NUM_THREADS ./hybrid_example

</source>

Depuis un nœud de connexionÀ partir de votre répertoire <code>$SCRATCH</code>, soumettez ce script avec la commande
<pre>
$ sbatch hybrid_job.sh
</pre>

<ul>
<li>La première ligne indique qu'il s'agit d'un script bash.</li>
<li>Les lignes commençant par <code>#SBATCH</code> sont des directives pour l'ordonnanceur.</li>
<li><code>sbatch</code> lit ces lignes comme étant une requête de tâche qu'elle nomme <code>hybrid_job</code>.</li>
<li>Ici, l'ordonnanceur recherche deux&nbsp;nœuds pour exécuter chacun 48&nbsp;tâches avec chacune 4&nbsp;fils pendant une&nbsp;heure.</li>
<li>Une fois les nœuds alloués, Slurm exécute le script  qui effectue les opérations suivantes&nbsp;:
<ul>
<li>changer le répertoire de soumission,</li>
<li>charger les modules,</li>
<li>précharger une bibliothèque qui adapte MPI-IO pour le système de fichiers  VAST; si vous utilisez intelmpi au lieu d'openmpi, utilisez plutôt <code>source /scinet/vast/etc/vastpreload-intelmpi.bash</code>,</li>
<li>exécuter l'application <code>hybrid_example</code>; même si l'ordonnanceur indique à <code>mpirun</code> combien de processus il faut exécuter, il faut quand même distribuer également les processus et les fils sur l'ensemble des cœurs,  ce qui est fait par l’option --map-by. Si vous utilisez plus de 8 fils par processus (tâche ou rang MPI) mais au plus 24, changez ''l3cache'' pour ''numa''. Si vous utilisez plus de 24 fils par processus, changez pour ''socket''.</li>
</ul>
</li>
</ul>

</ul>
</li>
</ul>

<span id="Submitting_jobs_for_the_GPU_subcluster"></span>
== Soumettre des tâches sur la sous-grappe de GPU ==

<span id="Partitions_and_limits"></span>
=== Partitions et limites ===

Tout comme pour la sous-grappe de CPU, la taille et la durée des tâches, le nombre de tâches exécutables et le nombre de tâches mises en file d'attente sont limités, ainsi que l'appartenance ou non d'un utilisateur à un groupe disposant d'une allocation via concours. La sous-grappe de GPU comporte plus de partitions que la sous-grappe de CPU pour pouvoir prendre en charge la planification par GPU plutôt que par nœud (chaque nœud dispose de 4&nbsp;GPU). 

Sur Trillium, vous ne pouvez demander qu'un seul GPU ou un multiple de quatre GPU. Vous ne pouvez pas demander --gpus-per-node=2 ou 3, ni utiliser la technologie MIG de NVIDIA pour allouer une fraction d'un GPU. Dans une tâche, vous pouvez utiliser MPS (Multi-Process Service) de NVIDIA pour partager un GPU entre les processus exécutés dns la tâche.

* Pour une tâche avec un seul GPU, utilisez <code>--gpus-per-node=1</code>.
* Pour une tâche avec un nœud GPU entier, utilisez <code>--gpus-per-node=4</code>.

{| class="wikitable"
!Utilisation
!Partition
!Limite pour les tâches en cours
!Limite pour les soumises et les tâches en cours
!Plus petite taille des tâches
!Plus grande taille des tâches
!Plus court temps d'exécution
!Plus long temps d'exécution
|-
|calcul avec GPU ||calcul|| 150 || 500 || 1/4 nœud (24&nbsp;cœurs / 1GPU) || par défaut, 5&nbsp;nœuds&nbsp;(480&nbsp;cœurs /20 GPU) <br> avec une allocation:&nbsp;25&nbsp;nœuds&nbsp;(2400&nbsp;cœurs /100 GPU)|| 15 minutes || 24 heures
|-
|test avec GPU || débogage|| 1 || 1 || 1/4 nœud (24 cœurs / 1 GPU) || 2 nodes (192 cœurs / 8 GPU)|| s.o. || 2 heures (1 GPU) - 30 minutes (8 GPU)
|}

Même si vous respectez ces limites, vos tâches devront passer par la file d'attente. Le temps d'attente dépend de nombreux facteurs, tels que la taille de ressources pour votre groupe, la quantité de l'allocation utilisée récemment, le nombre de nœuds et le temps d'exécution demandés, ainsi que le nombre total des tâches en attente.

<span id="Example:_Single-GPU_Job"></span>
=== Exemple d'une tâche avec un seul GPU ===

<source lang="bash">
#!/bin/bash
#SBATCH --job-name=single_gpu_job         # Job name
#SBATCH --output=single_gpu_job_%j.out    # Output file (%j = job ID)
#SBATCH --nodes=1                         # Request 1 node
#SBATCH --gpus-per-node=1                 # Request 1 GPU
#SBATCH --time=00:30:00                   # Max runtime (30 minutes)

# Load modules
module load StdEnv/2023
module load cuda/12.6
module load python/3.11.5

# Activate Python environment (if applicable)
source ~/myenv/bin/activate

# Check GPU allocation
srun nvidia-smi

# Run your workload
srun python my_script.py
</source>

<span id="Example:_Whole-Node_(4_GPUs)_Job"></span>
===  Exemple : Tâche avec un nœud entier (4 GPU)  ===

<source lang="bash">
#!/bin/bash
#SBATCH --job-name=whole_node_gpu_job
#SBATCH --output=whole_node_gpu_job_%j.out
#SBATCH --nodes=1
#SBATCH --gpus-per-node=4
#SBATCH --time=02:00:00

module load StdEnv/2023
module load cuda/12.6
module load python/3.11.5

# Activate Python environment (if applicable)
source ~/myenv/bin/activate

srun python my_distributed_script.py
</source>

<span id="Example:_Multi-Node_GPU_Job"></span>
=== Exemple d'une tâche avec plusieurs nœuds GPU ===

<source lang="bash">
#!/bin/bash
#SBATCH --job-name=multi_node_gpu_job
#SBATCH --output=multi_node_gpu_job_%j.out
#SBATCH --nodes=2                        # Request 2 full nodes
#SBATCH --gpus-per-node=4                # 4 GPUs per node (full node)
#SBATCH --time=04:00:00

module load StdEnv/2023
module load cuda/12.6
module load openmpi/4.1.5

# Check all GPUs allocated
srun nvidia-smi

# Activate Python environment (if applicable)
source ~/myenv/bin/activate

# Example: run a distributed training job with 8 GPUs (2 nodes × 4 GPUs)
srun python train_distributed.py
</source>

<span id="Best_Practices_for_GPU_Jobs"></span>
=== Meilleures pratiques pour les tâches avec GPU ===

* N'utilisez pas <code>--mem</code>; la mémoire est fixe par GPU (192GB) ou par nœud (768GB).
* Indiquez toujours le nombre de nœuds et <code>--gpus-per-node=4</code> pour les tâches sur un nœud entier ou sur plusieurs nœuds.
* Chargez uniquement les modules nécessaires (voir [[Using_modules/fr|Utiliser les modules]]).
* Pour une meilleure reproductibilité, soyez explicite quant aux versions des logiciels (par exemple, <code>cuda/12.6</code> plutôt que simplement <code>cuda</code>).
* Testez sur un seul GPU avant de passer à plusieurs GPU ou nœuds.
* Surveillez l'utilisation avec <code>nvidia-smi</code> pour vous assurer que les GPU sont pleinement utilisés.

<span id="Monitoring"></span>
=Suivi=

<span id="Monitoring_the_queue"></span>
== Suivi de la file ==

Une fois votre tâche soumise à la file d'attente, vous pouvez surveiller son état et ses performances à l'aide des commandes SLURM suivantes&nbsp;:

<ul>
<li><p><code>squeue</code> montre toutes les tâches dans la file; pour voir uniquement vos propres tâches, utilisez <code>squeue -u $USER</code>.</p></li>
<!-- <li><p><code>sqc</code> version particulière à SciNet, plus rapide que <code>squeue</code> qui montre un instantané caché de la queue.</p></li> -->
<li><p><code>squeue -j JOBID</code> montre l'état courant d'une tâche en particulier; pour les détails sur une tâche, incluant les nœuds alloués, les ressources et les indicateurs pour la tâche, utilisez <code>scontrol show job JOBID</code>.</p>
</li>

<li><p><code>squeue --start -j JOBID</code> donne une estimation du moment où une tâche en attente devrait démarrer. Notez que cette estimation est souvent inexacte et peut varier en fonction de la charge du système et des priorités.</p></li>

<li><p><code>scancel JOBID</code> annule une tâche déjà soumise</p></li>

<li><p><code>jobperf JOBID</code> produit un instantané en temps réel de l'utilisation du CPU et de la mémoire pendant que la tâche est exécutée.</p></li>

<li><p><code>sacct</code> affiche des informations sur vos tâches passées, notamment l'heure de début, l'heure d'exécution, l'utilisation du nœud et l'état de sortie.</p></li>
</ul>

Pour plus d'information sur le suivi des tâches, voir [[Running jobs/fr |la page sur Slurm]].

<span id="Monitoring_running_and_past_jobs"></span>
== Suivi des tâches en cours et des tâches passées ==

Une fois que votre tâche est terminée, elle est retirée de la file; ainsi les commandes relatives à la file (par exemple <code>squeue</code> et <code>sacct</code>) ne trouveront plus la tâche.

Vos tâches passées et leur utilisation des ressources peuvent être consultées via le portail [https://my.scinet.utoronto.ca my.SciNet]. Ce portail enregistre des informations sur toutes les tâches, y compris les données de performance collectées toutes les deux minutes pendant leur exécution. 

<span id="Quick_Reference_for_Common_Commands"></span>
= Commandes fréquemment utilisées =

{| class="wikitable"
! Commande !! Description
|-
| sbatch <script> || soumet un script pour une tâche en lot
|-
| squeue [-u $USER] || montre les tâches dans la file (toutes les tâches ou uniquement les vôtres)
|-
| scancel <JOBID> || annule une tâche
|-
| sacct || montre les données de <i>comptabilité</i> des tâches récemment exécutées
|-
| module load <module> || charge un module logiciel
|-
| module list || liste les modules chargés
|-
| module avail || liste les modules disponibles
|-
| module spider <module> || recherche les modules et leurs dépendances
|-
| debugjob [N] || demande une courte tâche de débogage (sur N nombre de nœuds)
|-
| diskusage_report || vérifie les quotas de stockage
|-
| jobperf <JOBID> || fait le suivi d'un CPU et de la mémoire utilisée pour une tâche en cours 
|-
| nvidia-smi || vérifie l'état d'un GPU (sur un nœud GPU)
|}