<languages />
 
Plusieurs logiciels sont incapables d'exploiter pleinement les GPU modernes tels que les [https://www.nvidia.com/en-us/data-center/a100/ A100] et [https://www.nvidia.com/en-us/data-center/h100/ H100] de NVidia. La technologie multi-instances [https://www.nvidia.com/en-us/technologies/multi-instance-gpu/ (MIG pour <i>Multi-Instance GPU</i>)] permet de partitionner un seul GPU en plusieurs instances, faisant ainsi de chacune un GPU virtuel complètement indépendant. Chacune des instances de GPU dispose alors d'une portion des ressources de calcul et de la mémoire du GPU d'origine, le tout détaché des autres instances par des protections sur puce.

Les instances d'un GPU sont moins gourmandes, ce qui se reflète par une utilisation moins rapide de votre priorité de calcul. Les tâches soumises sur une instance plutôt que sur un GPU entier utilisent moins de la priorité qui vous est allouée et vous pourrez exécuter plus de tâches avec un temps d'attente plus court.

= Pourquoi choisir un GPU entier ou une instance de GPU=
Les tâches qui utilisent moins de la moitié de la puissance de calcul d'un GPU entier et moins de la moitié de la mémoire GPU disponible doivent être évaluées et testées sur une instance. Dans la plupart des cas, ces tâches s'exécutent tout aussi rapidement sur une instance et consomment moins de la moitié des ressources de calcul.

Voir [[Multi-Instance GPU/fr#Quand_migrer_une_tâche_sur_une_instance|Quand migrer une tâche sur une instance]] ci-dessous.

= Limites de la technologie =
[https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#application-considerations  La technologie MIG ne prend pas en charge] la [https://developer.nvidia.com/docs/drive/drive-os/6.0.8.1/public/drive-os-linux-sdk/common/topics/nvsci_nvsciipc/Inter-ProcessCommunication1.html communication interprocessus CUDA] qui optimise le transfert de données via NVLink et NVSwitch. Cette limite diminue aussi l'efficacité de la communication entre les instances. En conséquence, <b>le lancement d'un exécutable sur plusieurs MIG à la fois n'améliore pas la performance et doit être évité.</b>

Veuillez noter que les API graphiques ne sont pas prises en charge (par exemple OpenGL, Vulkan, etc.); voir [https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#application-considerations Application Considerations].

Les tâches avec GPU qui nécessitent de nombreux cœurs CPU par GPU peuvent également nécessiter un GPU entier au lieu d'une instance. Le nombre maximum de cœurs CPU par instance dépend du 
[[Allocations_and_compute_scheduling/fr#Ratios_dans_les_bundles|nombre maximum de cœurs CPU par GPU entier]] et des [https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#a100-profiles profils MIG qui sont configurés]. Ces deux caractéristiques varient d'une grappe à l'autre et d'un nœud GPU à l'autre.

= Configurations disponibles =
[https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html#supported-mig-profiles Plusieurs configurations et profils MIG sont possibles], mais les profils suivants dépendent du système&nbsp;:
* [[Narval#Instances _GPU|Narval|NVIDIA A100-40gb pour Narval]]
* [[Rorqual#Instances _GPU|NVIDIA H100-80gb pour Rorqual]]

Le nom du profil indique la taille de l'instance, par exemple <code>3g.20gb</code> est dotée de 20Go de mémoire GPU et sa performance est égale aux 3/8<sup>e</sup> de la performance de calcul d’un GPU entier. Le fait de nécessiter moins de puissance diminue l’impact sur votre allocation et sur la priorité assignée à vos tâches.

Pour la liste de tous les gabarits (et le nom complet des GPU) sur une grappe en particulier, lancez

{{Command|sinfo -o "%G"{{!}}grep gpu{{!}}sed 's/gpu://g'{{!}}sed 's/,/\n/g'{{!}}cut -d: -f1{{!}}sort{{!}}uniq}}

Pour connaître le maximum recommandé de cœurs CPU et de mémoire système par instance, voir
[[Allocations_and_compute_scheduling/fr#Ratios_dans_les_bundles|le tableau des ratios]].

<span id="Job_examples"></span>
= Exemples =

Pour demander une instance de 20Go à 3/8 de la puissance pour une tâche interactive d’une durée d’une (1) heure&nbsp;:
 
{{Command2
|prompt=[name@narval ~]$
|salloc --account{{=}}def-someuser --gpus{{=}}a100_3g.20gb:1 --cpus-per-task{{=}}2 --mem{{=}}40gb --time{{=}}1:0:0
}}

Pour demander une instance de 20Go à 4/8 de la puissance pour un script de tâches en lot d’une durée de 24&nbsp;heures qui utilise le maximum recommandé de cœurs et de mémoire système&nbsp:

{{File
  |name=a100_4g.20gb_mig_job.sh
  |lang="sh"
  |contents=
#!/bin/bash
#SBATCH --account=def-someuser
#SBATCH --gpus=a100_4g.20gb:1 
#SBATCH --cpus-per-task=6    # There are 6 CPU cores per 3g.20gb and 4g.20gb on Narval.
#SBATCH --mem=62gb           # There are 62GB GPU RAM per 3g.20gb and 4g.20gb on Narval.
#SBATCH --time=24:00:00

hostname
nvidia-smi
}}

<span id="Finding_which_of_your_jobs_should_use_an_instance"></span>
= Quand migrer une tâche sur une instance =

L'historique de vos tâches est disponible sur  [[Portail|le portail d'utilisation de Narval (préparation en cours)]]. 

La consommation d’énergie est un bon indicateur de la puissance de calcul totale demandée au GPU. Par exemple, le travail suivant nécessitait un GPU&nbsp;A100 entier avec une enveloppe thermique (TDP) maximale de 400&nbsp;W, mais n'utilisait que 100&nbsp;W en moyenne, soit seulement 50&nbsp;W de plus que la consommation au repos&nbsp;:
 
[[File:ExampleGPUPower.png|400px|frame|left|Consommation d'énergie sur un GPU A100]] 
<br clear=all> <!-- This is to prevent the next section from filling to the right of the image. -->

Les fonctionnalités du GPU peuvent également fournir des informations sur son utilisation dans les cas où la consommation d'énergie n'est pas suffisante. Dans ce prochain exemple de tâche, le graphique d'utilisation du GPU confirme la conclusion du graphique de consommation d'énergie du GPU selon laquelle la tâche utilise moins de 25&nbsp;% de la puissance de calcul disponible d'un GPU&nbsp;A100 entier&nbsp;:
 
[[File:ExampleGPUUtilisation.png|400px|frame|left|Utilisation d'un GPU A100]]
<br clear=all> <!-- This is to prevent the next section from filling to the right of the image. -->

Il faut aussi tenir compte de la quantité maximale de mémoire GPU et de la quantité moyenne de cœurs CPU nécessaires pour exécuter la tâche. Dans le prochain exemple, la tâche utilise un maximum de 3Go de mémoire GPU sur les 40Go d'un GPU&nbsp;A100.
 
[[File:ExampleGPUMemory.png|400px|frame|left|Utilisation de la mémoire du GPU A100]]
<br clear=all> <!-- This is to prevent the next section from filling to the right of the image. -->

La tâche a aussi été lancée en utilisant un seul cœur de processeur. En tenant compte de ces trois métriques, nous voyons que la tâche pourrait facilement s'exécuter sur une instance de 3&nbsp;g.20&nbsp;Go ou de 4&nbsp;g.20&nbsp;Go avec de la puissance et de la mémoire à revendre. 

Un autre moyen de [[Running jobs/fr#Surveillance_d'une_tâche_en_cours |surveiller l'utilisation d'une tâche en cours d'exécution]] consiste à se connecter au nœud sur lequel la tâche se trouve et utiliser <code>nvidia-smi</code> pour lire les métriques du GPU en temps réel. Cela ne fournira pas de valeurs maximales et moyennes pour la mémoire et la puissance de toute la tâche, mais pourrait être utile pour identifier une sous-utilisation du GPU.

<span id="Can_I_use_multiple_instances_on_the_same_GPU?"></span>
= Puis-je utiliser plusieurs instances sur le même GPU? =

Non. En principe, il est possible de le faire, mais nos systèmes ne prennent pas en charge cette fonctionnalité. Si vous voulez exécuter plusieurs tâches intépendantes sur un GPU, utilisez [[Hyper-Q_/_MPS/fr|MPS]] plutôt que MIG.