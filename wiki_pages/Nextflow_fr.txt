<languages />

[https://www.nextflow.io Nextflow] est un logiciel permettant d'exécuter des flux de travail scientifiques reproductibles. Le terme <i>Nextflow</i> est utilisé pour décrire à la fois le langage spécifique au domaine (DSL) dans lequel les pipelines sont écrits et le logiciel utilisé pour interpréter ces flux de travail.


== Utilisation ==
Chargez le module Nextflow avec <code>module load nextflow</code>.

Bien que vous puissiez créer votre propre flux de travail, vous pouvez également utiliser les pipelines  [https://nf-co.re/ nf-core] qui sont publiés. Nous décrivons ici une configuration simple qui vous permettra d'exécuter des pipelines nf-core sur nos systèmes et vous aidera à configurer correctement Nextflow pour vos propres pipelines.

Dans notre exemple, nous utilisons le pipeline <code>nf-core/rnaseq</code> pour les 5 étapes. 

* Étape 1, Préparer le fichier de configuration
* Étape 2, Installer nf-core
* Étape 3, Download the container image and pipeline
* Étape 4, Préparer les données en entrée
* Étape 5, Créer un script pour la tâche

<span id="Step_1:_Set_up_the_configuration_file"></span>
==== Étape 1, Préparer le fichier de configuration ====

<div class="mw-translate-fuzzy">
Vous pouvez obtenir de [https://github.com/nf-core/configs/blob/master/conf/alliance_canada.confignf nf-core] un fichier de configuration pour nos grappes et le placer dans <code>~/.nextflow/config</code>.
Si vous utilisez ce fichier sur Fir, le profil doit être chargé avec l'indicateur <code>-profile fir</code> pour la commande <code>nextflow</code>. Sur les autres grappes, le profil est sélectionné automatiquement selon le nom de l'hôte.
</div>

<syntaxhighlight lang="bash">
curl -o ~/.nextflow/config https://raw.githubusercontent.com/nf-core/configs/refs/heads/master/conf/alliance_canada.config
</syntaxhighlight>

<div class="mw-translate-fuzzy">
Il faut configurer la variable d'environnement <code>$SLURM_ACCOUNT</code> (semblable à <code>def-pname</code>), ce qui peut se faire dans le fichier <code>~/.bashrc</code>.
</div>

<syntaxhighlight lang="bash">
export SLURM_ACCOUNT=def-pname
</syntaxhighlight>

<div class="mw-translate-fuzzy">
Cette configuration garantit qu'il n'y a pas plus de 100 tâches dans la file d'attente Slurm et que seul 60 tâches sont soumises par minute. Elle indique que les nœuds de calcul de Rorqual ont 192&nbsp;cœurs et 750GB de RAM avec un temps réel maximum d'exécution d'une semaine (168&nbsp;heures). Ceci est différent sur Trillium puisque les nœuds sont configurés autrement. Comme un seul nœud entier est demandé à la fois, la mémoire et les CPU ne sont pas spécifiés.
</div> 

<div lang="en" dir="ltr" class="mw-content-ltr">
'''We discourage you from running nf-core pipelines or any other generic Nextflow pipeline on Trillium.''' We recommend running a pipeline on [[Trillium]] only if it was designed specifically for Trillium.
</div>

<div class="mw-translate-fuzzy">
La configuration est liée au système sur lequel se fait l'exécution, mais elle est également liée au pipeline lui-même. Par exemple, ici <code>cpu = 1</code> est la valeur par défaut, mais certaines étapes du pipeline peuvent en utiliser plus. Cela peut devenir assez compliqué et les étiquettes dans le fichier <code>nf-core-smrnaseq_2.3.1/2_3_1/conf/base.config</code> sont utilisées par le pipeline à l'interne pour identifier une étape avec une configuration autre que celle par défaut. Nous n'abordons pas ce sujet ici, mais sachez qu'en modifiant ces étiquettes, vous pourriez observer des différences importantes dans le temps de mise en file d'attente et le temps d'exécution du pipeline.
</div>

<span id="Step_2._Install_nf-core"></span>
==== Étape 2, Installer nf-core ====

<div lang="en" dir="ltr" class="mw-content-ltr">
To use nf-core pipelines on an Alliance cluster, the pipelines must be downloaded on a login node because some clusters do not allow internet access from the compute nodes.
Run the following on a '''login node''' to install <code>nf-core</code>. 
<source lang="bash">
module purge 
module load python/3.11
module load rust         # New nf-core installations will error out if rust hasn't been loaded
module load postgresql   # Python modules which list psycopg2 as a dependency may crash without postgresql here.
python -m venv nf-core-env
source nf-core-env/bin/activate
python -m pip install nf_core==2.13
</source>
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
We use <code>pip</code> to install a [[Python]] package to help with the setup. The nf-core tools can be slow to install; this step may take several minutes.
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
==== Step 3. Download the container images and the pipeline ====
Set the name of the pipeline to be tested, and load Nextflow and the container utility [[Apptainer]]. 
Nextflow integrates well with Apptainer. 
As noted above, we are using hte <code>rna-seq</code> pipeline as an example.
</div> 

<source lang="bash">
export NFCORE_PL=rnaseq
export PL_VERSION=3.21.0
module load nextflow
module load apptainer
</source>

<div lang="en" dir="ltr" class="mw-content-ltr">
Create a directory to use as a cache:
</div>

<source lang="bash">
mkdir /project/<def-group>/NXF_SINGULARITY_CACHEDIR
export NXF_SINGULARITY_CACHEDIR=/project/<def-group>/NXF_SINGULARITY_CACHEDIR
</source>

<div lang="en" dir="ltr" class="mw-content-ltr">
Nextflow will store container images in the directory pointed to by <code>$NXF_SINGULARITY_CACHEDIR</code>. 
"Singularity" was a predecessor to "Apptainer" so the name of the variable still reflects that.
Workflow images tend to be big, so do not store them in your $HOME space because it has a small quota. 
Instead, store them in <code>/project</code> space.
</div> 

<div lang="en" dir="ltr" class="mw-content-ltr">
You should share this folder with other members of your group who are planning to use Nextflow with Apptainer, in order to reduce duplication and save space.
Also, you may add the <code>export</code> command to your <code>~/.bashrc</code> as a convenience.
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
Run the following command to download the <code>rnaseq</code> pipeline and container images.
</div>

<source lang="bash">
cd ~/scratch
mkdir -p nf-test && cd nf-test
nf-core download --container-cache-utilisation amend --container-system singularity --compress none -r ${PL_VERSION}  -p 6  ${NFCORE_PL}
</source>

<div lang="en" dir="ltr" class="mw-content-ltr">
Type "Y" when you see <code>Include the nf-core's default institutional configuration files into the download? (Y/n)</code>
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
'''IMPORTANT!''': This workflow downloads two components of  ''<code>rnaseq</code>'':
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
# Container image files go into <code>$NXF_SINGULARITY_CACHEDIR</code> 
# Pipeline files go into <code>~/scratch/nf-test/nf-core-${NFCORE_PL}_${PL_VERSION}</code> folder with the version number <code>X_X_X</code>. In this example the pipeline is stored at <code>~/scratch/nf-test/nf-core-rnaseq_3.21.0/3_21_0</code>. Please note that you have to include this <code>nf-core-rnaseq_3.21.0/3_21_0</code> folder name when calling <code>nextflow run</code> in your job script (see Step 5 below).
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
When the pipeline is launched, Nextflow will look at the <code>nextflow.config</code> file in the working directory and also at <code>~/.nextflow/config</code> (if it exists) in your home to control how to run the workflow. 
The nf-core pipelines all have a default configuration, a test configuration, and container configurations (singularity, podman, etc).
</div>

<span id="Step_4._Prepare_the_input_files"></span>
==== Préparer les fichiers d'entrée ====

<div lang="en" dir="ltr" class="mw-content-ltr">
Nextflow uses sequence files and a sample sheet as inputs.  
To download the sequence files needed for our 'rnaseq' example, run the following:
</div> 

<syntaxhighlight lang="bash">
cd ~/scratch/nf-test
mkdir -p input && cd input
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357070_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357070_2.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357071_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357071_2.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357072_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357072_2.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357073_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357074_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357075_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357076_1.fastq.gz
wget https://raw.githubusercontent.com/nf-core/test-datasets/rnaseq/testdata/GSE110004/SRR6357076_2.fastq.gz
</syntaxhighlight>

<div lang="en" dir="ltr" class="mw-content-ltr">
To prepare a sample sheet, copy and paste the following into <code>~/scratch/nf-test/samplesheet.csv</code>
and then '''change the username to your own:''':
</div>

<syntaxhighlight lang="text">
sample,fastq_1,fastq_2,strandedness
WT_REP1,/home/<username>/scratch/nf-test/input/SRR6357070_1.fastq.gz,/home/<username>/scratch/nf-test/input/SRR6357070_2.fastq.gz,reverse
WT_REP1,/home/<username>/scratch/nf-test/input/SRR6357071_1.fastq.gz,/home/<username>/scratch/nf-test/input/SRR6357071_2.fastq.gz,reverse
WT_REP2,/home/<username>/scratch/nf-test/input/SRR6357072_1.fastq.gz,/home/<username>/scratch/nf-test/input/SRR6357072_2.fastq.gz,reverse
RAP1_UNINDUCED_REP1,/home/<username>/scratch/nf-test/input/SRR6357073_1.fastq.gz,,reverse
RAP1_UNINDUCED_REP2,/home/<username>/scratch/nf-test/input/SRR6357074_1.fastq.gz,,reverse
RAP1_UNINDUCED_REP2,/home/<username>/scratch/nf-test/input/SRR6357075_1.fastq.gz,,reverse
RAP1_IAA_30M_REP1,/home/<username>/scratch/nf-test/input/SRR6357076_1.fastq.gz,/home/<username>/scratch/nf-test/input/SRR6357076_2.fastq.gz,reverse
</syntaxhighlight>

<div lang="en" dir="ltr" class="mw-content-ltr">
You can of course use your own data if you prefer. 
Read more [https://nf-co.re/rnaseq/3.2/docs/usage here] about the <code>rnaseq</code> example and sample sheets.
</div>

<span id="Step_5._Create_a_job_script"></span>
<div class="mw-translate-fuzzy">
====Exécution du pipeline====
</div>

<div class="mw-translate-fuzzy">
Utilisez les deux profils fournis par nf-core (<i>test</i> pour l'ensemble de données de test et <i>singularity</i> pour le conteneur) et le profil que nous venons de créer pour Narval. Notez que Nextflow est principalement écrit en Java et a tendance à utiliser beaucoup de mémoire virtuelle. Sur certaines grappes, ceci peut causer un problème si l'exécution se fait à partir d'un nœud de connexion.
<source lang="bash">
nextflow run nf-core-${NFCORE_PL}_${PL_VERSION}/2_3_1/  -profile test,singularity,narval  --outdir ${NFCORE_PL}_OUTPUT
</source>
Remarque : Si votre répertoire <code>~/.aws</code> contient une configuration AWS, Nextflow pourrait vous avertir que l'ensemble de données pour le test du pipeline ne peut pas être téléchargé avec vos identifiants par défaut.
</div>

<source lang="bash">
#!/bin/bash
#SBATCH --time=08:00:00
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G

module load python/3.11
source nf-core-env/bin/activate
module load apptainer
module load nextflow
export NFCORE_PL=rnaseq
export PL_VERSION=3.21.0
export FD_VERSION=3_21_0
export NXF_SINGULARITY_CACHEDIR=/project/<def-group>/NXF_SINGULARITY_CACHEDIR
export SLURM_ACCOUNT=def-pname

nextflow run nf-core-${NFCORE_PL}_${PL_VERSION}/${FD_VERSION}/ \
 -profile test,singularity,fir \
 --input ~/scratch/nf-test/input/samplesheet.csv --outdir ~/scratch/nf-test/output
</source>

<div lang="en" dir="ltr" class="mw-content-ltr">
Save the job script in <code>~/scratch/nf-test/nextflow_test.sh</code>,
then submit it with <code>sbatch nextflow_test.sh</code> to launch the test run.
</div> 

<div class="mw-translate-fuzzy">
Nextflow est maintenant démarré sur le nœud de connexion. Ceci achemine les tâches à l'ordonnanceur Slurm quand elles sont prêtes à être traitées.
</div> 

<div class="mw-translate-fuzzy">
Vous pouvez voir la progression du pipeline. Il est aussi possible d'ouvrir une nouvelle session sur la grappe ou de vous détacher de la session tmux pour voir les tâches dans la file d'attente Slurm avec <code>squeue -u $USER</code> ou <code>sq</code>.
</div>

<div lang="en" dir="ltr" class="mw-content-ltr">
To learn more about configurations and profiles in Nextflow, see:
* [https://www.nextflow.io/docs/latest/config.html "Configuration"] 
* [https://nf-co.re/docs/usage/getting_started/configuration#basic-configuration-profiles "Pipeline configuration"]
</div>

<span id="Known_issues"></span>
==Problèmes connus==

<div lang="en" dir="ltr" class="mw-content-ltr">
Note that Nextflow is mainly written in Java which tends to use a lot of virtual memory. On some clusters, this may be a problem when running from a login node.
</div>  

<div lang="en" dir="ltr" class="mw-content-ltr">
Be careful if you have an AWS configuration in your <code>~/.aws</code> directory, as Nextflow might complain that it can't download the pipeline test dataset with your default id.
</div> 

<span id="&quot;unable_to_create_native_thread&quot;"></span>
==== Message <i>unable to create native thread</i> ====

Nous avons constaté l'erreur suivante&nbsp;:
<source>
java.lang.OutOfMemoryError: unable to create native thread: possibly out of memory or process/resource limits reached
[error][gc,task] GC Failed to create worker thread
</source>
Nous croyons que l'erreur se produit quand Java tente de créer autant de fils que le nombre de cœurs physiques de l'ordinateur.
Il semble que l'erreur est résolue quand <code>nextflow</code> est exécuté avec <code>export NXF_OPTS='-XX:ActiveProcessorCount=1'</code>.

==== SIGBUS ====
Des erreurs <code>SIGBUS</code> du processus principal de Nextflow ont été signalées.
Nous soupçonnons que c'est à cause des problèmes Nextflow suivants&nbsp;:
  * https://github.com/nextflow-io/nextflow/issues/842
  * https://github.com/nextflow-io/nextflow/issues/2774
Le fait de définir la variable d'environnement <code>NXF_OPTS="-Dleveldb.mmap=false"</code> à l'exécution de <code>nextflow</code> semble résoudre le problème.

[[Category:Software]]