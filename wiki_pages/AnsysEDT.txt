<languages />
[[Category:Software]]

<translate>
<!--T:2-->
[https://www.ansys.com/products/electronics AnsysEDT] bundles electromagnetics simulation solutions such as Ansys HFSS, Ansys Maxwell, Ansys Q3D Extractor, Ansys SIwave, and Ansys Icepak using electrical CAD (ECAD) and mechanical CAD (MCAD) workflows.  AnsysEDT also integrates with the complete Ansys portfolio of thermal, fluid, and mechanical solvers for comprehensive multiphysics analysis.

= Licensing = <!--T:4-->

<!--T:2844-->
The Alliance is a hosting provider for AnsysEDT. This means we have the software installed on our clusters, but do not provide a generic license accessible to everyone. However, many institutions, faculties, and departments already have license servers that can be used if the legal aspects can be worked out.  Network changes would need to be made to enable the license server to be reached from the cluster compute nodes.  The Ansys software would then be able to check out licenses after loading the ansysedt module.  For help contact [[technical support]].

<!--T:10-->
== Configuring your license file ==
Specify your ansysedt license server by creating a file named <code>$HOME/.licenses/ansys.lic</code> consisting of two lines.  See [[Ansys#Configuring_your_license_file|Configuring your license file]] on the ansys wiki page for further details.

= Cluster batch job submission = <!--T:23-->

<!--T:1091-->
AnsysEDT can be run interactively in batch (non-gui) mode by first starting an salloc session with options <code>salloc --time=3:00:00 --tasks=8 --mem=16G --account=def-account</code> and then copy-pasting the full <code>ansysedt</code> command found in the last line of <i>script-local-cmd.sh</i>, being sure to manually specify $YOUR_AEDT_FILE.

=== Slurm scripts === <!--T:1092-->

<!--T:1093-->
Jobs may be submitted to a cluster queue with the <code>sbatch script-name.sh</code> command using either of the following single node scripts.  Please note these scripts are generic and may require modifications on various clusters.  Before using them, specify the simulation time, memory, number of cores and replace YOUR_AEDT_FILE with your input file name.   A full listing of command line options can be obtained by starting AnsysEDT in [[ANSYS#Graphical_use|graphical mode]] with commands <code>ansysedt -help</code> or <code>ansysedt -Batchoptionhelp</code> to obtain scrollable graphical popups.  

<!--T:1094-->
<tabs>
<tab name="Single node (command line)">
{{File
|name=script-local-cmd.sh
|lang="bash"
|contents=
#!/bin/bash

<!--T:1095-->
#SBATCH --account=account      # Specify your account (def or rrg)
#SBATCH --time=00-01:00        # Specify time (DD-HH:MM)
#SBATCH --mem=16G              # Specify memory (set to 0 to use all compute node memory)
#SBATCH --ntasks=8             # Specify number of cores to be used on a single node
#SBATCH --nodes=1              # Request one node (Do Not Change)

<!--T:1098-->
module load StdEnv/2023
#module load ansysedt/2023R2
module load ansysedt/2024R2.1

<!--T:1097-->
# Uncomment next line to run a test example:
#cp -f $EBROOTANSYSEDT/v232/Linux64/Examples/HFSS/Antennas/TransientGeoRadar.aedt .
cp -f $EBROOTANSYSEDT/v242/Linux64/Examples/HFSS/Antennas/TransientGeoRadar.aedt .

<!--T:2811-->
# Specify input file such as:
YOUR_AEDT_FILE="TransientGeoRadar.aedt"

<!--T:2812-->
# Remove previous output:
rm -rf $YOUR_AEDT_FILE.* ${YOUR_AEDT_FILE}results

<!--T:2813-->
# ---- do not change anything below this line ---- #

<!--T:2840-->
echo -e "\nANSYSLI_SERVERS= $ANSYSLI_SERVERS"
echo "ANSYSLMD_LICENSE_FILE= $ANSYSLMD_LICENSE_FILE"
echo -e "SLURM_TMPDIR= $SLURM_TMPDIR on $SLURMD_NODENAME\n"

<!--T:2841-->
export KMP_AFFINITY=disabled
ansysedt -monitor -UseElectronicsPPE -ng -distributed -machinelist list=localhost:1:$SLURM_NTASKS \
-batchoptions "TempDirectory=$SLURM_TMPDIR HPCLicenseType=pool HFSS/EnableGPU=0" -batchsolve "$YOUR_AEDT_FILE"
}}
</tab>
<tab name="Single node (options file)">
{{File
|name=script-local-opt.sh
|lang="bash"
|contents=
#!/bin/bash

<!--T:2816-->
#SBATCH --account=account      # Specify your account (def or rrg)
#SBATCH --time=00-01:00        # Specify time (DD-HH:MM)
#SBATCH --mem=16G              # Specify memory (set to 0 to allocate all compute node memory)
#SBATCH --ntasks=8             # Specify number of cores to be used on a single node
#SBATCH --nodes=1              # Request one node (Do Not Change)

<!--T:1099-->
module load StdEnv/2023
#module load ansysedt/2023R2
module load ansysedt/2024R2.1

<!--T:2818-->
# Uncomment next line to run a test example:
#cp -f $EBROOTANSYSEDT/v232/Linux64/Examples/HFSS/Antennas/TransientGeoRadar.aedt .
cp -f $EBROOTANSYSEDT/v242/Linux64/Examples/HFSS/Antennas/TransientGeoRadar.aedt .

<!--T:2819-->
# Specify input filename such as:
YOUR_AEDT_FILE="TransientGeoRadar.aedt"

<!--T:2820-->
# Remove previous output:
rm -rf $YOUR_AEDT_FILE.* ${YOUR_AEDT_FILE}results

<!--T:2821-->
# Specify options filename:
OPTIONS_TXT="Options.txt"

<!--T:2822-->
# Write sample options file
rm -f $OPTIONS_TXT
cat > $OPTIONS_TXT <<EOF
\$begin 'Config'
'TempDirectory'='$SLURM_TMPDIR'
'HPCLicenseType'='pool'
'HFSS/EnableGPU'=0
\$end 'Config'
EOF

<!--T:2823-->
# ---- do not change anything below this line ---- #

<!--T:2842-->
echo -e "\nANSYSLI_SERVERS= $ANSYSLI_SERVERS"
echo "ANSYSLMD_LICENSE_FILE= $ANSYSLMD_LICENSE_FILE"
echo -e "SLURM_TMPDIR= $SLURM_TMPDIR on $SLURMD_NODENAME\n"

<!--T:2843-->
export KMP_AFFINITY=disabled

<!--T:2845-->
ansysedt -monitor -UseElectronicsPPE -ng -distributed -machinelist list=localhost:1:$SLURM_NTASKS \
-batchoptions $OPTIONS_TXT -batchsolve "$YOUR_AEDT_FILE"
}}
</tab>
</tabs>

= Graphical use = <!--T:94-->

<!--T:941-->
Ansys programs may be run interactively in GUI mode on any cluster compute nodes or On Demand systems.

== Compute nodes == <!--T:943--> 

<!--T:201-->
AnsysEDT  can be run interactively on a single compute node for up to 24 hours.  This approach is ideal for testing large simulations, since all cores and memory can be requested with salloc as described in [[VNC#Compute_Nodes|TigerVNC]].  Once connected with vncviewer, any of the following program versions can be started after loading the required modules as shown below.

<!--T:1672-->
::: Start an interactive session using the following form of the salloc command (to specify cores and available memory):
::: <code>salloc --time=3:00:00 --nodes=1 --cores=8 --mem=16G --account=def-group</code>
::: <code>xfwm4 --replace &</code> (then hit enter twice)
::: <code>module load StdEnv/2023 ansysedt/2023R2</code>, or
::: <code>module load StdEnv/2023 ansysedt/2024R2.1</code>
::: <code>ansysedt</code>
::: o Click <code>Tools -> Options -> HPC and Analysis Options -> Edit</code> then :
:::: 1) untick Use Automatic Settings box (required one time only)
:::: 2) under Machines tab do not change Cores (auto-detected from slurm)
::: o To run interactive analysis click:  <code>Project -> Analyze All</code>

== OnDemand == <!--T:947-->

<!--T:125-->
To run starccm+ in graphical interactive mode on a remote desktop it is recommended to use an [https://docs.alliancecan.ca/wiki/Nibi#Access_through_Open_OnDemand_(OOD) OnDemand] or JupyterLab system as follows:

<!--T:126-->
1. Connect to an OnDemand system using one of the following URLs in your laptop browser :<br>
 [https://docs.alliancecan.ca/wiki/Nibi#Access_through_Open_OnDemand_(OOD) NIBI]: <code>https://ondemand.sharcnet.ca</code>
 FIR: <code>https://jupyterhub.fir.alliancecan.ca</code>
 RORQUAL: <code>https://jupyterhub.rorqual.alliancecan.ca</code>
 TRILLIUM: <code>https://ondemand.scinet.utoronto.ca</code>
2. Open a new terminal window in your desktop and run:
::: <code>module load StdEnv/2023</code>  (default)
::: <code>module load ansysedt/2024R2.1</code> **OR** <code>ansysedt/2023R2</code>
::: Type <code>ansysedt</code> in the terminal and wait for the gui to start
::: The following only needs to be done once:
:::: click <code>Tools -> Options -> HPC and Analysis Options -> Options</code>
:::: change <code>HPC License</code> pulldown to <b>Pool</b> (allows > 4 cores to be used)
:::: click <code>OK</code>
3.  To run the 2024R2.1 Antennas example copy the corresponding version into your account:
:::: <code>module load ansysedt/2024R2.1</code>
:::: <code>mkdir -p ~/Ansoft/$EBVERSIONANSYSEDT; cd ~/Ansoft/$EBVERSIONANSYSEDT; rm -rf Antennas</code>
:::: <code>cp -a $EBROOTANSYSEDT/v242/Linux64/Examples/HFSS/Antennas ~/Ansoft/$EBVERSIONANSYSEDT</code>
4. Now to run the example:
:::: open a simulation .aedt file then click <code>HFSS -> Validation Check</code>
:::: (if errors are reported by the validation check, close then reopen the simulation and repeat as required)
::::  to run simulation click <code>Project -> Analyze All</code>
:::: to quit without saving the converged solution click <code>File -> Close -> No </code>
::: If the program crashes and won't restart try running the following commands:
:::: <code>pkill -9 -u $USER -f "ansys*|mono|mwrpcss|apip-standalone-service"</code>
:::: <code>rm -rf ~/.mw</code> (ansysedt will re-run first-time configuration on startup)

= Site-Specific = <!--T:86-->

== SHARCNET license == <!--T:118-->

<!--T:90-->
The usage terms of the SHARCNET ANSYS License (which includes AnsysEDT) along with other various details maybe found in the SHARCNET license section of the Ansys wiki and will not be repeated here. 

==== License file ==== <!--T:92-->

<!--T:920-->
The SHARCNET Ansys license can be used for the AnsysEDT modules on any Alliance cluster by any researcher for free, by configuring your <code>ansys.lic</code> file as follows:
<source lang="bash">
[username@cluster:~] cat ~/.licenses/ansys.lic
setenv("ANSYSLMD_LICENSE_FILE", "1055@license3.sharcnet.ca")
setenv("ANSYSLI_SERVERS", "2325@license3.sharcnet.ca")
</source>

</translate>