[[Category:Software]]
<languages />

Nous décrivons ici l'utilisation de AlphaFold v3.0.

Le code source et la documentation se trouvent sur [https://github.com/google-deepmind/alphafold3 leur page GitHub].
Toute publication qui divulgue des résultats découlant de l'utilisation de ce code source ou des paramètres du modèle [https://github.com/google-deepmind/alphafold3#citing-this-work doit citer] le [https://doi.org/10.1038/s41586-024-07487-w document AlphaFold3].

== Versions disponibles ==
Sur nos grappes, AlphaFold3 est disponible sous forme de paquets préconstruits (<i>wheels</i>) Pour les lister, utilisez <code>avail_wheels</code>.
{{Command
|avail_wheels alphafold3
|result=
}}

AlphaFold2 est encore disponible ([[AlphaFold2|voir la documentation]]).

<span id="Creating_a_requirements_file_for_AlphaFold3"></span>
== Créer un fichier des dépendances requises ==

1. Chargez les dépendances de AlphaFold3.
{{Command|module load StdEnv/2023 hmmer/3.4 rdkit/2024.03.5 python/3.12
}}

2. Téléchargez le script d'exécution.
<tabs>
<tab name="3.0.1">
{{Command
|wget https://raw.githubusercontent.com/google-deepmind/alphafold3/refs/tags/v3.0.1/run_alphafold.py
}}
</tab>
<tab name="3.0.0">
{{Command
|wget https://raw.githubusercontent.com/google-deepmind/alphafold3/23e3d46d4ca126e8731e8c0cbb5673e9a848ceb5/run_alphafold.py
}}
</tab>
</tabs>

3. Créez et activez un environnement virtuel Python.
{{Commands
|virtualenv --no-download ~/alphafold3_env
|source ~/alphafold3_env/bin/activate
}}

4. Installez une version de AlphaFold3 ainsi que ses dépendances Python
{{Commands
|prompt=(alphafold3_env) [name@server ~]
|pip install --no-index --upgrade pip
|pip install --no-index alphafold3{{=}}{{=}}X.Y.Z
}}
où <code>X.Y.Z</code> est la version spécifique, par exemple <code>3.0.0</code>.
N'entrez pas le numéro de la version si vous voulez installer la plus récente.

5. Compilez les données nécessaires.
{{Command
|prompt=(alphafold3_env) [name@server ~]
|build_data
}}
Ceci crée des fichiers de données dans l'environnement virtuel.

6. Validez.
{{Command
|prompt=(alphafold3_env) [name@server ~]
|python run_alphafold.py --help
}}

7. Gelez l'environnement et l'ensemble des requis.
{{Command
|prompt=(alphafold3_env) [name@server ~]
|pip freeze > ~/alphafold3-requirements.txt
}}

8. Désactivez l'environnement.
{{Command
|prompt=(alphafold3_env) [name@server ~]
|deactivate
}}

9. Nettoyez et supprimez l'environnement virtuel.
{{Command
|rm -r ~/alphafold3_env
}}

L'environnement virtuel sera plutôt créé dans votre tâche.

== Modèle ==
Vous pouvez obtenir le modèle de Google, qui répond habituellement dans les 2 ou 3 jours ouvrables; voir [https://github.com/google-deepmind/alphafold3?tab=readme-ov-file Obtaining Model Parameters].

== Bases de données ==
AlphaFold3 nécessite un ensemble de bases de données.

<b>Important :</b> Les bases de données doivent résider dans le répertoire <code>$SCRATCH</code>.

1. Téléchargez le script de téléchargement.
{{Command
|wget https://raw.githubusercontent.com/google-deepmind/alphafold3/refs/heads/main/fetch_databases.sh
}}

2. Téléchargez les bases de données.
{{Commands
|mkdir -p $SCRATCH/alphafold/dbs
|bash fetch_databases.sh $SCRATCH/alphafold/dbs
}}

== Exécution par étapes ==
Alphafold3 doit être [https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md#running-the-pipeline-in-stages exécuté par étapes], c'est-à-dire
# séparer le pipeline de données pour CPU seulement et le modèle d'inférence (qui demande un GPU) pour optimiser les coûts et l'utilisation des ressources;
# cacher les résultats de la recherche de MSA/modèle, pour ensuite réutiliser le JSON augmenté pour plusieurs différentes inférences ou pour des variations d'autres fonctionnalités (par exemple un ligand).

Pour des références, voir
* [https://github.com/google-deepmind/alphafold3/blob/main/docs/input.md inputs]
* [https://github.com/google-deepmind/alphafold3/blob/main/docs/output.md outputs]
* [https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md performance]

=== 1. Pipeline de données (CPU) ===
Modifiez le script suivant selon vos besoins.
{{File
|name=alphafold3-data.sh
|lang="bash"
|contents=
#!/bin/bash

#SBATCH --job-name=alphafold3-data
#SBATCH --account=def-someprof    # adjust this to match the accounting group you are using to submit jobs
#SBATCH --time=08:00:00           # adjust this to match the walltime of your job
#SBATCH --cpus-per-task=8         # a MAXIMUM of 8 core, AlphaFold has no benefit to use more
#SBATCH --mem=64G                 # adjust this according to the memory you need

# Load modules dependencies.
module load StdEnv/2023 hmmer/3.4 rdkit/2024.03.5 python/3.12

DOWNLOAD_DIR=$SCRATCH/alphafold/dbs    # set the appropriate path to your downloaded data
INPUT_DIR=$SCRATCH/alphafold/input     # set the appropriate path to your input data
OUTPUT_DIR=$SLURM_TMPDIR/alphafold/output   # set the appropriate path to your output data

# Generate your virtual environment in $SLURM_TMPDIR.
virtualenv --no-download $SLURM_TMPDIR/env
source $SLURM_TMPDIR/env/bin/activate

# Install AlphaFold and its dependencies.
pip install --no-index --upgrade pip
pip install --no-index --requirement ~/alphafold3-requirements.txt

# build data in $VIRTUAL_ENV
build_data

# https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md#compilation-time-workaround-with-xla-flags
export XLA_FLAGS="--xla_gpu_enable_triton_gemm=false"

# Edit with the proper arguments and run your commands.
# run_alphafold.py --help
python run_alphafold.py \
    --db_dir=$DOWNLOAD_DIR \
    --input_dir=$INPUT_DIR \
    --output_dir=$OUTPUT_DIR \
    --jax_compilation_cache_dir=$HOME/.cache \
    --nhmmer_n_cpu=$SLURM_CPUS_PER_TASK \
    --jackhmmer_n_cpu=$SLURM_CPUS_PER_TASK \
    --norun_inference  # Run data stage

# copy back
mkdir $SCRATCH/alphafold/output
cp -vr $OUTPUT_DIR $SCRATCH/alphafold/output
}}

=== 2. Inférence de modèle ===
Modifiez le script suivant selon vos besoins.

{{Warning
|title=Compatibilité
|content=Alphafold3 prend en charge seulement la capacité de calcul des versions 8.0 et plus récentes, soit pour des '''A100s et plus performants'''.
}}
{{File
|name=alphafold3-inference.sh
|lang="bash"
|contents=
#!/bin/bash

#SBATCH --job-name=alphafold3-inference
#SBATCH --account=def-someprof    # adjust this to match the accounting group you are using to submit jobs
#SBATCH --time=08:00:00           # adjust this to match the walltime of your job
#SBATCH --cpus-per-task=1         # AlphaFold has no benefit to use more for the inference stage
#SBATCH --gpus=a100:1             # Alphafold3 inference only runs on ONE A100 or greater.
#SBATCH --mem=20G                 # adjust this according to the memory you need

# Load modules dependencies.
module load StdEnv/2023 hmmer/3.4 rdkit/2024.03.5 python/3.12 cuda/12.2 cudnn/9.2

DOWNLOAD_DIR=$SCRATCH/alphafold/dbs    # set the appropriate path to your downloaded data
INPUT_DIR=$SCRATCH/alphafold/input     # set the appropriate path to your input data, following the data stage.
OUTPUT_DIR=$SCRATCH/alphafold/output   # set the appropriate path to your output data

# Generate your virtual environment in $SLURM_TMPDIR.
virtualenv --no-download $SLURM_TMPDIR/env
source $SLURM_TMPDIR/env/bin/activate

# Install AlphaFold and its dependencies.
pip install --no-index --upgrade pip
pip install --no-index --requirement ~/alphafold3-requirements.txt

# build data in $VIRTUAL_ENV
build_data

# https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md#compilation-time-workaround-with-xla-flags
export XLA_FLAGS="--xla_gpu_enable_triton_gemm=false"

# https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md#gpu-memory
export XLA_PYTHON_CLIENT_PREALLOCATE=true
export XLA_CLIENT_MEM_FRACTION=0.95

# Edit with the proper arguments and run your commands.
# run_alphafold.py --help
python run_alphafold.py \
    --db_dir=$DOWNLOAD_DIR \
    --input_dir=$INPUT_DIR \
    --output_dir=$OUTPUT_DIR \
    --jax_compilation_cache_dir=$HOME/.cache \
    --norun_data_pipeline  # Run inference stage
}}

<span id="3._Job_submission"></span>
=== 3. Soumettre une tâche ===

Soumettez la tâche à l'ordonnanceur.

==== Tâches indépendantes ====
{{Command
|sbatch alphafold3-data.sh
}}

Attendez la fin et soumettez ensuite la deuxième étape.
{{Command
|sbatch alphafold3-inference.sh
}}

==== Tâches dépendantes ====
{{Commands
|jid1{{=}}$(sbatch alphafold3-data.sh)
|jid2{{=}}$(sbatch --dependency{{=}}afterok:$jid1 alphafold3-inference.sh)
|sq
}}
Si la première étape échoue, vous devez annuler manuellement la deuxième étape.
{{Command
|scancel -u $USER -n alphafold3-inference
}}

== Dépannage ==
=== Mémoire insuffisante (GPU) ===
Si vous voulez exécuter AlphaFold3 avec plus de 5120 jetons ou sur un GPU de mémoire moindre,  (par exemple sur un A100 avec 40Go de mémoire), vous pouvez activer la fonctionnalité de [https://github.com/google-deepmind/alphafold3/blob/main/docs/performance.md#unified-memory mémoire unifiée].

Dans le script de soumission à l'étape d'inférence, ajoutez les variables d'environnement suivantes&nbsp;:
<syntaxhighlight lang="bash">
export XLA_PYTHON_CLIENT_PREALLOCATE=false
export TF_FORCE_UNIFIED_MEMORY=true
export XLA_CLIENT_MEM_FRACTION=2.0  # 2 x 40GB = 80 GB
</syntaxhighlight>


et ajuster en conséquence la quantité de mémoire allouée à la tâche, par exemple <code>#SBATCH --mem=80G</code>.