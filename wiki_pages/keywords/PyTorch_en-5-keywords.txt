distributeddataparallel
data parallelism
multi-gpu
pytorch
dataloader
transformscompose
crossentropyloss
neural network training
slurm job script
gpu training
model replicas
gpu computing
distributed training
performance optimization
deepspeed
libtorch
hpc clusters
model checkpoints