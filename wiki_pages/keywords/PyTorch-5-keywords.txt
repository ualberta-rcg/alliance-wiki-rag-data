data parallelism
pytorch
multi-gpu
distributeddataparallel
model replicas
distributed training
batch size
learning rate
pytorch lightning
hpc clusters
gpu memory
large datasets
deep learning
gpu acceleration
performance optimization
libtorch
model parallelism
checkpoints
installation
job submission