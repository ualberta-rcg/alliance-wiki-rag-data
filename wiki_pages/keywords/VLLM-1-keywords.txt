vllm
large language models
memory-efficient inference
hugging face hub
virtual environment
slurm
job submission script
tensor parallelism
tensor parallel size
ray cluster
multi-node ray cluster
single node inference
llm inference
installation
hugging face models
job submission
gpu acceleration
multi-node inference