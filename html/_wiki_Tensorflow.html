<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>TensorFlow - Alliance Doc</title>
<script>(function(){var className="client-js";var cookie=document.cookie.match(/(?:^|; )ccwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"aDpFaTv@Jr5vJi8BNccn9AAAA8M","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"TensorFlow","wgTitle":"TensorFlow","wgCurRevisionId":157500,"wgRevisionId":157500,"wgArticleId":3554,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Software",
"AI and Machine Learning"],"wgPageViewLanguage":"en","wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"TensorFlow","wgRelevantArticleId":3554,"wgIsProbablyEditable":false,"wgRelevantPageIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"Tensorflow","wgULSAcceptLanguageList":[],"wgMFDisplayWikibaseDescriptions":{"search":false,"watchlist":false,"tagline":false},"wgCiteReferencePreviewsActive":true,"wgInternalRedirectTargetUrl":"/wiki/TensorFlow","wgTranslatePageTranslation":"source","wgULSPosition":"personal","wgULSisCompactLinksEnabled":true,"wgVector2022LanguageInHeader":false,"wgULSisLanguageSelectorEmpty":false};RLSTATE={"site.styles":"ready","user.styles":"ready","user":"ready","user.options":"loading","ext.translate.tag.languages":"ready","ext.pygments":"ready","skins.vector.styles.legacy":"ready","ext.translate.edit.documentation.styles":"ready","ext.translate":"ready","codex-search-styles":"ready",
"ext.uls.pt":"ready"};RLPAGEMODULES=["mediawiki.action.view.redirect","ext.tabs","ext.pygments.view","site","mediawiki.page.ready","mediawiki.toc","skins.vector.legacy.js","ext.languageSelector","ext.translate.pagetranslation.uls","ext.uls.compactlinks","ext.uls.geoclient","ext.uls.interface","ext.moderation.notify","ext.moderation.notify.desktop"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="/mediawiki/load.php?lang=en&amp;modules=codex-search-styles%7Cext.pygments%2Ctranslate%7Cext.translate.edit.documentation.styles%7Cext.translate.tag.languages%7Cext.uls.pt%7Cskins.vector.styles.legacy&amp;only=styles&amp;skin=vector">
<script async="" src="/mediawiki/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="/mediawiki/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector">
<meta name="generator" content="MediaWiki 1.43.0">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta name="viewport" content="width=1120">
<link rel="icon" href="/mediawiki/resources/assets/Alliance_favicon.png">
<link rel="search" type="application/opensearchdescription+xml" href="/mediawiki/rest.php/v1/search" title="Alliance Doc (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://docs.alliancecan.ca/mediawiki/api.php?action=rsd">
<link rel="canonical" href="https://docs.alliancecan.ca/wiki/TensorFlow">
<link rel="alternate" type="application/atom+xml" title="Alliance Doc Atom feed" href="/mediawiki/index.php?title=Special:RecentChanges&amp;feed=atom">
<style type="text/css" id="tabs-dynamic-styles">/*<![CDATA[*/
/* Dynamically generated tabs styles */
.tabs-input-1:checked ~ .tabs-container .tabs-content-1,
.tabs-input-2:checked ~ .tabs-container .tabs-content-2,
.tabs-input-0:checked ~ .tabs-container .tabs-content-1 {display:inline-block;}
.tabs-input-1:checked ~ .tabs-container .tabs-inline.tabs-content-1,
.tabs-input-2:checked ~ .tabs-container .tabs-inline.tabs-content-2,
.tabs-input-0:checked ~ .tabs-container .tabs-inline.tabs-content-1 {display:inline;}
.tabs-input-1:checked ~ .tabs-container .tabs-block.tabs-content-1,
.tabs-input-2:checked ~ .tabs-container .tabs-block.tabs-content-2,
.tabs-input-0:checked ~ .tabs-container .tabs-block.tabs-content-1 {display:block;}
/* The same styles, but with .checked instead of :checked, for browsers that rely on the JavaScript fallback */
.tabs-input-1.checked ~ .tabs-container .tabs-content-1,
.tabs-input-2.checked ~ .tabs-container .tabs-content-2,
.tabs-input-0.checked ~ .tabs-container .tabs-content-1 {display:inline-block;}
.tabs-input-1.checked ~ .tabs-container .tabs-inline.tabs-content-1,
.tabs-input-2.checked ~ .tabs-container .tabs-inline.tabs-content-2,
.tabs-input-0.checked ~ .tabs-container .tabs-inline.tabs-content-1 {display:inline;}
.tabs-input-1.checked ~ .tabs-container .tabs-block.tabs-content-1,
.tabs-input-2.checked ~ .tabs-container .tabs-block.tabs-content-2,
.tabs-input-0.checked ~ .tabs-container .tabs-block.tabs-content-1 {display:block;}
.tabs-dropdown .tabs-content,.tabs-dropdown .tabs-container,.tabs-dropdown li,.tabs-dropdown ul,.tabs-dropdown ol {background-color: white /* Malicious data in tabs-dropdown-bgcolor */}
/*]]>*/</style>
</head>
<body class="skin-vector-legacy mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-TensorFlow rootpage-TensorFlow skin-vector action-view"><div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice"></div>
	<div class="mw-indicators">
	<div id="mw-indicator-languageselector" class="mw-indicator"><span id="languageselector-box-1" class="languageselector " style=""><form name="languageselector-form-1" id="languageselector-form-1" method="get" action="/mediawiki/index.php" style="display:inline;"><input type="hidden" value="TensorFlow" name="title"><select name="setlang" id="languageselector-select-1" style=""><option value="aae">ArbÃ«risht</option><option value="ab">Ğ°Ô¥ÑÑˆÓ™Ğ°</option><option value="abs">bahasa ambon</option><option value="ace">AcÃ¨h</option><option value="acf">KwÃ©yÃ²l Sent Lisi</option><option value="acm">Ø¹Ø±Ø§Ù‚ÙŠ</option><option value="ady">Ğ°Ğ´Ñ‹Ğ³Ğ°Ğ±Ğ·Ñ</option><option value="ady-cyrl">Ğ°Ğ´Ñ‹Ğ³Ğ°Ğ±Ğ·Ñ</option><option value="aeb">ØªÙˆÙ†Ø³ÙŠ / TÃ»nsÃ®</option><option value="aeb-arab">ØªÙˆÙ†Ø³ÙŠ</option><option value="aeb-latn">TÃ»nsÃ®</option><option value="af">Afrikaans</option><option value="aln">GegÃ«</option><option value="alt">Ğ°Ğ»Ñ‚Ğ°Ğ¹ Ñ‚Ğ¸Ğ»</option><option value="am">áŠ áˆ›áˆ­áŠ›</option><option value="ami">Pangcah</option><option value="an">aragonÃ©s</option><option value="ang">Ã†nglisc</option><option value="ann">Obolo</option><option value="anp">à¤…à¤‚à¤—à¤¿à¤•à¤¾</option><option value="apc">Ø´Ø§Ù…ÙŠ</option><option value="ar">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option><option value="arc">ÜÜªÜ¡ÜÜ</option><option value="arn">mapudungun</option><option value="arq">Ø¬Ø§Ø²Ø§ÙŠØ±ÙŠØ©</option><option value="ary">Ø§Ù„Ø¯Ø§Ø±Ø¬Ø©</option><option value="arz">Ù…ØµØ±Ù‰</option><option value="as">à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾</option><option value="ase">American sign language</option><option value="ast">asturianu</option><option value="atj">Atikamekw</option><option value="av">Ğ°Ğ²Ğ°Ñ€</option><option value="avk">Kotava</option><option value="awa">à¤…à¤µà¤§à¥€</option><option value="ay">Aymar aru</option><option value="az">azÉ™rbaycanca</option><option value="azb">ØªÛ†Ø±Ú©Ø¬Ù‡</option><option value="ba">Ğ±Ğ°ÑˆÒ¡Ğ¾Ñ€Ñ‚ÑĞ°</option><option value="ban">Basa Bali</option><option value="ban-bali">á¬©á¬²á¬©á¬®á¬¶</option><option value="bar">Boarisch</option><option value="bbc">Batak Toba</option><option value="bbc-latn">Batak Toba</option><option value="bcc">Ø¬Ù‡Ù„Ø³Ø±ÛŒ Ø¨Ù„ÙˆÚ†ÛŒ</option><option value="bci">wawle</option><option value="bcl">Bikol Central</option><option value="bdr">Bajau Sama</option><option value="be">Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑĞºĞ°Ñ</option><option value="be-tarask">Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑĞºĞ°Ñ (Ñ‚Ğ°Ñ€Ğ°ÑˆĞºĞµĞ²Ñ–Ñ†Ğ°)</option><option value="bew">Betawi</option><option value="bg">Ğ±ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸</option><option value="bgc">à¤¹à¤°à¤¿à¤¯à¤¾à¤£à¤µà¥€</option><option value="bgn">Ø±ÙˆÚ† Ú©Ù¾ØªÛŒÙ† Ø¨Ù„ÙˆÚ†ÛŒ</option><option value="bh">à¤­à¥‹à¤œà¤ªà¥à¤°à¥€</option><option value="bho">à¤­à¥‹à¤œà¤ªà¥à¤°à¥€</option><option value="bi">Bislama</option><option value="bjn">Banjar</option><option value="blk">á€•á€¡á€­á€¯á€á€ºá‚á€˜á€¬á‚á€á€¬á‚</option><option value="bm">bamanankan</option><option value="bn">à¦¬à¦¾à¦‚à¦²à¦¾</option><option value="bo">à½–à½¼à½‘à¼‹à½¡à½²à½‚</option><option value="bpy">à¦¬à¦¿à¦·à§à¦£à§à¦ªà§à¦°à¦¿à¦¯à¦¼à¦¾ à¦®à¦£à¦¿à¦ªà§à¦°à§€</option><option value="bqi">Ø¨Ø®ØªÛŒØ§Ø±ÛŒ</option><option value="br">brezhoneg</option><option value="brh">BrÃ¡huÃ­</option><option value="bs">bosanski</option><option value="btm">Batak Mandailing</option><option value="bto">Iriga Bicolano</option><option value="bug">Basa Ugi</option><option value="bxr">Ğ±ÑƒÑ€ÑĞ°Ğ´</option><option value="ca">catalÃ </option><option value="cbk-zam">Chavacano de Zamboanga</option><option value="ccp">ğ‘„Œğ‘„‹ğ‘„´ğ‘„Ÿğ‘„³ğ‘„¦</option><option value="cdo">é–©æ±èª / MÃ¬ng-dÄ•Ì¤ng-ngá¹³Ì„</option><option value="ce">Ğ½Ğ¾Ñ…Ñ‡Ğ¸Ğ¹Ğ½</option><option value="ceb">Cebuano</option><option value="ch">Chamoru</option><option value="chn">chinuk wawa</option><option value="chr">á£á³á©</option><option value="chy">TsetsÃªhestÃ¢hese</option><option value="ckb">Ú©ÙˆØ±Ø¯ÛŒ</option><option value="co">corsu</option><option value="cps">CapiceÃ±o</option><option value="cpx">è†ä»™èª / PÃ³-sing-gá¹³Ì‚</option><option value="cpx-hans">è†ä»™è¯­ï¼ˆç®€ä½“ï¼‰</option><option value="cpx-hant">è†ä»™èªï¼ˆç¹é«”ï¼‰</option><option value="cr">NÄ“hiyawÄ“win / á“€á¦áƒá”­ááá£</option><option value="crh">qÄ±rÄ±mtatarca</option><option value="crh-cyrl">ĞºÑŠÑ‹Ñ€Ñ‹Ğ¼Ñ‚Ğ°Ñ‚Ğ°Ñ€Ğ´Ğ¶Ğ° (ĞšĞ¸Ñ€Ğ¸Ğ»Ğ»)</option><option value="crh-latn">qÄ±rÄ±mtatarca (Latin)</option><option value="crh-ro">tatarÅŸa</option><option value="cs">ÄeÅ¡tina</option><option value="csb">kaszÃ«bsczi</option><option value="cu">ÑĞ»Ğ¾Ğ²Ñ£Ğ½ÑŒÑĞºÑŠ / â°”â°â°‘â°‚â°¡â°â° â°”â°â°Ÿ</option><option value="cv">Ñ‡Ó‘Ğ²Ğ°ÑˆĞ»Ğ°</option><option value="cy">Cymraeg</option><option value="da">dansk</option><option value="dag">dagbanli</option><option value="de">Deutsch</option><option value="de-at">Ã–sterreichisches Deutsch</option><option value="de-ch">Schweizer Hochdeutsch</option><option value="de-formal">Deutsch (Sie-Form)</option><option value="dga">Dagaare</option><option value="din">ThuÉ”Å‹jÃ¤Å‹</option><option value="diq">Zazaki</option><option value="dsb">dolnoserbski</option><option value="dtp">Kadazandusun</option><option value="dty">à¤¡à¥‹à¤Ÿà¥‡à¤²à¥€</option><option value="dua">DuÃ¡lÃ¡</option><option value="dv">Ş‹Ş¨ŞˆŞ¬Ş€Ş¨Ş„Ş¦ŞŞ°</option><option value="dz">à½‡à½¼à½„à¼‹à½</option><option value="ee">eÊ‹egbe</option><option value="efi">Efá»‹k</option><option value="egl">emiliÃ n e rumagnÃ²l</option><option value="el">Î•Î»Î»Î·Î½Î¹ÎºÎ¬</option><option value="eml">emiliÃ n e rumagnÃ²l</option><option value="en" selected="">English</option><option value="en-ca">Canadian English</option><option value="en-gb">British English</option><option value="eo">Esperanto</option><option value="es">espaÃ±ol</option><option value="es-formal">espaÃ±ol (formal)</option><option value="et">eesti</option><option value="eu">euskara</option><option value="ext">estremeÃ±u</option><option value="fa">ÙØ§Ø±Ø³ÛŒ</option><option value="fat">mfantse</option><option value="ff">Fulfulde</option><option value="fi">suomi</option><option value="fit">meÃ¤nkieli</option><option value="fj">Na Vosa Vakaviti</option><option value="fo">fÃ¸royskt</option><option value="fon">fÉ”Ì€ngbÃ¨</option><option value="fr">franÃ§ais</option><option value="frc">franÃ§ais cadien</option><option value="frp">arpetan</option><option value="frr">Nordfriisk</option><option value="fur">furlan</option><option value="fy">Frysk</option><option value="ga">Gaeilge</option><option value="gaa">Ga</option><option value="gag">Gagauz</option><option value="gan">è´›èª</option><option value="gan-hans">èµ£è¯­ï¼ˆç®€ä½“ï¼‰</option><option value="gan-hant">è´›èªï¼ˆç¹é«”ï¼‰</option><option value="gcf">krÃ©yÃ²l Gwadloup</option><option value="gcr">kriyÃ²l gwiyannen</option><option value="gd">GÃ idhlig</option><option value="gl">galego</option><option value="gld">Ğ½Ğ°Ì„Ğ½Ğ¸</option><option value="glk">Ú¯ÛŒÙ„Ú©ÛŒ</option><option value="gn">AvaÃ±e'áº½</option><option value="gom">à¤—à¥‹à¤‚à¤¯à¤šà¥€ à¤•à¥‹à¤‚à¤•à¤£à¥€ / GÃµychi Konknni</option><option value="gom-deva">à¤—à¥‹à¤‚à¤¯à¤šà¥€ à¤•à¥‹à¤‚à¤•à¤£à¥€</option><option value="gom-latn">GÃµychi Konknni</option><option value="gor">Bahasa Hulontalo</option><option value="got">ğŒ²ğŒ¿ğ„ğŒ¹ğƒğŒº</option><option value="gpe">Ghanaian Pidgin</option><option value="grc">á¼ˆÏÏ‡Î±Î¯Î± á¼‘Î»Î»Î·Î½Î¹Îºá½´</option><option value="gsw">Alemannisch</option><option value="gu">àª—à«àªœàª°àª¾àª¤à«€</option><option value="guc">wayuunaiki</option><option value="gur">farefare</option><option value="guw">gungbe</option><option value="gv">Gaelg</option><option value="ha">Hausa</option><option value="hak">å®¢å®¶èª / Hak-kÃ¢-ngÃ®</option><option value="haw">HawaiÊ»i</option><option value="he">×¢×‘×¨×™×ª</option><option value="hi">à¤¹à¤¿à¤¨à¥à¤¦à¥€</option><option value="hif">Fiji Hindi</option><option value="hif-latn">Fiji Hindi</option><option value="hil">Ilonggo</option><option value="hno">ÛÙ†Ø¯Ú©Ùˆ</option><option value="hr">hrvatski</option><option value="hrx">Hunsrik</option><option value="hsb">hornjoserbsce</option><option value="hsn">æ¹˜èª</option><option value="ht">KreyÃ²l ayisyen</option><option value="hu">magyar</option><option value="hu-formal">magyar (formal)</option><option value="hy">Õ°Õ¡ÕµÕ¥Ö€Õ¥Õ¶</option><option value="hyw">Ô±Ö€Õ¥Ö‚Õ´Õ¿Õ¡Õ°Õ¡ÕµÕ¥Ö€Õ§Õ¶</option><option value="ia">interlingua</option><option value="iba">Jaku Iban</option><option value="ibb">ibibio</option><option value="id">Bahasa Indonesia</option><option value="ie">Interlingue</option><option value="ig">Igbo</option><option value="igl">Igala</option><option value="ii">ê†‡ê‰™</option><option value="ik">IÃ±upiatun</option><option value="ike-cans">áƒá“„á’ƒá‘á‘á‘¦</option><option value="ike-latn">inuktitut</option><option value="ilo">Ilokano</option><option value="inh">Ğ³Ó€Ğ°Ğ»Ğ³Ó€Ğ°Ğ¹</option><option value="io">Ido</option><option value="is">Ã­slenska</option><option value="isv-cyrl">Ğ¼ĞµĞ´Ğ¶ÑƒÑĞ»Ğ¾Ğ²Ñ˜Ğ°Ğ½ÑĞºÑ‹</option><option value="isv-latn">medÅ¾uslovjansky</option><option value="it">italiano</option><option value="iu">áƒá“„á’ƒá‘á‘á‘¦ / inuktitut</option><option value="ja">æ—¥æœ¬èª</option><option value="jam">Patois</option><option value="jbo">la .lojban.</option><option value="jut">jysk</option><option value="jv">Jawa</option><option value="ka">áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒ˜</option><option value="kaa">Qaraqalpaqsha</option><option value="kab">Taqbaylit</option><option value="kai">Karai-karai</option><option value="kbd">Ğ°Ğ´Ñ‹Ğ³ÑĞ±Ğ·Ñ</option><option value="kbd-cyrl">Ğ°Ğ´Ñ‹Ğ³ÑĞ±Ğ·Ñ</option><option value="kbp">KabÉ©yÉ›</option><option value="kcg">Tyap</option><option value="kea">kabuverdianu</option><option value="kg">Kongo</option><option value="kge">Kumoring</option><option value="khw">Ú©Ú¾ÙˆØ§Ø±</option><option value="ki">GÄ©kÅ©yÅ©</option><option value="kiu">KÄ±rmancki</option><option value="kjh">Ñ…Ğ°ĞºĞ°Ñ</option><option value="kjp">á€–á á€¯á€¶á€œá€­á€€á€º</option><option value="kk">Ò›Ğ°Ğ·Ğ°Ò›ÑˆĞ°</option><option value="kk-arab">Ù‚Ø§Ø²Ø§Ù‚Ø´Ø§ (ØªÙ´ÙˆØªÛ•)</option><option value="kk-cn">Ù‚Ø§Ø²Ø§Ù‚Ø´Ø§ (Ø¬Û‡Ù†Ú¯Ùˆ)</option><option value="kk-cyrl">Ò›Ğ°Ğ·Ğ°Ò›ÑˆĞ° (ĞºĞ¸Ñ€Ğ¸Ğ»)</option><option value="kk-kz">Ò›Ğ°Ğ·Ğ°Ò›ÑˆĞ° (ÒšĞ°Ğ·Ğ°Ò›ÑÑ‚Ğ°Ğ½)</option><option value="kk-latn">qazaqÅŸa (latÄ±n)</option><option value="kk-tr">qazaqÅŸa (TÃ¼rkÃ¯ya)</option><option value="kl">kalaallisut</option><option value="km">á—á¶áŸá¶ááŸ’á˜áŸ‚áš</option><option value="kn">à²•à²¨à³à²¨à²¡</option><option value="knc">Yerwa Kanuri</option><option value="ko">í•œêµ­ì–´</option><option value="ko-kp">ì¡°ì„ ë§</option><option value="koi">Ğ¿ĞµÑ€ĞµĞ¼ ĞºĞ¾Ğ¼Ğ¸</option><option value="kr">kanuri</option><option value="krc">ĞºÑŠĞ°Ñ€Ğ°Ñ‡Ğ°Ğ¹-Ğ¼Ğ°Ğ»ĞºÑŠĞ°Ñ€</option><option value="kri">Krio</option><option value="krj">Kinaray-a</option><option value="krl">karjal</option><option value="ks">à¤•à¥‰à¤¶à¥à¤° / Ú©Ù²Ø´ÙØ±</option><option value="ks-arab">Ú©Ù²Ø´ÙØ±</option><option value="ks-deva">à¤•à¥‰à¤¶à¥à¤°</option><option value="ksh">Ripoarisch</option><option value="ksw">á€…á€¾á€®á¤</option><option value="ku">kurdÃ®</option><option value="ku-arab">Ú©ÙˆØ±Ø¯ÛŒ (Ø¹Û•Ø±Û•Ø¨ÛŒ)</option><option value="ku-latn">kurdÃ® (latÃ®nÃ®)</option><option value="kum">ĞºÑŠÑƒĞ¼ÑƒĞºÑŠ</option><option value="kus">KÊ‹saal</option><option value="kv">ĞºĞ¾Ğ¼Ğ¸</option><option value="kw">kernowek</option><option value="ky">ĞºÑ‹Ñ€Ğ³Ñ‹Ğ·Ñ‡Ğ°</option><option value="la">Latina</option><option value="lad">Ladino</option><option value="lb">LÃ«tzebuergesch</option><option value="lbe">Ğ»Ğ°ĞºĞºÑƒ</option><option value="lez">Ğ»ĞµĞ·Ğ³Ğ¸</option><option value="lfn">Lingua Franca Nova</option><option value="lg">Luganda</option><option value="li">Limburgs</option><option value="lij">Ligure</option><option value="liv">LÄ«vÃµ kÄ“Ä¼</option><option value="lki">Ù„Û•Ú©ÛŒ</option><option value="lld">Ladin</option><option value="lmo">lombard</option><option value="ln">lingÃ¡la</option><option value="lo">àº¥àº²àº§</option><option value="loz">Silozi</option><option value="lrc">Ù„ÛŠØ±ÛŒ Ø´ÙˆÙ…Ø§Ù„ÛŒ</option><option value="lt">lietuviÅ³</option><option value="ltg">latgaÄ¼u</option><option value="lua">ciluba</option><option value="lus">Mizo Å£awng</option><option value="luz">Ù„Ø¦Ø±ÛŒ Ø¯ÙˆÙ™Ù…ÛŒÙ†ÛŒ</option><option value="lv">latvieÅ¡u</option><option value="lzh">æ–‡è¨€</option><option value="lzz">Lazuri</option><option value="mad">MadhurÃ¢</option><option value="mag">à¤®à¤—à¤¹à¥€</option><option value="mai">à¤®à¥ˆà¤¥à¤¿à¤²à¥€</option><option value="map-bms">Basa Banyumasan</option><option value="mdf">Ğ¼Ğ¾ĞºÑˆĞµĞ½ÑŒ</option><option value="mg">Malagasy</option><option value="mhr">Ğ¾Ğ»Ñ‹Ğº Ğ¼Ğ°Ñ€Ğ¸Ğ¹</option><option value="mi">MÄori</option><option value="min">Minangkabau</option><option value="mk">Ğ¼Ğ°ĞºĞµĞ´Ğ¾Ğ½ÑĞºĞ¸</option><option value="ml">à´®à´²à´¯à´¾à´³à´‚</option><option value="mn">Ğ¼Ğ¾Ğ½Ğ³Ğ¾Ğ»</option><option value="mnc">manju gisun</option><option value="mnc-latn">manju gisun</option><option value="mnc-mong">á ®á  á ¨á µá¡  á¡¤á¡³á °á¡ á ¨</option><option value="mni">ê¯ƒê¯¤ê¯‡ê¯© ê¯‚ê¯£ê¯Ÿ</option><option value="mnw">á€˜á€¬á€á€¬á€™á€”á€º</option><option value="mo">Ğ¼Ğ¾Ğ»Ğ´Ğ¾Ğ²ĞµĞ½ÑÑĞºÑ</option><option value="mos">moore</option><option value="mr">à¤®à¤°à¤¾à¤ à¥€</option><option value="mrh">Mara</option><option value="mrj">ĞºÑ‹Ñ€Ñ‹Ğº Ğ¼Ğ°Ñ€Ñ‹</option><option value="ms">Bahasa Melayu</option><option value="ms-arab">Ø¨Ù‡Ø§Ø³ Ù…Ù„Ø§ÙŠÙˆ</option><option value="mt">Malti</option><option value="mui">Baso Palembang</option><option value="mwl">MirandÃ©s</option><option value="my">á€™á€¼á€”á€ºá€™á€¬á€˜á€¬á€á€¬</option><option value="myv">ÑÑ€Ğ·ÑĞ½ÑŒ</option><option value="mzn">Ù…Ø§Ø²ÙØ±ÙˆÙ†ÛŒ</option><option value="na">Dorerin Naoero</option><option value="nah">NÄhuatl</option><option value="nan">é–©å—èª / BÃ¢n-lÃ¢m-gÃº</option><option value="nan-hant">é–©å—èªï¼ˆå‚³çµ±æ¼¢å­—ï¼‰</option><option value="nan-latn-pehoeji">BÃ¢n-lÃ¢m-gÃº (PeÌh-Åe-jÄ«)</option><option value="nan-latn-tailo">BÃ¢n-lÃ¢m-gÃº (TÃ¢i-lÃ´)</option><option value="nap">Napulitano</option><option value="nb">norsk bokmÃ¥l</option><option value="nds">PlattdÃ¼Ã¼tsch</option><option value="nds-nl">Nedersaksies</option><option value="ne">à¤¨à¥‡à¤ªà¤¾à¤²à¥€</option><option value="new">à¤¨à¥‡à¤ªà¤¾à¤² à¤­à¤¾à¤·à¤¾</option><option value="nia">Li Niha</option><option value="nit">à°•à±Šà°²à°¾à°®à°¿</option><option value="niu">NiuÄ“</option><option value="nl">Nederlands</option><option value="nl-informal">Nederlands (informeel)</option><option value="nmz">nawdm</option><option value="nn">norsk nynorsk</option><option value="nod">á¨£á©¤á©´á¨¾á©®á©¬á©¥á¨¦</option><option value="nog">Ğ½Ğ¾Ğ³Ğ°Ğ¹ÑˆĞ°</option><option value="nov">Novial</option><option value="nqo">ß’ßß</option><option value="nr">isiNdebele seSewula</option><option value="nrm">Nouormand</option><option value="nso">Sesotho sa Leboa</option><option value="nup">Nupe</option><option value="nv">DinÃ© bizaad</option><option value="ny">Chi-Chewa</option><option value="nyn">runyankore</option><option value="nyo">Orunyoro</option><option value="nys">Nyunga</option><option value="oc">occitan</option><option value="ojb">Ojibwemowin</option><option value="olo">livvinkarjala</option><option value="om">Oromoo</option><option value="or">à¬“à¬¡à¬¼à¬¿à¬†</option><option value="os">Ğ¸Ñ€Ğ¾Ğ½</option><option value="pa">à¨ªà©°à¨œà¨¾à¨¬à©€</option><option value="pag">Pangasinan</option><option value="pam">Kapampangan</option><option value="pap">Papiamentu</option><option value="pcd">Picard</option><option value="pcm">NaijÃ¡</option><option value="pdc">Deitsch</option><option value="pdt">Plautdietsch</option><option value="pfl">PÃ¤lzisch</option><option value="pi">à¤ªà¤¾à¤²à¤¿</option><option value="pih">Norfuk / Pitkern</option><option value="pl">polski</option><option value="pms">PiemontÃ¨is</option><option value="pnb">Ù¾Ù†Ø¬Ø§Ø¨ÛŒ</option><option value="pnt">Î Î¿Î½Ï„Î¹Î±ÎºÎ¬</option><option value="prg">prÅ«siskan</option><option value="ps">Ù¾ÚšØªÙˆ</option><option value="pt">portuguÃªs</option><option value="pt-br">portuguÃªs do Brasil</option><option value="pwn">pinayuanan</option><option value="qqq">Message documentation</option><option value="qu">Runa Simi</option><option value="qug">Runa shimi</option><option value="rgn">RumagnÃ´l</option><option value="rif">Tarifit</option><option value="rki">á€›á€á€­á€¯á€„á€º</option><option value="rm">rumantsch</option><option value="rmc">romaÅˆi Ähib</option><option value="rmy">romani Ähib</option><option value="rn">ikirundi</option><option value="ro">romÃ¢nÄƒ</option><option value="roa-tara">tarandÃ­ne</option><option value="rsk">Ñ€ÑƒÑĞºĞ¸</option><option value="ru">Ñ€ÑƒÑÑĞºĞ¸Ğ¹</option><option value="rue">Ñ€ÑƒÑĞ¸Ğ½ÑŒÑĞºÑ‹Ğ¹</option><option value="rup">armÃ£neashti</option><option value="ruq">VlÄƒheÅŸte</option><option value="ruq-cyrl">Ğ’Ğ»Ğ°Ñ…ĞµÑÑ‚Ğµ</option><option value="ruq-latn">VlÄƒheÅŸte</option><option value="rut">Ğ¼Ñ‹Ñ…Ğ°Ó€Ğ±Ğ¸ÑˆĞ´Ñ‹</option><option value="rw">Ikinyarwanda</option><option value="ryu">ã†ã¡ãªãƒ¼ãã¡</option><option value="sa">à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤®à¥</option><option value="sah">ÑĞ°Ñ…Ğ° Ñ‚Ñ‹Ğ»Ğ°</option><option value="sat">á±¥á±Ÿá±±á±›á±Ÿá±²á±¤</option><option value="sc">sardu</option><option value="scn">sicilianu</option><option value="sco">Scots</option><option value="sd">Ø³Ù†ÚŒÙŠ</option><option value="sdc">Sassaresu</option><option value="sdh">Ú©ÙˆØ±Ø¯ÛŒ Ø®ÙˆØ§Ø±Ú¯</option><option value="se">davvisÃ¡megiella</option><option value="se-fi">davvisÃ¡megiella (Suoma bealde)</option><option value="se-no">davvisÃ¡megiella (Norgga bealde)</option><option value="se-se">davvisÃ¡megiella (RuoÅ§a bealde)</option><option value="sei">Cmique Itom</option><option value="ses">Koyraboro Senni</option><option value="sg">SÃ¤ngÃ¶</option><option value="sgs">Å¾emaitÄ—Å¡ka</option><option value="sh">srpskohrvatski / ÑÑ€Ğ¿ÑĞºĞ¾Ñ…Ñ€Ğ²Ğ°Ñ‚ÑĞºĞ¸</option><option value="sh-cyrl">ÑÑ€Ğ¿ÑĞºĞ¾Ñ…Ñ€Ğ²Ğ°Ñ‚ÑĞºĞ¸ (Ñ›Ğ¸Ñ€Ğ¸Ğ»Ğ¸Ñ†Ğ°)</option><option value="sh-latn">srpskohrvatski (latinica)</option><option value="shi">Taclá¸¥it</option><option value="shn">á½á‚ƒá‚‡á€á‚ƒá‚‡á€á‚†á€¸ </option><option value="shy">tacawit</option><option value="shy-latn">tacawit</option><option value="si">à·ƒà·’à¶‚à·„à¶½</option><option value="sjd">ĞºÓ£Ğ»Ğ»Ñ‚ ÑĞ°Ì„Ğ¼ÑŒ ĞºÓ£Ğ»Ğ»</option><option value="sje">bidumsÃ¡megiella</option><option value="sk">slovenÄina</option><option value="skr">Ø³Ø±Ø§Ø¦ÛŒÚ©ÛŒ</option><option value="skr-arab">Ø³Ø±Ø§Ø¦ÛŒÚ©ÛŒ</option><option value="sl">slovenÅ¡Äina</option><option value="sli">SchlÃ¤sch</option><option value="sm">Gagana Samoa</option><option value="sma">Ã¥arjelsaemien</option><option value="smn">anarÃ¢Å¡kielÃ¢</option><option value="sms">nuÃµrttsÃ¤Ã¤Ê¹mÇ©iÃµll</option><option value="sn">chiShona</option><option value="so">Soomaaliga</option><option value="sq">shqip</option><option value="sr">ÑÑ€Ğ¿ÑĞºĞ¸ / srpski</option><option value="sr-ec">ÑÑ€Ğ¿ÑĞºĞ¸ (Ñ›Ğ¸Ñ€Ğ¸Ğ»Ğ¸Ñ†Ğ°)</option><option value="sr-el">srpski (latinica)</option><option value="srn">Sranantongo</option><option value="sro">sardu campidanesu</option><option value="ss">SiSwati</option><option value="st">Sesotho</option><option value="stq">Seeltersk</option><option value="sty">ÑĞµĞ±ĞµÑ€Ñ‚Ğ°Ñ‚Ğ°Ñ€</option><option value="su">Sunda</option><option value="sv">svenska</option><option value="sw">Kiswahili</option><option value="syl">ê ê ¤ê Ÿê ê ¤</option><option value="szl">Å›lÅ¯nski</option><option value="szy">Sakizaya</option><option value="ta">à®¤à®®à®¿à®´à¯</option><option value="tay">Tayal</option><option value="tcy">à²¤à³à²³à³</option><option value="tdd">á¥–á¥­á¥° á¥–á¥¬á¥² á¥‘á¥¨á¥’á¥°</option><option value="te">à°¤à±†à°²à±à°—à±</option><option value="tet">tetun</option><option value="tg">Ñ‚Ğ¾Ò·Ğ¸ĞºÓ£</option><option value="tg-cyrl">Ñ‚Ğ¾Ò·Ğ¸ĞºÓ£</option><option value="tg-latn">tojikÄ«</option><option value="th">à¹„à¸—à¸¢</option><option value="ti">á‰µáŒáˆ­áŠ›</option><option value="tig">á‰µáŒáˆ¬</option><option value="tk">TÃ¼rkmenÃ§e</option><option value="tl">Tagalog</option><option value="tly">tolÄ±ÅŸi</option><option value="tn">Setswana</option><option value="to">lea faka-Tonga</option><option value="tok">toki pona</option><option value="tpi">Tok Pisin</option><option value="tr">TÃ¼rkÃ§e</option><option value="tru">á¹ªuroyo</option><option value="trv">Seediq</option><option value="ts">Xitsonga</option><option value="tt">Ñ‚Ğ°Ñ‚Ğ°Ñ€Ñ‡Ğ° / tatarÃ§a</option><option value="tt-cyrl">Ñ‚Ğ°Ñ‚Ğ°Ñ€Ñ‡Ğ°</option><option value="tt-latn">tatarÃ§a</option><option value="ttj">Orutooro</option><option value="tum">chiTumbuka</option><option value="tw">Twi</option><option value="ty">reo tahiti</option><option value="tyv">Ñ‚Ñ‹Ğ²Ğ° Ğ´Ñ‹Ğ»</option><option value="tzm">âµœâ´°âµâ´°âµ£âµ‰âµ–âµœ</option><option value="udm">ÑƒĞ´Ğ¼ÑƒÑ€Ñ‚</option><option value="ug">Ø¦Û‡ÙŠØºÛ‡Ø±Ú†Û• / Uyghurche</option><option value="ug-arab">Ø¦Û‡ÙŠØºÛ‡Ø±Ú†Û•</option><option value="ug-latn">Uyghurche</option><option value="uk">ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°</option><option value="ur">Ø§Ø±Ø¯Ùˆ</option><option value="uz">oÊ»zbekcha / ÑĞ·Ğ±ĞµĞºÑ‡Ğ°</option><option value="ve">Tshivenda</option><option value="vec">vÃ¨neto</option><option value="vep">vepsÃ¤n kelâ€™</option><option value="vi">Tiáº¿ng Viá»‡t</option><option value="vls">West-Vlams</option><option value="vmf">MainfrÃ¤nkisch</option><option value="vmw">emakhuwa</option><option value="vo">VolapÃ¼k</option><option value="vot">VaÄÄa</option><option value="vro">vÃµro</option><option value="wa">walon</option><option value="wal">wolaytta</option><option value="war">Winaray</option><option value="wls">FakaÊ»uvea</option><option value="wo">Wolof</option><option value="wuu">å´è¯­</option><option value="wuu-hans">å´è¯­ï¼ˆç®€ä½“ï¼‰</option><option value="wuu-hant">å³èªï¼ˆæ­£é«”ï¼‰</option><option value="xal">Ñ…Ğ°Ğ»ÑŒĞ¼Ğ³</option><option value="xh">isiXhosa</option><option value="xmf">áƒ›áƒáƒ áƒ’áƒáƒšáƒ£áƒ áƒ˜</option><option value="xsy">saisiyat</option><option value="yi">×™×™Ö´×“×™×©</option><option value="yo">YorÃ¹bÃ¡</option><option value="yrl">Nháº½áº½gatÃº</option><option value="yue">ç²µèª</option><option value="yue-hans">ç²µè¯­ï¼ˆç®€ä½“ï¼‰</option><option value="yue-hant">ç²µèªï¼ˆç¹é«”ï¼‰</option><option value="za">Vahcuengh</option><option value="zea">ZeÃªuws</option><option value="zgh">âµœâ´°âµâ´°âµ£âµ‰âµ–âµœ âµœâ´°âµâ´°âµ¡â´°âµ¢âµœ</option><option value="zh">ä¸­æ–‡</option><option value="zh-cn">ä¸­æ–‡ï¼ˆä¸­å›½å¤§é™†ï¼‰</option><option value="zh-hans">ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰</option><option value="zh-hant">ä¸­æ–‡ï¼ˆç¹é«”ï¼‰</option><option value="zh-hk">ä¸­æ–‡ï¼ˆé¦™æ¸¯ï¼‰</option><option value="zh-mo">ä¸­æ–‡ï¼ˆæ¾³é–€ï¼‰</option><option value="zh-my">ä¸­æ–‡ï¼ˆé©¬æ¥è¥¿äºšï¼‰</option><option value="zh-sg">ä¸­æ–‡ï¼ˆæ–°åŠ å¡ï¼‰</option><option value="zh-tw">ä¸­æ–‡ï¼ˆè‡ºç£ï¼‰</option><option value="zu">isiZulu</option></select><input id="languageselector-commit-1" style="" type="submit" value="set"></form></span></div>
	</div>
	<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">TensorFlow</span></h1>
	<div id="bodyContent" class="vector-body">
		<div id="siteSub" class="noprint">From Alliance Doc</div>
		<div id="contentSub"><div id="mw-content-subtitle"><span class="mw-redirectedfrom">(Redirected from <a href="/mediawiki/index.php?title=Tensorflow&amp;redirect=no" class="mw-redirect" title="Tensorflow">Tensorflow</a>)</span></div></div>
		<div id="contentSub2"></div>
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" class="mw-body-content"><div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><div class="mw-pt-languages noprint navigation-not-searchable" lang="en" dir="ltr"><div class="mw-pt-languages-label">Other languages:</div><ul class="mw-pt-languages-list"><li><span class="mw-pt-languages-ui mw-pt-languages-selected mw-pt-progress mw-pt-progress--complete" lang="en" dir="ltr">English</span></li>
<li><a href="/wiki/TensorFlow/fr" class="mw-pt-progress mw-pt-progress--complete" title="TensorFlow (100% translated)" lang="fr" dir="ltr">franÃ§ais</a></li></ul></div> 
<p><a rel="nofollow" class="external text" href="https://www.tensorflow.org/">TensorFlow</a> is <i>an open-source software library for Machine Intelligence</i>.
</p><p>If you are porting a TensorFlow program to an Alliance cluster, you should follow <a href="/wiki/Tutoriel_Apprentissage_machine/en" title="Tutoriel Apprentissage machine/en">our tutorial on machine learning</a>.
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Installing_TensorFlow"><span class="tocnumber">1</span> <span class="toctext">Installing TensorFlow</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#R_package"><span class="tocnumber">1.1</span> <span class="toctext">R package</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-3"><a href="#Submitting_a_TensorFlow_job_with_a_GPU"><span class="tocnumber">2</span> <span class="toctext">Submitting a TensorFlow job with a GPU</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Monitoring"><span class="tocnumber">3</span> <span class="toctext">Monitoring</span></a>
<ul>
<li class="toclevel-2 tocsection-5"><a href="#TensorBoard"><span class="tocnumber">3.1</span> <span class="toctext">TensorBoard</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6"><a href="#TensorFlow_with_multi-GPUs"><span class="tocnumber">4</span> <span class="toctext">TensorFlow with multi-GPUs</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#TensorFlow_1.x"><span class="tocnumber">4.1</span> <span class="toctext">TensorFlow 1.x</span></a>
<ul>
<li class="toclevel-3 tocsection-8"><a href="#Parameter_server"><span class="tocnumber">4.1.1</span> <span class="toctext">Parameter server</span></a></li>
<li class="toclevel-3 tocsection-9"><a href="#Replicated"><span class="tocnumber">4.1.2</span> <span class="toctext">Replicated</span></a></li>
<li class="toclevel-3 tocsection-10"><a href="#Benchmarks"><span class="tocnumber">4.1.3</span> <span class="toctext">Benchmarks</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-11"><a href="#TensorFlow_2.x"><span class="tocnumber">4.2</span> <span class="toctext">TensorFlow 2.x</span></a>
<ul>
<li class="toclevel-3 tocsection-12"><a href="#Mirrored_strategy"><span class="tocnumber">4.2.1</span> <span class="toctext">Mirrored strategy</span></a>
<ul>
<li class="toclevel-4 tocsection-13"><a href="#Single_node"><span class="tocnumber">4.2.1.1</span> <span class="toctext">Single node</span></a></li>
<li class="toclevel-4 tocsection-14"><a href="#Multiple_nodes"><span class="tocnumber">4.2.1.2</span> <span class="toctext">Multiple nodes</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-15"><a href="#Horovod"><span class="tocnumber">4.2.2</span> <span class="toctext">Horovod</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-16"><a href="#Creating_model_checkpoints"><span class="tocnumber">5</span> <span class="toctext">Creating model checkpoints</span></a>
<ul>
<li class="toclevel-2 tocsection-17"><a href="#With_Keras"><span class="tocnumber">5.1</span> <span class="toctext">With Keras</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#With_a_custom_training_loop"><span class="tocnumber">5.2</span> <span class="toctext">With a custom training loop</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Custom_TensorFlow_operators"><span class="tocnumber">6</span> <span class="toctext">Custom TensorFlow operators</span></a>
<ul>
<li class="toclevel-2 tocsection-20"><a href="#TensorFlow_&lt;=_1.4.x"><span class="tocnumber">6.1</span> <span class="toctext">TensorFlow &lt;= 1.4.x</span></a></li>
<li class="toclevel-2 tocsection-21"><a href="#TensorFlow_&gt;_1.4.x"><span class="tocnumber">6.2</span> <span class="toctext">TensorFlow &gt; 1.4.x</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-22"><a href="#Troubleshooting"><span class="tocnumber">7</span> <span class="toctext">Troubleshooting</span></a>
<ul>
<li class="toclevel-2 tocsection-23"><a href="#scikit_image"><span class="tocnumber">7.1</span> <span class="toctext">scikit image</span></a></li>
<li class="toclevel-2 tocsection-24"><a href="#libcupti.so"><span class="tocnumber">7.2</span> <span class="toctext">libcupti.so</span></a></li>
<li class="toclevel-2 tocsection-25"><a href="#libiomp5.so_invalid_ELF_header"><span class="tocnumber">7.3</span> <span class="toctext">libiomp5.so invalid ELF header</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-26"><a href="#Controlling_the_number_of_CPUs_and_threads"><span class="tocnumber">8</span> <span class="toctext">Controlling the number of CPUs and threads</span></a>
<ul>
<li class="toclevel-2 tocsection-27"><a href="#TensorFlow_1.x_2"><span class="tocnumber">8.1</span> <span class="toctext">TensorFlow 1.x</span></a></li>
<li class="toclevel-2 tocsection-28"><a href="#TensorFlow_2.x_2"><span class="tocnumber">8.2</span> <span class="toctext">TensorFlow 2.x</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-29"><a href="#Known_issues"><span class="tocnumber">9</span> <span class="toctext">Known issues</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Installing_TensorFlow">Installing TensorFlow</span></h2>
<p>These instructions install TensorFlow in your /home directory using Alliance's prebuilt <a rel="nofollow" class="external text" href="http://pythonwheels.com/">Python wheels</a>. Custom Python wheels are stored in <code>/cvmfs/soft.computecanada.ca/custom/python/wheelhouse/</code>. To install a TensorFlow wheel, we will use the <code>pip</code> command and install it into a <a href="/wiki/Python#Creating_and_using_a_virtual_environment" title="Python"> Python virtual environment</a>.
</p>
<form id="tabs-inputform" class="tabs tabs-inputform" action="#"></form><div class="tabs tabs-tabbox"><input type="radio" form="tabs-inputform" id="tabs-input-1-0" name="tabs-1" class="tabs-input tabs-input-0" checked="" /><input type="radio" form="tabs-inputform" id="tabs-input-1-1" name="tabs-1" class="tabs-input tabs-input-1" /><label class="tabs-label" for="tabs-input-1-1" data-tabpos="1">TF 2.x</label><wbr /><input type="radio" form="tabs-inputform" id="tabs-input-1-2" name="tabs-1" class="tabs-input tabs-input-2" /><label class="tabs-label" for="tabs-input-1-2" data-tabpos="2">TF 1.x</label><wbr /><div class="tabs-container" style="">
<div class="tabs-content tabs-content-1">
<p>Load modules required by TensorFlow. In some cases, other modules may be required (e.g. CUDA).
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>python/3
</pre></div></div>
<p><br />
Create a new Python virtual environment.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>virtualenv<span class="w"> </span>--no-download<span class="w"> </span>tensorflow
</pre></div></div>
<p><br />
Activate your newly created Python virtual environment.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span><span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
</pre></div></div>
<p><br />
Install TensorFlow in your newly created virtual environment using the following command.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span> <span class="gp">[name@server ~]$ </span>pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.8
</pre></div></div>
</div>
<div class="tabs-content tabs-content-2">
<p>Load modules required by TensorFlow. TF 1.x requires StdEnv/2018.
</p><p><b>Note: TF 1.x is not available on Narval, since StdEnv/2018 is not available on this cluster.</b>
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>StdEnv/2018<span class="w"> </span>python/3
</pre></div></div>
<p><br />
Create a new Python virtual environment.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>virtualenv<span class="w"> </span>--no-download<span class="w"> </span>tensorflow
</pre></div></div>
<p><br />
Activate your newly created Python virtual environment.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span><span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
</pre></div></div>
<p><br />
Install TensorFlow in your newly created virtual environment using one of the commands below, depending on whether you need to use a GPU.
</p><p><b>Do not</b> install the <code>tensorflow</code> package (without the <code>_cpu</code> or <code>_gpu</code> suffixes) as it has compatibility issues with other libraries.
</p>
<h3><span class="mw-headline" id="CPU-only">CPU-only</span></h3>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span> <span class="gp">[name@server ~]$ </span>pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow_cpu</span><span class="o">==</span><span class="m">1</span>.15.0
</pre></div></div>
<p><br />
</p>
<h3><span class="mw-headline" id="GPU">GPU</span></h3>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span> <span class="gp">[name@server ~]$ </span>pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow_gpu</span><span class="o">==</span><span class="m">1</span>.15.0
</pre></div></div>
</div>
</div></div>
<p><br />
</p>
<h3><span class="mw-headline" id="R_package">R package</span></h3>
<p>To use TensorFlow in R, you will need to first follow the preceding instructions on creating a virtual environment and installing TensorFlow in it. Once this is done, follow these instructions.
</p><p>Load the required modules.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>module<span class="w"> </span>load<span class="w"> </span>gcc<span class="w"> </span>r
</pre></div></div>
<p>Activate your Python virtual environment.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span><span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
</pre></div></div>
<p>Launch R.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp gp-VirtualEnv">(tensorflow)</span><span class="gp">_[name@server ~]$ </span>R
</pre></div></div>
<p>In R, install package devtools, then tensorflow: 
</p>
<div class="mw-highlight mw-highlight-lang-r mw-content-ltr" dir="ltr"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&#39;devtools&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">repos</span><span class="o">=</span><span class="s">&#39;https://cloud.r-project.org&#39;</span><span class="p">)</span>
<span class="n">devtools</span><span class="o">::</span><span class="nf">install_github</span><span class="p">(</span><span class="s">&#39;rstudio/tensorflow&#39;</span><span class="p">)</span>
</pre></div>
<p>You are then good to go. Do not call <code>install_tensorflow()</code> in R, as TensorFlow has already been installed in your virtual environment with <code>pi</code>p. To use the TensorFlow installed in your virtual environment, enter the following commands in R after the environment has been activated.
</p>
<div class="mw-highlight mw-highlight-lang-r mw-content-ltr" dir="ltr"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">tensorflow</span><span class="p">)</span>
<span class="nf">use_virtualenv</span><span class="p">(</span><span class="nf">Sys.getenv</span><span class="p">(</span><span class="s">&#39;VIRTUAL_ENV&#39;</span><span class="p">))</span>
</pre></div>
<h2><span class="mw-headline" id="Submitting_a_TensorFlow_job_with_a_GPU">Submitting a TensorFlow job with a GPU</span></h2>
<p>Once you have the above setup completed, you can submit a TensorFlow job.
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@server ~]$ </span>sbatch<span class="w"> </span>tensorflow-test.sh
</pre></div></div>
<p>The job submission script contains
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-test.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--gres%3Dgpu%3A1++++++++%23+request+GPU+%22generic+resource%22%0A%23SBATCH+--cpus-per-task%3D6+++%23+maximum+CPU+cores+per+GPU+request%3A+6+on+Cedar%2C+16+on+Graham.%0A%23SBATCH+--mem%3D32000M++++++++%23+memory+per+node%0A%23SBATCH+--time%3D0-03%3A00++++++%23+time+%28DD-HH%3AMM%29%0A%23SBATCH+--output%3D%25N-%25j.out++%23+%25N+for+node+name%2C+%25j+for+jobID%0A%0Amodule+load+cuda+cudnn+%0Asource+tensorflow%2Fbin%2Factivate%0Apython+.%2Ftensorflow-test.py" />
<input type="hidden" name="filename" value="tensorflow-test.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --gres=gpu:1        # request GPU &quot;generic resource&quot;</span>
<span class="c1">#SBATCH --cpus-per-task=6   # maximum CPU cores per GPU request: 6 on Cedar, 16 on Graham.</span>
<span class="c1">#SBATCH --mem=32000M        # memory per node</span>
<span class="c1">#SBATCH --time=0-03:00      # time (DD-HH:MM)</span>
<span class="c1">#SBATCH --output=%N-%j.out  # %N for node name, %j for jobID</span>

module<span class="w"> </span>load<span class="w"> </span>cuda<span class="w"> </span>cudnn<span class="w"> </span>
<span class="nb">source</span><span class="w"> </span>tensorflow/bin/activate
python<span class="w"> </span>./tensorflow-test.py
</pre></div>
</div>
<p><br />
while the Python script has the form
</p>
<div class="tabs tabs-tabbox"><input type="radio" form="tabs-inputform" id="tabs-input-2-0" name="tabs-2" class="tabs-input tabs-input-0" checked="" /><input type="radio" form="tabs-inputform" id="tabs-input-2-1" name="tabs-2" class="tabs-input tabs-input-1" /><label class="tabs-label" for="tabs-input-2-1" data-tabpos="1">TF 2.x</label><wbr /><input type="radio" form="tabs-inputform" id="tabs-input-2-2" name="tabs-2" class="tabs-input tabs-input-2" /><label class="tabs-label" for="tabs-input-2-2" data-tabpos="2">TF 1.x</label><wbr /><div class="tabs-container" style="">
<div class="tabs-content tabs-content-1">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-test.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Anode1+%3D+tf.constant%283.0%29%0Anode2+%3D+tf.constant%284.0%29%0Aprint%28node1%2C+node2%29%0Aprint%28node1+%2B+node2%29" />
<input type="hidden" name="filename" value="tensorflow-test.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">node1</span> <span class="o">+</span> <span class="n">node2</span><span class="p">)</span>
</pre></div>
</div>
<p><br />
</p>
</div>
<div class="tabs-content tabs-content-2">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-test.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Anode1+%3D+tf.constant%283.0%29%0Anode2+%3D+tf.constant%284.0%29%0Aprint%28node1%2C+node2%29%0Asess+%3D+tf.Session%28%29%0Aprint%28sess.run%28node1+%2B+node2%29%29" />
<input type="hidden" name="filename" value="tensorflow-test.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">node1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>
<span class="n">node2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">node1</span> <span class="o">+</span> <span class="n">node2</span><span class="p">))</span>
</pre></div>
</div>
<p><br />
</p>
</div>
</div></div>
<p>Once the job has completed (should take less than a minute), you should see an output file called something like <code>cdr116-122907.out</code> with contents similar to the following (the logged messages from TensorFlow are only examples, expect different messages and more messages):
</p>
<div class="tabs tabs-tabbox"><input type="radio" form="tabs-inputform" id="tabs-input-3-0" name="tabs-3" class="tabs-input tabs-input-0" checked="" /><input type="radio" form="tabs-inputform" id="tabs-input-3-1" name="tabs-3" class="tabs-input tabs-input-1" /><label class="tabs-label" for="tabs-input-3-1" data-tabpos="1">TF 2.x</label><wbr /><input type="radio" form="tabs-inputform" id="tabs-input-3-2" name="tabs-3" class="tabs-input tabs-input-2" /><label class="tabs-label" for="tabs-input-3-2" data-tabpos="2">TF 1.x</label><wbr /><div class="tabs-container" style="">
<div class="tabs-content tabs-content-1">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> cdr116-122907.out</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="2017-07-10+12%3A35%3A19.491097%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A961%5D+DMA%3A+0%0A2017-07-10+12%3A35%3A19.491156%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A971%5D+0%3A+++Y%0A2017-07-10+12%3A35%3A19.520737%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A1030%5D+Creating+TensorFlow+device+%28%2Fgpu%3A0%29+-%3E+%28device%3A+0%2C+name%3A+Tesla+P100-PCIE-12GB%2C+pci+bus+id%3A+0000%3A82%3A00.0%29%0Atf.Tensor%283.0%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29+tf.Tensor%284.0%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29%0Atf.Tensor%287.0%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29" />
<input type="hidden" name="filename" value="cdr116-122907.out" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-text mw-content-ltr" dir="ltr"><pre><span></span>2017-07-10 12:35:19.491097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2017-07-10 12:35:19.491156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2017-07-10 12:35:19.520737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0)
tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)
tf.Tensor(7.0, shape=(), dtype=float32)
</pre></div>
</div>
<p><br />
</p>
</div>
<div class="tabs-content tabs-content-2">
<div class="code-file">
<div class="filename"><b>File&#160;:</b> cdr116-122907.out</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="2017-07-10+12%3A35%3A19.491097%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A961%5D+DMA%3A+0%0A2017-07-10+12%3A35%3A19.491156%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A971%5D+0%3A+++Y%0A2017-07-10+12%3A35%3A19.520737%3A+I+tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.cc%3A1030%5D+Creating+TensorFlow+device+%28%2Fgpu%3A0%29+-%3E+%28device%3A+0%2C+name%3A+Tesla+P100-PCIE-12GB%2C+pci+bus+id%3A+0000%3A82%3A00.0%29%0ATensor%28%22Const%3A0%22%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29+Tensor%28%22Const_1%3A0%22%2C+shape%3D%28%29%2C+dtype%3Dfloat32%29%0A7.0" />
<input type="hidden" name="filename" value="cdr116-122907.out" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-text mw-content-ltr" dir="ltr"><pre><span></span>2017-07-10 12:35:19.491097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2017-07-10 12:35:19.491156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2017-07-10 12:35:19.520737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0)
Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32)
7.0
</pre></div>
</div>
<p><br />
</p>
</div>
</div></div>
<p><br />
TensorFlow can run on all GPU node types. Cedar's <i>GPU large</i> node type, which is equipped with 4 x P100-PCIE-16GB with GPUDirect P2P enabled between each pair, is highly recommended for large-scale deep learning or machine learning research. See <a href="/wiki/Using_GPUs_with_SLURM" class="mw-redirect" title="Using GPUs with SLURM">Using GPUs with SLURM</a> for more information.
</p>
<h2><span class="mw-headline" id="Monitoring">Monitoring</span></h2>
<p>It is possible to connect to the node running a job and execute processes. This can be used to monitor resources used by TensorFlow and to visualize the progress of the training. See <a href="/wiki/Running_jobs#Attaching_to_a_running_job" title="Running jobs">Attaching to a running job</a> for examples.
</p>
<h3><span class="mw-headline" id="TensorBoard">TensorBoard</span></h3>
<p>TensorFlow comes with a suite of visualization tools called <a rel="nofollow" class="external text" href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard">TensorBoard</a>. TensorBoard operates by reading TensorFlow events and model files. To know how to create these files, read <a rel="nofollow" class="external text" href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard#serializing_the_data">TensorBoard tutorial on summaries</a>.
</p><p>TensorBoard requires too much processing power to be run on a login node. Users are strongly encouraged to execute it in the same job as the Tensorflow process. To do so, launch TensorBoard in the background by calling it before your python script, and appending an ampersand (<code>&amp;</code>) to the call:
</p>
<pre># Your SBATCH arguments here

tensorboard --logdir=/tmp/your_log_dir --host 0.0.0.0 --load_fast false &amp;
python train.py  # example
</pre>
<p>Once the job is running, to access TensorBoard with a web browser, you need to create a connection between your computer and the compute node running TensorFlow and TensorBoard. To do this you first need the hostname of the compute node running the Tensorboard server. Show the list of your jobs using the command <code>sq</code>; find the job, and note the value in the "NODELIST" column (this is the hostname).
</p><p>To create the connection, use the following command on your local computer:
</p>
<div class="command"><div class="mw-highlight mw-highlight-lang-shell-session mw-content-ltr" dir="ltr"><pre><span></span><span class="gp">[name@my_computer ~]$ </span>ssh<span class="w"> </span>-N<span class="w"> </span>-f<span class="w"> </span>-L<span class="w"> </span>localhost:6006:computenode:6006<span class="w"> </span>userid@cluster.computecanada.ca
</pre></div></div>
<p><br />
Replace <code>computenode</code> with the node hostname you retrieved from the preceding step, <code>userid</code> by your Alliance username, <code>cluster</code> by the cluster hostname (i.e.: <code>beluga</code>, <code>cedar</code>, <code>graham</code>, etc.). If port 6006 was already in use, tensorboard will be using another one (e.g. 6007, 6008...).
</p><p>Once the connection is created, go to <a rel="nofollow" class="external text" href="http://localhost:6006">http://localhost:6006</a>.
</p>
<h2><span class="mw-headline" id="TensorFlow_with_multi-GPUs">TensorFlow with multi-GPUs</span></h2>
<h3><span class="mw-headline" id="TensorFlow_1.x">TensorFlow 1.x</span></h3>
<p>TensorFlow provides different methods of managing variables when training models on multiple GPUs. "Parameter Server" and "Replicated" are the most two common methods. 
</p>
<ul><li>In this section, <a rel="nofollow" class="external text" href="https://github.com/tensorflow/benchmarks">TensorFlow Benchmarks</a> code will be used as an example to explain the different methods. Users can reference the TensorFlow Benchmarks code to implement their own.</li></ul>
<h4><span class="mw-headline" id="Parameter_server">Parameter server</span></h4>
<p>Variables are stored on a parameter server that holds the master copy of the variable. In distributed training, the parameter servers are separate processes in the different devices. For each step, each tower gets a copy of the variables from the parameter server, and sends its gradients to the param server.
</p><p>Parameters can be stored in a CPU:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=parameter_server --local_parameter_device=cpu
</pre>
<p>or a GPU:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=parameter_server --local_parameter_device=gpu
</pre>
<h4><span class="mw-headline" id="Replicated">Replicated</span></h4>
<p>With this method, each GPU has its own copy of the variables. To apply gradients, an all_reduce algorithm or or regular cross-device aggregation is used to replicate the combined gradients to all towers (depending on the all_reduce_spec parameter's setting).
</p><p>All reduce method can be default:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated
</pre>
<p>Xring --- use one global ring reduction for all tensors:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated --all_reduce_spec=xring
</pre>
<p>Pscpu --- use CPU at worker 0 to reduce all tensors:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated --all_reduce_spec=pscpu
</pre>
<p>NCCL --- use NCCL to locally reduce all tensors:
</p>
<pre>python tf_cnn_benchmarks.py --variable_update=replicated --all_reduce_spec=nccl
</pre>
<p>Different variable managing methods perform differently with different models. Users are highly recommended to test their own models with all methods on different types of GPU node.
</p>
<h4><span class="mw-headline" id="Benchmarks">Benchmarks</span></h4>
<p>This section will give ResNet-50 and VGG-16 benchmarking results on both Graham and Cedar with single and multiple GPUs using different methods for managing variables. TensorFlow v1.5 (built with CUDA 9 and cuDNN 7) is used. The benchmark can be found on github at <a rel="nofollow" class="external text" href="https://github.com/tensorflow/benchmarks">TensorFlow Benchmarks</a>. 
</p>
<ul><li>ResNet-50</li></ul>
<p>Batch size is 32 per GPU. Data parallelism is used. (Results in "images per second")
</p>
<table class="wikitable">

<tbody><tr>
<th>Node type</th>
<th>1 GPU</th>
<th>Number of GPUs</th>
<th>ps,cpu</th>
<th>ps, gpu</th>
<th>replicated</th>
<th>replicated, xring</th>
<th>replicated, pscpu</th>
<th>replicated, nccl
</th></tr>
<tr>
<td>Graham  GPU node</td>
<td>171.23</td>
<td>2</td>
<td>93.31</td>
<td><b>324.04</b></td>
<td>318.33</td>
<td>316.01</td>
<td>109.82</td>
<td>315.99
</td></tr>
<tr>
<td>Cedar GPU Base</td>
<td>172.99</td>
<td>4</td>
<td><b>662.65</b></td>
<td>595.43</td>
<td>616.02</td>
<td>490.03</td>
<td>645.04</td>
<td>608.95
</td></tr>
<tr>
<td>Cedar GPU Large</td>
<td>205.71</td>
<td>4</td>
<td>673.47</td>
<td>721.98</td>
<td><b>754.35</b></td>
<td>574.91</td>
<td>664.72</td>
<td>692.25
</td></tr></tbody></table>
<ul><li>VGG-16</li></ul>
<p>Batch size is 32 per GPU. Data parallelism is used.  (Results in <i>images per second</i>)
</p>
<table class="wikitable">

<tbody><tr>
<th>Node type</th>
<th>1 GPU</th>
<th>Number of GPUs</th>
<th>ps,cpu</th>
<th>ps, gpu</th>
<th>replicated</th>
<th>replicated, xring</th>
<th>replicated, pscpu</th>
<th>replicated, nccl
</th></tr>
<tr>
<td>Graham  GPU node</td>
<td>115.89</td>
<td>2</td>
<td>91.29</td>
<td>194.46</td>
<td>194.43</td>
<td>203.83</td>
<td>132.19</td>
<td><b>219.72</b>
</td></tr>
<tr>
<td>Cedar GPU Base</td>
<td>114.77</td>
<td>4</td>
<td>232.85</td>
<td>280.69</td>
<td>274.41</td>
<td>341.29</td>
<td>330.04</td>
<td><b>388.53</b>
</td></tr>
<tr>
<td>Cedar GPU Large</td>
<td>137.16</td>
<td>4</td>
<td>175.20</td>
<td>379.80</td>
<td>336.72</td>
<td>417.46</td>
<td>225.37</td>
<td><b>490.52</b>
</td></tr></tbody></table>
<h3><span class="mw-headline" id="TensorFlow_2.x">TensorFlow 2.x</span></h3>
<p>Much like TensorFlow 1.x, TensorFlow 2.x offers a number of different strategies to make use of multiple GPUs through the high-level API <code>tf.distribute</code>. In the following sections, we provide code examples of each strategy using Keras for simplicity. For more details, please refer to the official <a rel="nofollow" class="external text" href="https://www.tensorflow.org/api_docs/python/tf/distribute">TensorFlow documentation</a>.
</p>
<h4><span class="mw-headline" id="Mirrored_strategy">Mirrored strategy</span></h4>
<h5><span class="mw-headline" id="Single_node">Single node</span></h5>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-singleworker.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--nodes+1%0A%23SBATCH+--gres%3Dgpu%3A4%0A%0A%23SBATCH+--mem%3D8G++++++%0A%23SBATCH+--time%3D0-00%3A30%0A%23SBATCH+--output%3D%25N-%25j.out%0A%0Amodule+load+python%2F3%0Avirtualenv+--no-download+%24SLURM_TMPDIR%2Fenv%0Asource+%24SLURM_TMPDIR%2Fenv%2Fbin%2Factivate%0Apip+install+--no-index+tensorflow%0A%0Aexport+NCCL_BLOCKING_WAIT%3D1++%23Set+this+environment+variable+if+you+wish+to+use+the+NCCL+backend+for+inter-GPU+communication.%0A%0Apython+tensorflow-singleworker.py" />
<input type="hidden" name="filename" value="tensorflow-singleworker.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes 1</span>
<span class="c1">#SBATCH --gres=gpu:4</span>

<span class="c1">#SBATCH --mem=8G      </span>
<span class="c1">#SBATCH --time=0-00:30</span>
<span class="c1">#SBATCH --output=%N-%j.out</span>

module<span class="w"> </span>load<span class="w"> </span>python/3
virtualenv<span class="w"> </span>--no-download<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env
<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span>tensorflow

<span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_BLOCKING_WAIT</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1">#Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.</span>

python<span class="w"> </span>tensorflow-singleworker.py
</pre></div>
</div>
<p><br />
</p><p>The Python script <code>tensorflow-singleworker.py</code> has the form:
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-singleworker.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Aimport+numpy+as+np%0A%0Aimport+argparse%0A%0A%0Aparser+%3D+argparse.ArgumentParser%28description%3D%27cifar10+classification+models%2C+tensorflow+MirroredStrategy+test%27%29%0Aparser.add_argument%28%27--lr%27%2C+default%3D0.001%2C+help%3D%27%27%29%0Aparser.add_argument%28%27--batch_size%27%2C+type%3Dint%2C+default%3D256%2C+help%3D%27%27%29%0A%0Aargs+%3D+parser.parse_args%28%29%0A%0Astrategy+%3D+tf.distribute.MirroredStrategy%28%29%0A%0Awith+strategy.scope%28%29%3A%0A%0A++++model+%3D+tf.keras.Sequential%28%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%2C+padding%3D%27same%27%2C%0A+++++++++++++++++input_shape%3D%2832%2C32%2C3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%2C+padding%3D%27same%27%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Flatten%28%29%29%0A++++model.add%28tf.keras.layers.Dense%28512%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.5%29%29%0A++++model.add%28tf.keras.layers.Dense%2810%29%29%0A%0A++++model.compile%28loss%3Dtf.keras.losses.SparseCategoricalCrossentropy%28from_logits%3DTrue%29%2C%0A+++++++++optimizer%3Dtf.keras.optimizers.SGD%28learning_rate%3Dargs.lr%29%2Cmetrics%3D%5B%27accuracy%27%5D%29%0A%0A%23%23%23+This+next+line+will+attempt+to+download+the+CIFAR10+dataset+from+the+internet+if+you+don%27t+already+have+it+stored+in+%7E%2F.keras%2Fdatasets.+%0A%23%23%23+Run+this+line+on+a+login+node+prior+to+submitting+your+job%2C+or+manually+download+the+data+from+%0A%23%23%23+https%3A%2F%2Fwww.cs.toronto.edu%2F%7Ekriz%2Fcifar-10-python.tar.gz%2C+rename+to+%22cifar-10-batches-py.tar.gz%22+and+place+it+under+%7E%2F.keras%2Fdatasets%0A%0A%28x_train%2C+y_train%29%2C_+%3D+tf.keras.datasets.cifar10.load_data%28%29%0A%0Adataset+%3D+tf.data.Dataset.from_tensor_slices%28%28x_train%2C+y_train%29%29.batch%28args.batch_size%29%0A%0Amodel.fit%28dataset%2C+epochs%3D2%29" />
<input type="hidden" name="filename" value="tensorflow-singleworker.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;cifar10 classification models, tensorflow MirroredStrategy test&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1">### This next line will attempt to download the CIFAR10 dataset from the internet if you don&#39;t already have it stored in ~/.keras/datasets. </span>
<span class="c1">### Run this line on a login node prior to submitting your job, or manually download the data from </span>
<span class="c1">### https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz, rename to &quot;cifar-10-batches-py.tar.gz&quot; and place it under ~/.keras/datasets</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p><br />
</p>
<h5><span class="mw-headline" id="Multiple_nodes">Multiple nodes</span></h5>
<p>The syntax to use multiple GPUs distributed across multiple nodes is very similar to the single node case, the most notable difference being the use of <code>MultiWorkerMirroredStrategy()</code>. Here, we use <code>SlurmClusterResolver()</code> to tell TensorFlow to acquire all the necessary job information from SLURM, instead of manually assigning master and worker nodes, for example. We also need to add <code>CommunicationImplementation.NCCL</code> to the distribution strategy to specify that we want to use Nvidia's NCCL backend for inter-GPU communications. This was not necessary in the single-node case, as NCCL is the default backend with <code>MirroredStrategy()</code>.
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-multiworker.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--nodes+2++++++++++++++%23+Request+2+nodes+so+all+resources+are+in+two+nodes.%0A%23SBATCH+--gres%3Dgpu%3A2++++++++++%23+Request+2+GPU+%22generic+resources%E2%80%9D.+You+will+get+2+per+node.%0A%0A%23SBATCH+--ntasks-per-node%3D2+++%23+Request+1+process+per+GPU.+You+will+get+1+CPU+per+process+by+default.+Request+more+CPUs+with+the+%22cpus-per-task%22+parameter+if+your+input+pipeline+can+handle+parallel+data-loading%2Fdata-transforms%0A%0A%23SBATCH+--mem%3D8G++++++%0A%23SBATCH+--time%3D0-00%3A30%0A%23SBATCH+--output%3D%25N-%25j.out%0A%0A%0Asrun+-N+%24SLURM_NNODES+-n+%24SLURM_NNODES+config_env.sh%0A%0Amodule+load+gcc%2F9.3.0+cuda%2F11.8%0Aexport+NCCL_BLOCKING_WAIT%3D1++%23Set+this+environment+variable+if+you+wish+to+use+the+NCCL+backend+for+inter-GPU+communication.%0Aexport+XLA_FLAGS%3D--xla_gpu_cuda_data_dir%3D%24CUDA_HOME%0A%0Asrun+launch_training.sh" />
<input type="hidden" name="filename" value="tensorflow-multiworker.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes 2              # Request 2 nodes so all resources are in two nodes.</span>
<span class="c1">#SBATCH --gres=gpu:2          # Request 2 GPU &quot;generic resourcesâ€. You will get 2 per node.</span>

<span class="c1">#SBATCH --ntasks-per-node=2   # Request 1 process per GPU. You will get 1 CPU per process by default. Request more CPUs with the &quot;cpus-per-task&quot; parameter if your input pipeline can handle parallel data-loading/data-transforms</span>

<span class="c1">#SBATCH --mem=8G      </span>
<span class="c1">#SBATCH --time=0-00:30</span>
<span class="c1">#SBATCH --output=%N-%j.out</span>


srun<span class="w"> </span>-N<span class="w"> </span><span class="nv">$SLURM_NNODES</span><span class="w"> </span>-n<span class="w"> </span><span class="nv">$SLURM_NNODES</span><span class="w"> </span>config_env.sh

module<span class="w"> </span>load<span class="w"> </span>gcc/9.3.0<span class="w"> </span>cuda/11.8
<span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_BLOCKING_WAIT</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1">#Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">XLA_FLAGS</span><span class="o">=</span>--xla_gpu_cuda_data_dir<span class="o">=</span><span class="nv">$CUDA_HOME</span>

srun<span class="w"> </span>launch_training.sh
</pre></div>
</div>
<p><br />
</p><p>Where <code>config_env.sh</code> has the form:
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> config_env.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%0Amodule+load+python%0A%0Avirtualenv+--no-download+%24SLURM_TMPDIR%2FENV%0A%0Asource+%24SLURM_TMPDIR%2FENV%2Fbin%2Factivate%0A%0Apip+install+--upgrade+pip+--no-index%0A%0Apip+install+--no-index+tensorflow%0A%0Aecho+%22Done+installing+virtualenv%21%22" />
<input type="hidden" name="filename" value="config_env.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>

module<span class="w"> </span>load<span class="w"> </span>python

virtualenv<span class="w"> </span>--no-download<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/ENV

<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/ENV/bin/activate

pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip<span class="w"> </span>--no-index

pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span>tensorflow

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Done installing virtualenv!&quot;</span>
</pre></div>
</div>
<p><br />
</p><p>The script <code>launch_training.sh</code> has the form:
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> launch_training.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%0Asource+%24SLURM_TMPDIR%2FENV%2Fbin%2Factivate%0A%0Apython+tensorflow-multiworker.py" />
<input type="hidden" name="filename" value="launch_training.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/ENV/bin/activate

python<span class="w"> </span>tensorflow-multiworker.py
</pre></div>
</div>
<p><br />
</p><p>And the Python script <code>tensorflow-multiworker.py</code> has the form:
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-multiworker.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Aimport+numpy+as+np%0A%0Aimport+argparse%0A%0A%0Aparser+%3D+argparse.ArgumentParser%28description%3D%27cifar10+classification+models%2C+tensorflow+MultiWorkerMirrored+test%27%29%0Aparser.add_argument%28%27--lr%27%2C+default%3D0.001%2C+help%3D%27%27%29%0Aparser.add_argument%28%27--batch_size%27%2C+type%3Dint%2C+default%3D256%2C+help%3D%27%27%29%0A%0Aargs+%3D+parser.parse_args%28%29%0A%0Acluster_config+%3D+tf.distribute.cluster_resolver.SlurmClusterResolver%28%29%0Acomm_options+%3D+tf.distribute.experimental.CommunicationOptions%28implementation%3Dtf.distribute.experimental.CommunicationImplementation.NCCL%29%0A%0Astrategy+%3D+tf.distribute.MultiWorkerMirroredStrategy%28cluster_resolver%3Dcluster_config%2C+communication_options%3Dcomm_options%29%0A%0Awith+strategy.scope%28%29%3A%0A%0A++++model+%3D+tf.keras.Sequential%28%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%2C+padding%3D%27same%27%2C%0A+++++++++++++++++input_shape%3D%2832%2C32%2C3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%2C+padding%3D%27same%27%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0A++++model.add%28tf.keras.layers.Flatten%28%29%29%0A++++model.add%28tf.keras.layers.Dense%28512%29%29%0A++++model.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0A++++model.add%28tf.keras.layers.Dropout%280.5%29%29%0A++++model.add%28tf.keras.layers.Dense%2810%29%29%0A%0A++++model.compile%28loss%3Dtf.keras.losses.SparseCategoricalCrossentropy%28from_logits%3DTrue%29%2C%0A+++++++++optimizer%3Dtf.keras.optimizers.SGD%28learning_rate%3Dargs.lr%29%2Cmetrics%3D%5B%27accuracy%27%5D%29%0A%0A%23%23%23+This+next+line+will+attempt+to+download+the+CIFAR10+dataset+from+the+internet+if+you+don%27t+already+have+it+stored+in+%7E%2F.keras%2Fdatasets.+%0A%23%23%23+Run+this+line+on+a+login+node+prior+to+submitting+your+job%2C+or+manually+download+the+data+from+%0A%23%23%23+https%3A%2F%2Fwww.cs.toronto.edu%2F%7Ekriz%2Fcifar-10-python.tar.gz%2C+rename+to+%22cifar-10-batches-py.tar.gz%22+and+place+it+under+%7E%2F.keras%2Fdatasets%0A%0A%28x_train%2C+y_train%29%2C_+%3D+tf.keras.datasets.cifar10.load_data%28%29%0A%0Adataset+%3D+tf.data.Dataset.from_tensor_slices%28%28x_train%2C+y_train%29%29.batch%28args.batch_size%29%0A%0Amodel.fit%28dataset%2C+epochs%3D2%29" />
<input type="hidden" name="filename" value="tensorflow-multiworker.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;cifar10 classification models, tensorflow MultiWorkerMirrored test&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">cluster_config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">SlurmClusterResolver</span><span class="p">()</span>
<span class="n">comm_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">CommunicationOptions</span><span class="p">(</span><span class="n">implementation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">CommunicationImplementation</span><span class="o">.</span><span class="n">NCCL</span><span class="p">)</span>

<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">(</span><span class="n">cluster_resolver</span><span class="o">=</span><span class="n">cluster_config</span><span class="p">,</span> <span class="n">communication_options</span><span class="o">=</span><span class="n">comm_options</span><span class="p">)</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1">### This next line will attempt to download the CIFAR10 dataset from the internet if you don&#39;t already have it stored in ~/.keras/datasets. </span>
<span class="c1">### Run this line on a login node prior to submitting your job, or manually download the data from </span>
<span class="c1">### https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz, rename to &quot;cifar-10-batches-py.tar.gz&quot; and place it under ~/.keras/datasets</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p><br />
</p>
<h4><span class="mw-headline" id="Horovod">Horovod</span></h4>
<p><a rel="nofollow" class="external text" href="https://horovod.readthedocs.io/en/latest/summary_include.html">Horovod</a> is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. The following is the same tutorial from above reimplemented using Horovod:
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-horovod.sh</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="%23%21%2Fbin%2Fbash%0A%23SBATCH+--nodes+1+++++++++++++%0A%23SBATCH+--gres%3Dgpu%3A2++++++++++%23+Request+2+GPU+%22generic+resources%E2%80%9D.+You+will+get+2+per+node.%0A%0A%23SBATCH+--ntasks-per-node%3D2+++%23+Request+1+process+per+GPU.+You+will+get+1+CPU+per+process+by+default.+Request+more+CPUs+with+the+%22cpus-per-task%22+parameter+if+your+input+pipeline+can+handle+parallel+data-loading%2Fdata-transforms%0A%0A%23SBATCH+--mem%3D8G++++++%0A%23SBATCH+--time%3D0-00%3A30%0A%23SBATCH+--output%3D%25N-%25j.out%0A%0A%0Amodule+load+StdEnv%2F2020+%0Amodule+load+python%2F3.8%0Avirtualenv+--no-download+%24SLURM_TMPDIR%2Fenv%0Asource+%24SLURM_TMPDIR%2Fenv%2Fbin%2Factivate%0Apip+install+--no-index+tensorflow%3D%3D2.5.0+horovod%0A%0Aexport+NCCL_BLOCKING_WAIT%3D1++%23Set+this+environment+variable+if+you+wish+to+use+the+NCCL+backend+for+inter-GPU+communication.%0A%0Asrun+python+tensorflow-horovod.py" />
<input type="hidden" name="filename" value="tensorflow-horovod.sh" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --nodes 1             </span>
<span class="c1">#SBATCH --gres=gpu:2          # Request 2 GPU &quot;generic resourcesâ€. You will get 2 per node.</span>

<span class="c1">#SBATCH --ntasks-per-node=2   # Request 1 process per GPU. You will get 1 CPU per process by default. Request more CPUs with the &quot;cpus-per-task&quot; parameter if your input pipeline can handle parallel data-loading/data-transforms</span>

<span class="c1">#SBATCH --mem=8G      </span>
<span class="c1">#SBATCH --time=0-00:30</span>
<span class="c1">#SBATCH --output=%N-%j.out</span>


module<span class="w"> </span>load<span class="w"> </span>StdEnv/2020<span class="w"> </span>
module<span class="w"> </span>load<span class="w"> </span>python/3.8
virtualenv<span class="w"> </span>--no-download<span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env
<span class="nb">source</span><span class="w"> </span><span class="nv">$SLURM_TMPDIR</span>/env/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>--no-index<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.5.0<span class="w"> </span>horovod

<span class="nb">export</span><span class="w"> </span><span class="nv">NCCL_BLOCKING_WAIT</span><span class="o">=</span><span class="m">1</span><span class="w">  </span><span class="c1">#Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.</span>

srun<span class="w"> </span>python<span class="w"> </span>tensorflow-horovod.py
</pre></div>
</div>
<p><br />
</p><p><br />
</p>
<div class="code-file">
<div class="filename"><b>File&#160;:</b> tensorflow-horovod.py</div>
<div class="download_form">
<p class="mw-empty-elt"></p><form action="/mediawiki/resources/assets/download.php" method="post">
<input type="hidden" name="text" value="import+tensorflow+as+tf%0Aimport+numpy+as+np%0Aimport+horovod.tensorflow.keras+as+hvd%0A%0Aimport+argparse%0A%0A%0Aparser+%3D+argparse.ArgumentParser%28description%3D%27cifar10+classification+models%2C+tensorflow+horovod+test%27%29%0Aparser.add_argument%28%27--lr%27%2C+default%3D0.001%2C+help%3D%27%27%29%0Aparser.add_argument%28%27--batch_size%27%2C+type%3Dint%2C+default%3D256%2C+help%3D%27%27%29%0A%0Aargs+%3D+parser.parse_args%28%29%0A%0Ahvd.init%28%29%0A%0Agpus+%3D+tf.config.experimental.list_physical_devices%28%27GPU%27%29%0A%0Atf.config.experimental.set_visible_devices%28gpus%5Bhvd.local_rank%28%29%5D%2C+%27GPU%27%29%0A%0Amodel+%3D+tf.keras.Sequential%28%29%0A%0Amodel.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%2C+padding%3D%27same%27%2C%0A+++++++++++++++++input_shape%3D%2832%2C32%2C3%29%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.Conv2D%2832%2C+%283%2C+3%29%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0Amodel.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0Amodel.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%2C+padding%3D%27same%27%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.Conv2D%2864%2C+%283%2C+3%29%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.MaxPooling2D%28pool_size%3D%282%2C+2%29%29%29%0Amodel.add%28tf.keras.layers.Dropout%280.25%29%29%0A%0Amodel.add%28tf.keras.layers.Flatten%28%29%29%0Amodel.add%28tf.keras.layers.Dense%28512%29%29%0Amodel.add%28tf.keras.layers.Activation%28%27relu%27%29%29%0Amodel.add%28tf.keras.layers.Dropout%280.5%29%29%0Amodel.add%28tf.keras.layers.Dense%2810%29%29%0A%0Aoptimizer+%3D+tf.keras.optimizers.SGD%28learning_rate%3Dargs.lr%29%0A%0Aoptimizer+%3D+hvd.DistributedOptimizer%28optimizer%29%0A%0Amodel.compile%28loss%3Dtf.keras.losses.SparseCategoricalCrossentropy%28from_logits%3DTrue%29%2C%0A+++++++++optimizer%3Doptimizer%2Cmetrics%3D%5B%27accuracy%27%5D%29%0A%0Acallbacks+%3D+%5B%0A++++hvd.callbacks.BroadcastGlobalVariablesCallback%280%29%2C%0A%5D%0A%0A%23%23%23+This+next+line+will+attempt+to+download+the+CIFAR10+dataset+from+the+internet+if+you+don%27t+already+have+it+stored+in+%7E%2F.keras%2Fdatasets.+%0A%23%23%23+Run+this+line+on+a+login+node+prior+to+submitting+your+job%2C+or+manually+download+the+data+from+%0A%23%23%23+https%3A%2F%2Fwww.cs.toronto.edu%2F%7Ekriz%2Fcifar-10-python.tar.gz%2C+rename+to+%22cifar-10-batches-py.tar.gz%22+and+place+it+under+%7E%2F.keras%2Fdatasets%0A%0A%28x_train%2C+y_train%29%2C_+%3D+tf.keras.datasets.cifar10.load_data%28%29%0A%0Adataset+%3D+tf.data.Dataset.from_tensor_slices%28%28x_train%2C+y_train%29%29.batch%28args.batch_size%29%0A%0Amodel.fit%28dataset%2C+epochs%3D2%2C+callbacks%3Dcallbacks%2C+verbose%3D2%29+%23+verbose%3D2+to+avoid+printing+a+progress+bar+to+%2A.out+files." />
<input type="hidden" name="filename" value="tensorflow-horovod.py" />
<input type="submit" value="" name="submit" class="download_submit" />
</form>
<p class="mw-empty-elt"></p>
</div>
<div class="mw-highlight mw-highlight-lang-python mw-content-ltr" dir="ltr"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">horovod.tensorflow.keras</span> <span class="k">as</span> <span class="nn">hvd</span>

<span class="kn">import</span> <span class="nn">argparse</span>


<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;cifar10 classification models, tensorflow horovod test&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">(</span><span class="n">gpus</span><span class="p">[</span><span class="n">hvd</span><span class="o">.</span><span class="n">local_rank</span><span class="p">()],</span> <span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">BroadcastGlobalVariablesCallback</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1">### This next line will attempt to download the CIFAR10 dataset from the internet if you don&#39;t already have it stored in ~/.keras/datasets. </span>
<span class="c1">### Run this line on a login node prior to submitting your job, or manually download the data from </span>
<span class="c1">### https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz, rename to &quot;cifar-10-batches-py.tar.gz&quot; and place it under ~/.keras/datasets</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># verbose=2 to avoid printing a progress bar to *.out files.</span>
</pre></div>
</div>
<p><br />
</p>
<h2><span class="mw-headline" id="Creating_model_checkpoints">Creating model checkpoints</span></h2>
<p>Whether or not you expect your code to run for long time periods, it is a good habit to create Checkpoints during training. A checkpoint is a snapshot of your model at a given point during the training process (after a certain number of iterations or after a number of epochs) that is saved to disk and can be loaded at a later time. It is a handy way of breaking jobs that are expected to run for a very long time, into multiple shorter jobs that may get allocated on the cluster more quickly. It is also a good way of avoiding losing progress in case of unexpected errors in your code or node failures.
</p>
<h3><span class="mw-headline" id="With_Keras">With Keras</span></h3>
<p>To create a checkpoint when training with <code>keras</code>, we recommend using the <code>callbacks</code> parameter of the <code>model.fit()</code> method. The following example shows how to instruct TensorFlow to create a checkpoint at the end of every training epoch:
</p>
<pre>callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath="./ckpt",save_freq="epoch")] # Make sure the path where you want to create the checkpoint exists

model.fit(dataset, epochs=10 , callbacks=callbacks)
</pre>
<p>For more information, please refer to the <a rel="nofollow" class="external text" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint">official TensorFlow documentation</a>.
</p>
<h3><span class="mw-headline" id="With_a_custom_training_loop">With a custom training loop</span></h3>
<p>Please refer to the <a rel="nofollow" class="external text" href="https://www.tensorflow.org/guide/checkpoint#writing_checkpoints">official TensorFlow documentation</a>.
</p>
<h2><span class="mw-headline" id="Custom_TensorFlow_operators">Custom TensorFlow operators</span></h2>
<p>In your research, you may come across <a rel="nofollow" class="external text" href="https://github.com/Yang7879/3D-BoNet">code that leverages custom operators</a> that are not part of the core tensorflow distribution, or you might want to <a rel="nofollow" class="external text" href="https://www.tensorflow.org/guide/create_op">create your own</a>. In both cases, you will need to compile your custom operators <i>before</i> submitting your job. To ensure your code will run correctly, follow the steps below.
</p><p>First, create a <a href="/wiki/Python" title="Python">Python virtual environment</a> and install a tensorflow version compatible with your custom operators. Then go to the directory containing the operators source code and follow the next steps according to the version you installed:
</p>
<h3><span id="TensorFlow_.3C.3D_1.4.x"></span><span class="mw-headline" id="TensorFlow_&lt;=_1.4.x">TensorFlow &lt;= 1.4.x</span></h3>
<p>If your custom operator <b>is</b> GPU-enabled:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>cuda/&lt;version&gt;
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>nvcc<span class="w"> </span>&lt;operator&gt;.cu<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-c<span class="w"> </span>-O2<span class="w"> </span>-DGOOGLE_CUDA<span class="o">=</span><span class="m">1</span><span class="w"> </span>-x<span class="w"> </span>cu<span class="w"> </span>-Xcompiler<span class="w"> </span>-fPI
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public<span class="w"> </span>-I<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/include<span class="w"> </span>-lcudart<span class="w"> </span>-L<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/lib64/
</pre></div></div>
<p><br />
If your custom operator <b>is not</b> GPU-enabled:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public
</pre></div></div>
<p><br />
</p>
<h3><span id="TensorFlow_.3E_1.4.x"></span><span class="mw-headline" id="TensorFlow_&gt;_1.4.x">TensorFlow &gt; 1.4.x</span></h3>
<p>If your custom operator <b>is</b> GPU-enabled:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>cuda/&lt;version&gt;
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>nvcc<span class="w"> </span>&lt;operator&gt;.cu<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-c<span class="w"> </span>-O2<span class="w"> </span>-DGOOGLE_CUDA<span class="o">=</span><span class="m">1</span><span class="w"> </span>-x<span class="w"> </span>cu<span class="w"> </span>-Xcompiler<span class="w"> </span>-fPI
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>&lt;operator&gt;.cu.o<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/include<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public<span class="w"> </span>-lcudart<span class="w"> </span>-L<span class="w"> </span>/usr/local/cuda-&lt;version&gt;/lib64/<span class="w"> </span>-L<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow<span class="w"> </span>-ltensorflow_framework
</pre></div></div>
<p><br />
If your custom operator <b>is not</b> GPU-enabled:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>g++<span class="w"> </span>-std<span class="o">=</span>c++11<span class="w"> </span>&lt;operator&gt;.cpp<span class="w"> </span>-o<span class="w"> </span>&lt;operator&gt;.so<span class="w"> </span>-shared<span class="w"> </span>-fPIC<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include<span class="w"> </span>-I<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow/include/external/nsync/public<span class="w"> </span>-L<span class="w"> </span>/&lt;path<span class="w"> </span>to<span class="w"> </span>python<span class="w"> </span>virtual<span class="w"> </span>env&gt;/lib/python&lt;version&gt;/site-packages/tensorflow<span class="w"> </span>-ltensorflow_framework
</pre></div></div>
<p><br />
</p>
<h2><span class="mw-headline" id="Troubleshooting">Troubleshooting</span></h2>
<h3><span class="mw-headline" id="scikit_image">scikit image</span></h3>
<p>If you are using the scikit-image library, you may get the following error:
<code>OMP: Error #15: Initializing libiomp5.so, but found libiomp5.so already initialized. </code>
</p><p>This is because the tensorflow library tries to load a bundled version of OMP which conflicts with the system version. The workaround is as follows:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">(</span>tf_skimage_venv<span class="o">)</span><span class="w"> </span>name@server<span class="w"> </span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>tf_skimage_venv
<span class="o">(</span>tf_skimage_venv<span class="o">)</span><span class="w"> </span>name@server<span class="w"> </span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">LIBIOMP_PATH</span><span class="o">=</span><span class="k">$(</span>strace<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;from skimage.transform import AffineTransform&#39;</span><span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span>ENOENT<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-ohP<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;(?&lt;=&quot;)[^&quot;]+libiomp5.so(?=&quot;)&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>realpath<span class="k">)</span>
<span class="o">(</span>tf_skimage_venv<span class="o">)</span><span class="w"> </span>name@server<span class="w"> </span>$<span class="w"> </span>find<span class="w"> </span>-path<span class="w"> </span><span class="s1">&#39;*_solib_local*&#39;</span><span class="w"> </span>-name<span class="w"> </span>libiomp5.so<span class="w"> </span>-exec<span class="w"> </span>ln<span class="w"> </span>-sf<span class="w"> </span><span class="nv">$LIBIOMP_PATH</span><span class="w"> </span><span class="o">{}</span><span class="w"> </span><span class="se">\;</span>
</pre></div></div>
<p>This will patch the tensorflow library installation to use the systemwide libiomp5.so.
</p>
<h3><span class="mw-headline" id="libcupti.so">libcupti.so</span></h3>
<p>Some tracing features of Tensorflow require libcupti.so to be available, and might give the following error if they are not:
</p><p><code>I tensorflow/stream_executor/dso_loader.cc:142] Couldn't open CUDA library libcupti.so.9.0. LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64</code>
</p><p>The solution is to run the following before executing your script:
</p>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span>module<span class="w"> </span>load<span class="w"> </span>cuda/9.0.xxx
<span class="o">[</span>name@server<span class="w"> </span>~<span class="o">]</span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:<span class="nv">$CUDA_HOME</span>/extras/CUPTI/lib64/
</pre></div></div>
<p>Where xxx is the appropriate CUDA version, which can be found using <code>module av cuda</code>
</p>
<h3><span class="mw-headline" id="libiomp5.so_invalid_ELF_header">libiomp5.so invalid ELF header</span></h3>
<p>Sometimes the <code>libiomp5.so</code> shared object file will be erroneously installed as a text file. This might result in errors like the following:
</p><p><code>/home/username/venv/lib/python3.6/site-packages/tensorflow/python/../../_solib_local/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib/libiomp5.so: invalid ELF header</code>
</p><p>The workaround for such errors is to access the directory mentioned in the error (i.e. <code>[...]/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib</code>) and execute the following command:
</p>
<div>
<div style="float:right; margin-left:8px">
<p><span typeof="mw:File"><a href="https://explainshell.com/explain?cmd=ln+-sf+%24%28cat+libiomp5.so%29+libiomp5.so" rel="nofollow"><img src="/mediawiki/images/thumb/3/30/Question.png/40px-Question.png" decoding="async" width="40" height="40" class="mw-file-element" srcset="/mediawiki/images/thumb/3/30/Question.png/60px-Question.png 1.5x, /mediawiki/images/thumb/3/30/Question.png/80px-Question.png 2x" /></a></span>
</p>
</div>
<div class="command">
<div class="mw-highlight mw-highlight-lang-bash mw-content-ltr" dir="ltr"><pre><span></span><span class="o">[</span>name@server<span class="w"> </span>...Ulinux_Slib<span class="o">]</span><span class="w"> </span>$<span class="w"> </span>ln<span class="w"> </span>-sf<span class="w"> </span><span class="k">$(</span>cat<span class="w"> </span>libiomp5.so<span class="k">)</span><span class="w"> </span>libiomp5.so
</pre></div>
</div>
</div>
<p>This will replace the text file with the correct symbolic link.
</p>
<h2><span class="mw-headline" id="Controlling_the_number_of_CPUs_and_threads">Controlling the number of CPUs and threads</span></h2>
<h3><span class="mw-headline" id="TensorFlow_1.x_2">TensorFlow 1.x</span></h3>
<p>The config parameters <code>device_count</code>, <code>intra_op_parallelism_threads</code> and <code>inter_op_parallelism_threads</code> influence the number of threads used by TensorFlow. You can set those parameters when instantiating a session:
</p>
<pre>tf.Session(config=tf.ConfigProto(device_count={'CPU': num_cpus}, intra_op_parallelism_threads=num_intra_threads, inter_op_parallelism_threads=num_inter_threads))
</pre>
<p>For example, if you want to run multiple instances of TF in parallel on a single node, you might want to reduce those values, potentially down to <code>1</code>.
</p>
<h3><span class="mw-headline" id="TensorFlow_2.x_2">TensorFlow 2.x</span></h3>
<p>Sessions are not used anymore in TF 2.x, so here is the approach for configuring threads:
</p>
<pre>tf.config.threading.set_inter_op_parallelism_threads(num_threads)
tf.config.threading.set_intra_op_parallelism_threads(num_threads)
</pre>
<p>As of TF 2.1, there does not seem to be a way to set a CPU count.
</p>
<h2><span class="mw-headline" id="Known_issues">Known issues</span></h2>
<p>A bug sneaked into the Keras implementation of Tensorflow after version 2.8.3. It affects the performance of the layers used for data augmentation with prefix <i>tf.keras.layers.Random</i> (like <i>tf.keras.layers.RandomRotation</i>, <i>tf.keras.layers.RandomTranslation</i>, etc). It significantly slows down the training process by more than 100 times. The bug is fixed in version 2.12.
</p>
<!-- 
NewPP limit report
Cached time: 20250530235524
Cache expiry: 86400
Reduced expiry: false
Complications: [showâ€toc]
CPU time usage: 0.190 seconds
Real time usage: 3.617 seconds
Preprocessor visited node count: 1418/1000000
Postâ€expand include size: 24820/2097152 bytes
Template argument size: 23008/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 36/100
Unstrip recursion depth: 3/20
Unstrip postâ€expand size: 90206/5000000 bytes
ExtLoops count: 0/100
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 3532.221      1 -total
 42.19% 1490.327     13 Template:File
 31.81% 1123.668     14 Template:Command2
 17.48%  617.426      6 Template:Commands
  2.86%  101.140      1 Template:Command
-->

<!-- Saved in parser cache with key ccwiki:pcache:idhash:3554-0!canonical and timestamp 20250530235524 and revision id 157500. Rendering was triggered because: page-view
 -->
</div>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://docs.alliancecan.ca/mediawiki/index.php?title=TensorFlow&amp;oldid=157500">https://docs.alliancecan.ca/mediawiki/index.php?title=TensorFlow&amp;oldid=157500</a>"</div></div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="/wiki/Category:Software" title="Category:Software">Software</a></li><li><a href="/wiki/Category:AI_and_Machine_Learning" title="Category:AI and Machine Learning">AI and Machine Learning</a></li></ul></div></div>
	</div>
</div>

<div id="mw-navigation">
	<h2>Navigation menu</h2>
	<div id="mw-head">
		
<nav id="p-personal" class="mw-portlet mw-portlet-personal vector-user-menu-legacy vector-menu" aria-labelledby="p-personal-label"  >
	<h3
		id="p-personal-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Personal tools</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-uls" class="mw-list-item active"><a class="uls-trigger" href="#"><span>English</span></a></li><li id="pt-login" class="mw-list-item"><a href="/mediawiki/index.php?title=Special:UserLogin&amp;returnto=TensorFlow" title="You are encouraged to log in; however, it is not mandatory [o]" accesskey="o"><span>Log in</span></a></li>
		</ul>
		
	</div>
</nav>

		<div id="left-navigation">
			
<nav id="p-namespaces" class="mw-portlet mw-portlet-namespaces vector-menu-tabs vector-menu-tabs-legacy vector-menu" aria-labelledby="p-namespaces-label"  >
	<h3
		id="p-namespaces-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Namespaces</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected mw-list-item"><a href="/wiki/TensorFlow" title="View the content page [c]" accesskey="c"><span>Page</span></a></li><li id="ca-talk" class="new mw-list-item"><a href="/mediawiki/index.php?title=Talk:TensorFlow&amp;action=edit&amp;redlink=1" rel="discussion" class="new" title="Discussion about the content page (page does not exist) [t]" accesskey="t"><span>Discussion</span></a></li>
		</ul>
		
	</div>
</nav>

			
<nav id="p-variants" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown vector-menu" aria-labelledby="p-variants-label"  >
	<input type="checkbox"
		id="p-variants-checkbox"
		role="button"
		aria-haspopup="true"
		data-event-name="ui.dropdown-p-variants"
		class="vector-menu-checkbox"
		aria-labelledby="p-variants-label"
	>
	<label
		id="p-variants-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">English</span>
	</label>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</nav>

		</div>
		<div id="right-navigation">
			
<nav id="p-views" class="mw-portlet mw-portlet-views vector-menu-tabs vector-menu-tabs-legacy vector-menu" aria-labelledby="p-views-label"  >
	<h3
		id="p-views-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Views</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected mw-list-item"><a href="/wiki/TensorFlow"><span>Read</span></a></li><li id="ca-viewsource" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow&amp;action=edit" title="This page is protected.&#10;You can view its source [e]" accesskey="e"><span>View source</span></a></li><li id="ca-history" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</nav>

			
<nav id="p-cactions" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown vector-menu" aria-labelledby="p-cactions-label"  title="More options" >
	<input type="checkbox"
		id="p-cactions-checkbox"
		role="button"
		aria-haspopup="true"
		data-event-name="ui.dropdown-p-cactions"
		class="vector-menu-checkbox"
		aria-labelledby="p-cactions-label"
	>
	<label
		id="p-cactions-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">More</span>
	</label>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</nav>

			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<h3 >Search</h3>
	<form action="/mediawiki/index.php" id="searchform" class="vector-search-box-form">
		<div id="simpleSearch"
			class="vector-search-box-inner"
			 data-search-loc="header-navigation">
			<input class="vector-search-box-input"
				 type="search" name="search" placeholder="Search Alliance Doc" aria-label="Search Alliance Doc" autocapitalize="sentences" title="Search Alliance Doc [f]" accesskey="f" id="searchInput"
			>
			<input type="hidden" name="title" value="Special:Search">
			<input id="mw-searchButton"
				 class="searchButton mw-fallbackSearchButton" type="submit" name="fulltext" title="Search the pages for this text" value="Search">
			<input id="searchButton"
				 class="searchButton" type="submit" name="go" title="Go to a page with this exact name if it exists" value="Go">
		</div>
	</form>
</div>

		</div>
	</div>
	
<div id="mw-panel" class="vector-legacy-sidebar">
	<div id="p-logo" role="banner">
		<a class="mw-wiki-logo" href="/wiki/Technical_documentation"
			title="Visit the main page"></a>
	</div>
	
<nav id="p-navigation" class="mw-portlet mw-portlet-navigation vector-menu-portal portal vector-menu" aria-labelledby="p-navigation-label"  >
	<h3
		id="p-navigation-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Navigation</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-wiki-main-page" class="mw-list-item"><a href="/wiki/Technical_documentation"><span>Wiki Main Page</span></a></li>
		</ul>
		
	</div>
</nav>

	
<nav id="p-sidebar-support" class="mw-portlet mw-portlet-sidebar-support vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-support-label"  >
	<h3
		id="p-sidebar-support-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Support</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-getting-started" class="mw-list-item"><a href="/wiki/Getting_started"><span>Getting started</span></a></li><li id="n-sidebar-technical-support" class="mw-list-item"><a href="/wiki/Technical_support"><span>Getting help</span></a></li><li id="n-sidebar-running-jobs" class="mw-list-item"><a href="/wiki/Running_jobs"><span>Running jobs</span></a></li><li id="n-sidebar-known-issues" class="mw-list-item"><a href="/wiki/Known_issues"><span>Known issues</span></a></li><li id="n-sidebar-system-status" class="mw-list-item"><a href="http://status.computecanada.ca" rel="nofollow"><span>System status</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-sidebar-resources" class="mw-portlet mw-portlet-sidebar-resources vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-resources-label"  >
	<h3
		id="p-sidebar-resources-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Resources</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-BÃ©luga" class="mw-list-item"><a href="/wiki/B%C3%A9luga/en"><span>BÃ©luga</span></a></li><li id="n-Cedar" class="mw-list-item"><a href="/wiki/Cedar"><span>Cedar</span></a></li><li id="n-Graham" class="mw-list-item"><a href="/wiki/Graham"><span>Graham</span></a></li><li id="n-Narval" class="mw-list-item"><a href="/wiki/Narval/en"><span>Narval</span></a></li><li id="n-Niagara" class="mw-list-item"><a href="/wiki/Niagara"><span>Niagara</span></a></li><li id="n-sidebar-cloud" class="mw-list-item"><a href="/wiki/CC-Cloud"><span>Cloud</span></a></li><li id="n-tamIA" class="mw-list-item"><a href="/wiki/TamIA/en"><span>tamIA</span></a></li><li id="n-Killarney" class="mw-list-item"><a href="/wiki/Killarney"><span>Killarney</span></a></li><li id="n-sidebar-quantum-computing" class="mw-list-item"><a href="/wiki/Services_d%27informatique_quantique/en"><span>Quantum computing</span></a></li><li id="n-sidebar-available-software" class="mw-list-item"><a href="/wiki/Available_software"><span>Available software</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-sidebar-alliance" class="mw-portlet mw-portlet-sidebar-alliance vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-alliance-label"  >
	<h3
		id="p-sidebar-alliance-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">The Alliance</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-alliance-main-page" class="mw-list-item"><a href="https://alliancecan.ca/en" rel="nofollow"><span>Alliance main page</span></a></li><li id="n-sidebar-ccdb" class="mw-list-item"><a href="https://ccdb.computecanada.ca/security/login" rel="nofollow"><span>CCDB</span></a></li><li id="n-sidebar-getting-an-account" class="mw-list-item"><a href="https://alliancecan.ca/en/services/advanced-research-computing/account-management/apply-account" rel="nofollow"><span>Getting An Account</span></a></li><li id="n-sidebar-acknowledging-alliance" class="mw-list-item"><a href="https://alliancecan.ca/en/services/advanced-research-computing/research-portal/acknowledging-alliance" rel="nofollow"><span>Acknowledging the Alliance</span></a></li><li id="n-sidebar-aup" class="mw-list-item"><a href="https://alliancecan.ca/en/services/advanced-research-computing/account-management/policies" rel="nofollow"><span>Acceptable Use Policy</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-sidebar-authoring" class="mw-portlet mw-portlet-sidebar-authoring vector-menu-portal portal vector-menu" aria-labelledby="p-sidebar-authoring-label"  >
	<h3
		id="p-sidebar-authoring-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Authoring</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-sidebar-guidelines" class="mw-list-item"><a href="/wiki/Authoring_guidelines"><span>Guidelines</span></a></li><li id="n-sidebar-mediawiki-help" class="mw-list-item"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/Help:Contents"><span>MediaWiki Help</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r"><span>Recent changes</span></a></li>
		</ul>
		
	</div>
</nav>

<nav id="p-tb" class="mw-portlet mw-portlet-tb vector-menu-portal portal vector-menu" aria-labelledby="p-tb-label"  >
	<h3
		id="p-tb-label"
		
		class="vector-menu-heading "
	>
		<span class="vector-menu-heading-label">Tools</span>
	</h3>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/TensorFlow" title="A list of all wiki pages that link here [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/TensorFlow" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q"><span>Special pages</span></a></li><li id="t-print" class="mw-list-item"><a href="javascript:print();" rel="alternate" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow&amp;oldid=157500" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/mediawiki/index.php?title=TensorFlow&amp;action=info" title="More information about this page"><span>Page information</span></a></li>
		</ul>
		
	</div>
</nav>

	
</div>

</div>

<footer id="footer" class="mw-footer" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 12 July 2024, at 17:55.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="/wiki/CCWiki:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/CCWiki:About">About Alliance Doc</a></li>
	<li id="footer-places-disclaimers"><a href="/wiki/CCWiki:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-mobileview"><a href="https://docs.alliancecan.ca/mediawiki/index.php?title=TensorFlow&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/" class="cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled"><img src="/mediawiki/resources/assets/poweredby_mediawiki.svg" alt="Powered by MediaWiki" width="88" height="31" loading="lazy"></a></li>
</ul>

</footer>

<script>(RLQ=window.RLQ||[]).push(function(){mw.log.warn("This page is using the deprecated ResourceLoader module \"codex-search-styles\".\n[1.43] Use a CodexModule with codexComponents to set your specific components used: https://www.mediawiki.org/wiki/Codex#Using_a_limited_subset_of_components");});</script>
<script src="https://www.googletagmanager.com/gtag/js?id=G-TVBPRD78K4" async=""></script><script>
window.dataLayer = window.dataLayer || [];

function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-TVBPRD78K4', {});
</script>

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":3726,"wgPageParseReport":{"limitreport":{"cputime":"0.190","walltime":"3.617","ppvisitednodes":{"value":1418,"limit":1000000},"postexpandincludesize":{"value":24820,"limit":2097152},"templateargumentsize":{"value":23008,"limit":2097152},"expansiondepth":{"value":8,"limit":100},"expensivefunctioncount":{"value":36,"limit":100},"unstrip-depth":{"value":3,"limit":20},"unstrip-size":{"value":90206,"limit":5000000},"timingprofile":["100.00% 3532.221      1 -total"," 42.19% 1490.327     13 Template:File"," 31.81% 1123.668     14 Template:Command2"," 17.48%  617.426      6 Template:Commands","  2.86%  101.140      1 Template:Command"]},"loops":{"limitreport-count-limited":{"value":0,"limit":100}},"cachereport":{"timestamp":"20250530235524","ttl":86400,"transientcontent":false}}});});</script>
</body>
</html>